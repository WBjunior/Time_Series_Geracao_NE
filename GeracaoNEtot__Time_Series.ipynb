{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WBjunior/Time_Series_Geracao_NE/blob/main/GeracaoNEtot__Time_Series.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pmdarima\n",
        "!pip install mapie"
      ],
      "metadata": {
        "id": "2bi7z5g7K_uq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8f1769d-98c6-4128-9b85-39b4011557b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pmdarima in /usr/local/lib/python3.9/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.9/dist-packages (from pmdarima) (1.3.5)\n",
            "Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.9/dist-packages (from pmdarima) (0.13.5)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.9/dist-packages (from pmdarima) (1.2.1)\n",
            "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.9/dist-packages (from pmdarima) (0.29.33)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.9/dist-packages (from pmdarima) (1.2.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (from pmdarima) (1.26.14)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from pmdarima) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.9/dist-packages (from pmdarima) (1.22.4)\n",
            "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /usr/local/lib/python3.9/dist-packages (from pmdarima) (57.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.19->pmdarima) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.19->pmdarima) (2022.7.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.22->pmdarima) (3.1.0)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.9/dist-packages (from statsmodels>=0.13.2->pmdarima) (0.5.3)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.9/dist-packages (from statsmodels>=0.13.2->pmdarima) (23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from patsy>=0.5.2->statsmodels>=0.13.2->pmdarima) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mapie in /usr/local/lib/python3.9/dist-packages (0.6.1)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.9/dist-packages (from mapie) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from mapie) (23.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from mapie) (1.2.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->mapie) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->mapie) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->mapie) (1.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xqH-7LlV3Z5",
        "outputId": "9b37e43e-2740-4b21-93ba-bae0dfad24fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-6e69e88428a1>:2: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import pandas.util.testing as tm\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from tensorflow import keras\n",
        "import math\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "import statsmodels.api as sm\n",
        "import itertools\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score,mean_absolute_percentage_error\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from mapie.regression import MapieRegressor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEY-9xt_Q7tR"
      },
      "source": [
        "# Dados de geração - ONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBKgy-JsRZnY"
      },
      "outputs": [],
      "source": [
        "geracao2023 = pd.read_csv('https://ons-dl-prod-opendata.s3.amazonaws.com/dataset/geracao_usina_2_ho/GERACAO_USINA-2_2023_01.csv',sep=';')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLl6MZLYYm6g",
        "outputId": "caa8383c-00d3-4646-be4e-9e52b421c65e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 463248 entries, 0 to 463247\n",
            "Data columns (total 11 columns):\n",
            " #   Column                  Non-Null Count   Dtype  \n",
            "---  ------                  --------------   -----  \n",
            " 0   din_instante            463248 non-null  object \n",
            " 1   id_subsistema           463248 non-null  object \n",
            " 2   nom_subsistema          463248 non-null  object \n",
            " 3   id_estado               463248 non-null  object \n",
            " 4   nom_estado              463248 non-null  object \n",
            " 5   cod_modalidadeoperacao  463248 non-null  object \n",
            " 6   nom_tipousina           463248 non-null  object \n",
            " 7   nom_tipocombustivel     462504 non-null  object \n",
            " 8   nom_usina               463248 non-null  object \n",
            " 9   ceg                     463248 non-null  object \n",
            " 10  val_geracao             462288 non-null  float64\n",
            "dtypes: float64(1), object(10)\n",
            "memory usage: 38.9+ MB\n"
          ]
        }
      ],
      "source": [
        "geracao2023.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvjajN6ZM1gQ",
        "outputId": "6324c5d7-8389-483a-c996-b4988a863a6f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count                           463248\n",
              "mean     2023-01-16 11:51:24.675163648\n",
              "min                2023-01-01 00:00:00\n",
              "25%                2023-01-08 18:00:00\n",
              "50%                2023-01-16 12:00:00\n",
              "75%                2023-01-24 06:00:00\n",
              "max                2023-01-31 23:00:00\n",
              "Name: din_instante, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "geracao2023['din_instante'].astype('datetime64[ms]').describe(exclude=[object],datetime_is_numeric=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "OVt7ntbMON2f",
        "outputId": "dc09d84d-6983-4f16-94a7-8bc351f66578"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         val_geracao\n",
              "count  462288.000000\n",
              "mean      115.967232\n",
              "std       424.723064\n",
              "min         0.000000\n",
              "25%         0.000000\n",
              "50%        24.000000\n",
              "75%        81.476000\n",
              "max      9923.151000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-63af6f5d-bc2b-4a94-8155-f0d25c64f540\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>val_geracao</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>462288.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>115.967232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>424.723064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>24.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>81.476000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9923.151000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63af6f5d-bc2b-4a94-8155-f0d25c64f540')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-63af6f5d-bc2b-4a94-8155-f0d25c64f540 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-63af6f5d-bc2b-4a94-8155-f0d25c64f540');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "geracao2023.describe(exclude=[object])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "MjSFUi9BK7gA",
        "outputId": "3f6705e4-42db-4551-d2a0-6a3fc4feb84c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               din_instante id_subsistema nom_subsistema id_estado nom_estado  \\\n",
              "count                463248        463248         463248    463248     463248   \n",
              "unique                  744             4              5        28         28   \n",
              "top     2023-01-31 23:00:00            NE       NORDESTE        BA      BAHIA   \n",
              "freq                    625        188544         188544     58776      58776   \n",
              "\n",
              "       cod_modalidadeoperacao  nom_tipousina nom_tipocombustivel nom_usina  \\\n",
              "count                  463248         463248              462504    463248   \n",
              "unique                      7              5                  12       623   \n",
              "top                    TIPO I  HIDROELÉTRICA          Hidráulica  São José   \n",
              "freq                   188976         154752              154752      1488   \n",
              "\n",
              "           ceg  \n",
              "count   463248  \n",
              "unique     343  \n",
              "top          -  \n",
              "freq    203904  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3bc16a80-0e6c-441c-9c36-b9c469fa9b88\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>din_instante</th>\n",
              "      <th>id_subsistema</th>\n",
              "      <th>nom_subsistema</th>\n",
              "      <th>id_estado</th>\n",
              "      <th>nom_estado</th>\n",
              "      <th>cod_modalidadeoperacao</th>\n",
              "      <th>nom_tipousina</th>\n",
              "      <th>nom_tipocombustivel</th>\n",
              "      <th>nom_usina</th>\n",
              "      <th>ceg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>463248</td>\n",
              "      <td>463248</td>\n",
              "      <td>463248</td>\n",
              "      <td>463248</td>\n",
              "      <td>463248</td>\n",
              "      <td>463248</td>\n",
              "      <td>463248</td>\n",
              "      <td>462504</td>\n",
              "      <td>463248</td>\n",
              "      <td>463248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>744</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>28</td>\n",
              "      <td>28</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>623</td>\n",
              "      <td>343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>2023-01-31 23:00:00</td>\n",
              "      <td>NE</td>\n",
              "      <td>NORDESTE</td>\n",
              "      <td>BA</td>\n",
              "      <td>BAHIA</td>\n",
              "      <td>TIPO I</td>\n",
              "      <td>HIDROELÉTRICA</td>\n",
              "      <td>Hidráulica</td>\n",
              "      <td>São José</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>625</td>\n",
              "      <td>188544</td>\n",
              "      <td>188544</td>\n",
              "      <td>58776</td>\n",
              "      <td>58776</td>\n",
              "      <td>188976</td>\n",
              "      <td>154752</td>\n",
              "      <td>154752</td>\n",
              "      <td>1488</td>\n",
              "      <td>203904</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3bc16a80-0e6c-441c-9c36-b9c469fa9b88')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3bc16a80-0e6c-441c-9c36-b9c469fa9b88 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3bc16a80-0e6c-441c-9c36-b9c469fa9b88');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "geracao2023.describe(include=[object])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "geracao2023['nom_tipousina'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02llplPJum3q",
        "outputId": "f951316a-d4c4-4827-b9c3-cfc1b79fa084"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['HIDROELÉTRICA', 'TÉRMICA', 'EOLIELÉTRICA', 'FOTOVOLTAICA',\n",
              "       'NUCLEAR'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "geracao2023[(geracao2023['nom_tipousina']=='EOLIELÉTRICA')].describe(include=[object])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "4Gmm58yIuMdb",
        "outputId": "94be80d3-fb00-44e5-8882-67bd7ede6e01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               din_instante id_subsistema nom_subsistema id_estado  \\\n",
              "count                122328        122328         122328    122328   \n",
              "unique                  744             4              4        12   \n",
              "top     2023-01-31 23:00:00            NE       NORDESTE        RN   \n",
              "freq                    165        108936         108936     39744   \n",
              "\n",
              "                 nom_estado cod_modalidadeoperacao nom_tipousina  \\\n",
              "count                122328                 122328        122328   \n",
              "unique                   12                      4             1   \n",
              "top     RIO GRANDE DO NORTE     Conjunto de Usinas  EOLIELÉTRICA   \n",
              "freq                  39744                 102984        122328   \n",
              "\n",
              "       nom_tipocombustivel            nom_usina     ceg  \n",
              "count               122328               122328  122328  \n",
              "unique                   2                  165      13  \n",
              "top                 Eólica  Conj. Paulino Neves       -  \n",
              "freq                121584                  744  113400  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0f83effa-fee6-4e1e-9713-95c448a920a9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>din_instante</th>\n",
              "      <th>id_subsistema</th>\n",
              "      <th>nom_subsistema</th>\n",
              "      <th>id_estado</th>\n",
              "      <th>nom_estado</th>\n",
              "      <th>cod_modalidadeoperacao</th>\n",
              "      <th>nom_tipousina</th>\n",
              "      <th>nom_tipocombustivel</th>\n",
              "      <th>nom_usina</th>\n",
              "      <th>ceg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>122328</td>\n",
              "      <td>122328</td>\n",
              "      <td>122328</td>\n",
              "      <td>122328</td>\n",
              "      <td>122328</td>\n",
              "      <td>122328</td>\n",
              "      <td>122328</td>\n",
              "      <td>122328</td>\n",
              "      <td>122328</td>\n",
              "      <td>122328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>744</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>165</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>2023-01-31 23:00:00</td>\n",
              "      <td>NE</td>\n",
              "      <td>NORDESTE</td>\n",
              "      <td>RN</td>\n",
              "      <td>RIO GRANDE DO NORTE</td>\n",
              "      <td>Conjunto de Usinas</td>\n",
              "      <td>EOLIELÉTRICA</td>\n",
              "      <td>Eólica</td>\n",
              "      <td>Conj. Paulino Neves</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>165</td>\n",
              "      <td>108936</td>\n",
              "      <td>108936</td>\n",
              "      <td>39744</td>\n",
              "      <td>39744</td>\n",
              "      <td>102984</td>\n",
              "      <td>122328</td>\n",
              "      <td>121584</td>\n",
              "      <td>744</td>\n",
              "      <td>113400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f83effa-fee6-4e1e-9713-95c448a920a9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0f83effa-fee6-4e1e-9713-95c448a920a9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0f83effa-fee6-4e1e-9713-95c448a920a9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dados de geração do nordeste em Janeiro de 2023"
      ],
      "metadata": {
        "id": "34b5XpB9f4J9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoqSkSUdN0bi"
      },
      "outputs": [],
      "source": [
        "geracaoNE = geracao2023[(geracao2023['id_subsistema']=='NE')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IETd4BYlvxTs"
      },
      "outputs": [],
      "source": [
        "geracaoNE = geracaoNE[['din_instante','val_geracao']].sort_values(by='din_instante')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "geracaoNE=geracaoNE.groupby(by='din_instante').sum()"
      ],
      "metadata": {
        "id": "CUHPamqn0oFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6j5XHJUCFQkq",
        "outputId": "1c2807f7-fa0f-4b4a-aec4-9244b86fca36"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "val_geracao    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "geracaoNE.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "srpaXOn7f4wy",
        "outputId": "3907b86a-2037-4a58-be72-ea7fce5dd8f9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"d9e50058-1a41-4eb2-8da2-26c60319a26c\" class=\"plotly-graph-div\" style=\"height:800px; width:1500px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d9e50058-1a41-4eb2-8da2-26c60319a26c\")) {                    Plotly.newPlot(                        \"d9e50058-1a41-4eb2-8da2-26c60319a26c\",                        [{\"x\":[\"2023-01-01 00:00:00\",\"2023-01-01 01:00:00\",\"2023-01-01 02:00:00\",\"2023-01-01 03:00:00\",\"2023-01-01 04:00:00\",\"2023-01-01 05:00:00\",\"2023-01-01 06:00:00\",\"2023-01-01 07:00:00\",\"2023-01-01 08:00:00\",\"2023-01-01 09:00:00\",\"2023-01-01 10:00:00\",\"2023-01-01 11:00:00\",\"2023-01-01 12:00:00\",\"2023-01-01 13:00:00\",\"2023-01-01 14:00:00\",\"2023-01-01 15:00:00\",\"2023-01-01 16:00:00\",\"2023-01-01 17:00:00\",\"2023-01-01 18:00:00\",\"2023-01-01 19:00:00\",\"2023-01-01 20:00:00\",\"2023-01-01 21:00:00\",\"2023-01-01 22:00:00\",\"2023-01-01 23:00:00\",\"2023-01-02 00:00:00\",\"2023-01-02 01:00:00\",\"2023-01-02 02:00:00\",\"2023-01-02 03:00:00\",\"2023-01-02 04:00:00\",\"2023-01-02 05:00:00\",\"2023-01-02 06:00:00\",\"2023-01-02 07:00:00\",\"2023-01-02 08:00:00\",\"2023-01-02 09:00:00\",\"2023-01-02 10:00:00\",\"2023-01-02 11:00:00\",\"2023-01-02 12:00:00\",\"2023-01-02 13:00:00\",\"2023-01-02 14:00:00\",\"2023-01-02 15:00:00\",\"2023-01-02 16:00:00\",\"2023-01-02 17:00:00\",\"2023-01-02 18:00:00\",\"2023-01-02 19:00:00\",\"2023-01-02 20:00:00\",\"2023-01-02 21:00:00\",\"2023-01-02 22:00:00\",\"2023-01-02 23:00:00\",\"2023-01-03 00:00:00\",\"2023-01-03 01:00:00\",\"2023-01-03 02:00:00\",\"2023-01-03 03:00:00\",\"2023-01-03 04:00:00\",\"2023-01-03 05:00:00\",\"2023-01-03 06:00:00\",\"2023-01-03 07:00:00\",\"2023-01-03 08:00:00\",\"2023-01-03 09:00:00\",\"2023-01-03 10:00:00\",\"2023-01-03 11:00:00\",\"2023-01-03 12:00:00\",\"2023-01-03 13:00:00\",\"2023-01-03 14:00:00\",\"2023-01-03 15:00:00\",\"2023-01-03 16:00:00\",\"2023-01-03 17:00:00\",\"2023-01-03 18:00:00\",\"2023-01-03 19:00:00\",\"2023-01-03 20:00:00\",\"2023-01-03 21:00:00\",\"2023-01-03 22:00:00\",\"2023-01-03 23:00:00\",\"2023-01-04 00:00:00\",\"2023-01-04 01:00:00\",\"2023-01-04 02:00:00\",\"2023-01-04 03:00:00\",\"2023-01-04 04:00:00\",\"2023-01-04 05:00:00\",\"2023-01-04 06:00:00\",\"2023-01-04 07:00:00\",\"2023-01-04 08:00:00\",\"2023-01-04 09:00:00\",\"2023-01-04 10:00:00\",\"2023-01-04 11:00:00\",\"2023-01-04 12:00:00\",\"2023-01-04 13:00:00\",\"2023-01-04 14:00:00\",\"2023-01-04 15:00:00\",\"2023-01-04 16:00:00\",\"2023-01-04 17:00:00\",\"2023-01-04 18:00:00\",\"2023-01-04 19:00:00\",\"2023-01-04 20:00:00\",\"2023-01-04 21:00:00\",\"2023-01-04 22:00:00\",\"2023-01-04 23:00:00\",\"2023-01-05 00:00:00\",\"2023-01-05 01:00:00\",\"2023-01-05 02:00:00\",\"2023-01-05 03:00:00\",\"2023-01-05 04:00:00\",\"2023-01-05 05:00:00\",\"2023-01-05 06:00:00\",\"2023-01-05 07:00:00\",\"2023-01-05 08:00:00\",\"2023-01-05 09:00:00\",\"2023-01-05 10:00:00\",\"2023-01-05 11:00:00\",\"2023-01-05 12:00:00\",\"2023-01-05 13:00:00\",\"2023-01-05 14:00:00\",\"2023-01-05 15:00:00\",\"2023-01-05 16:00:00\",\"2023-01-05 17:00:00\",\"2023-01-05 18:00:00\",\"2023-01-05 19:00:00\",\"2023-01-05 20:00:00\",\"2023-01-05 21:00:00\",\"2023-01-05 22:00:00\",\"2023-01-05 23:00:00\",\"2023-01-06 00:00:00\",\"2023-01-06 01:00:00\",\"2023-01-06 02:00:00\",\"2023-01-06 03:00:00\",\"2023-01-06 04:00:00\",\"2023-01-06 05:00:00\",\"2023-01-06 06:00:00\",\"2023-01-06 07:00:00\",\"2023-01-06 08:00:00\",\"2023-01-06 09:00:00\",\"2023-01-06 10:00:00\",\"2023-01-06 11:00:00\",\"2023-01-06 12:00:00\",\"2023-01-06 13:00:00\",\"2023-01-06 14:00:00\",\"2023-01-06 15:00:00\",\"2023-01-06 16:00:00\",\"2023-01-06 17:00:00\",\"2023-01-06 18:00:00\",\"2023-01-06 19:00:00\",\"2023-01-06 20:00:00\",\"2023-01-06 21:00:00\",\"2023-01-06 22:00:00\",\"2023-01-06 23:00:00\",\"2023-01-07 00:00:00\",\"2023-01-07 01:00:00\",\"2023-01-07 02:00:00\",\"2023-01-07 03:00:00\",\"2023-01-07 04:00:00\",\"2023-01-07 05:00:00\",\"2023-01-07 06:00:00\",\"2023-01-07 07:00:00\",\"2023-01-07 08:00:00\",\"2023-01-07 09:00:00\",\"2023-01-07 10:00:00\",\"2023-01-07 11:00:00\",\"2023-01-07 12:00:00\",\"2023-01-07 13:00:00\",\"2023-01-07 14:00:00\",\"2023-01-07 15:00:00\",\"2023-01-07 16:00:00\",\"2023-01-07 17:00:00\",\"2023-01-07 18:00:00\",\"2023-01-07 19:00:00\",\"2023-01-07 20:00:00\",\"2023-01-07 21:00:00\",\"2023-01-07 22:00:00\",\"2023-01-07 23:00:00\",\"2023-01-08 00:00:00\",\"2023-01-08 01:00:00\",\"2023-01-08 02:00:00\",\"2023-01-08 03:00:00\",\"2023-01-08 04:00:00\",\"2023-01-08 05:00:00\",\"2023-01-08 06:00:00\",\"2023-01-08 07:00:00\",\"2023-01-08 08:00:00\",\"2023-01-08 09:00:00\",\"2023-01-08 10:00:00\",\"2023-01-08 11:00:00\",\"2023-01-08 12:00:00\",\"2023-01-08 13:00:00\",\"2023-01-08 14:00:00\",\"2023-01-08 15:00:00\",\"2023-01-08 16:00:00\",\"2023-01-08 17:00:00\",\"2023-01-08 18:00:00\",\"2023-01-08 19:00:00\",\"2023-01-08 20:00:00\",\"2023-01-08 21:00:00\",\"2023-01-08 22:00:00\",\"2023-01-08 23:00:00\",\"2023-01-09 00:00:00\",\"2023-01-09 01:00:00\",\"2023-01-09 02:00:00\",\"2023-01-09 03:00:00\",\"2023-01-09 04:00:00\",\"2023-01-09 05:00:00\",\"2023-01-09 06:00:00\",\"2023-01-09 07:00:00\",\"2023-01-09 08:00:00\",\"2023-01-09 09:00:00\",\"2023-01-09 10:00:00\",\"2023-01-09 11:00:00\",\"2023-01-09 12:00:00\",\"2023-01-09 13:00:00\",\"2023-01-09 14:00:00\",\"2023-01-09 15:00:00\",\"2023-01-09 16:00:00\",\"2023-01-09 17:00:00\",\"2023-01-09 18:00:00\",\"2023-01-09 19:00:00\",\"2023-01-09 20:00:00\",\"2023-01-09 21:00:00\",\"2023-01-09 22:00:00\",\"2023-01-09 23:00:00\",\"2023-01-10 00:00:00\",\"2023-01-10 01:00:00\",\"2023-01-10 02:00:00\",\"2023-01-10 03:00:00\",\"2023-01-10 04:00:00\",\"2023-01-10 05:00:00\",\"2023-01-10 06:00:00\",\"2023-01-10 07:00:00\",\"2023-01-10 08:00:00\",\"2023-01-10 09:00:00\",\"2023-01-10 10:00:00\",\"2023-01-10 11:00:00\",\"2023-01-10 12:00:00\",\"2023-01-10 13:00:00\",\"2023-01-10 14:00:00\",\"2023-01-10 15:00:00\",\"2023-01-10 16:00:00\",\"2023-01-10 17:00:00\",\"2023-01-10 18:00:00\",\"2023-01-10 19:00:00\",\"2023-01-10 20:00:00\",\"2023-01-10 21:00:00\",\"2023-01-10 22:00:00\",\"2023-01-10 23:00:00\",\"2023-01-11 00:00:00\",\"2023-01-11 01:00:00\",\"2023-01-11 02:00:00\",\"2023-01-11 03:00:00\",\"2023-01-11 04:00:00\",\"2023-01-11 05:00:00\",\"2023-01-11 06:00:00\",\"2023-01-11 07:00:00\",\"2023-01-11 08:00:00\",\"2023-01-11 09:00:00\",\"2023-01-11 10:00:00\",\"2023-01-11 11:00:00\",\"2023-01-11 12:00:00\",\"2023-01-11 13:00:00\",\"2023-01-11 14:00:00\",\"2023-01-11 15:00:00\",\"2023-01-11 16:00:00\",\"2023-01-11 17:00:00\",\"2023-01-11 18:00:00\",\"2023-01-11 19:00:00\",\"2023-01-11 20:00:00\",\"2023-01-11 21:00:00\",\"2023-01-11 22:00:00\",\"2023-01-11 23:00:00\",\"2023-01-12 00:00:00\",\"2023-01-12 01:00:00\",\"2023-01-12 02:00:00\",\"2023-01-12 03:00:00\",\"2023-01-12 04:00:00\",\"2023-01-12 05:00:00\",\"2023-01-12 06:00:00\",\"2023-01-12 07:00:00\",\"2023-01-12 08:00:00\",\"2023-01-12 09:00:00\",\"2023-01-12 10:00:00\",\"2023-01-12 11:00:00\",\"2023-01-12 12:00:00\",\"2023-01-12 13:00:00\",\"2023-01-12 14:00:00\",\"2023-01-12 15:00:00\",\"2023-01-12 16:00:00\",\"2023-01-12 17:00:00\",\"2023-01-12 18:00:00\",\"2023-01-12 19:00:00\",\"2023-01-12 20:00:00\",\"2023-01-12 21:00:00\",\"2023-01-12 22:00:00\",\"2023-01-12 23:00:00\",\"2023-01-13 00:00:00\",\"2023-01-13 01:00:00\",\"2023-01-13 02:00:00\",\"2023-01-13 03:00:00\",\"2023-01-13 04:00:00\",\"2023-01-13 05:00:00\",\"2023-01-13 06:00:00\",\"2023-01-13 07:00:00\",\"2023-01-13 08:00:00\",\"2023-01-13 09:00:00\",\"2023-01-13 10:00:00\",\"2023-01-13 11:00:00\",\"2023-01-13 12:00:00\",\"2023-01-13 13:00:00\",\"2023-01-13 14:00:00\",\"2023-01-13 15:00:00\",\"2023-01-13 16:00:00\",\"2023-01-13 17:00:00\",\"2023-01-13 18:00:00\",\"2023-01-13 19:00:00\",\"2023-01-13 20:00:00\",\"2023-01-13 21:00:00\",\"2023-01-13 22:00:00\",\"2023-01-13 23:00:00\",\"2023-01-14 00:00:00\",\"2023-01-14 01:00:00\",\"2023-01-14 02:00:00\",\"2023-01-14 03:00:00\",\"2023-01-14 04:00:00\",\"2023-01-14 05:00:00\",\"2023-01-14 06:00:00\",\"2023-01-14 07:00:00\",\"2023-01-14 08:00:00\",\"2023-01-14 09:00:00\",\"2023-01-14 10:00:00\",\"2023-01-14 11:00:00\",\"2023-01-14 12:00:00\",\"2023-01-14 13:00:00\",\"2023-01-14 14:00:00\",\"2023-01-14 15:00:00\",\"2023-01-14 16:00:00\",\"2023-01-14 17:00:00\",\"2023-01-14 18:00:00\",\"2023-01-14 19:00:00\",\"2023-01-14 20:00:00\",\"2023-01-14 21:00:00\",\"2023-01-14 22:00:00\",\"2023-01-14 23:00:00\",\"2023-01-15 00:00:00\",\"2023-01-15 01:00:00\",\"2023-01-15 02:00:00\",\"2023-01-15 03:00:00\",\"2023-01-15 04:00:00\",\"2023-01-15 05:00:00\",\"2023-01-15 06:00:00\",\"2023-01-15 07:00:00\",\"2023-01-15 08:00:00\",\"2023-01-15 09:00:00\",\"2023-01-15 10:00:00\",\"2023-01-15 11:00:00\",\"2023-01-15 12:00:00\",\"2023-01-15 13:00:00\",\"2023-01-15 14:00:00\",\"2023-01-15 15:00:00\",\"2023-01-15 16:00:00\",\"2023-01-15 17:00:00\",\"2023-01-15 18:00:00\",\"2023-01-15 19:00:00\",\"2023-01-15 20:00:00\",\"2023-01-15 21:00:00\",\"2023-01-15 22:00:00\",\"2023-01-15 23:00:00\",\"2023-01-16 00:00:00\",\"2023-01-16 01:00:00\",\"2023-01-16 02:00:00\",\"2023-01-16 03:00:00\",\"2023-01-16 04:00:00\",\"2023-01-16 05:00:00\",\"2023-01-16 06:00:00\",\"2023-01-16 07:00:00\",\"2023-01-16 08:00:00\",\"2023-01-16 09:00:00\",\"2023-01-16 10:00:00\",\"2023-01-16 11:00:00\",\"2023-01-16 12:00:00\",\"2023-01-16 13:00:00\",\"2023-01-16 14:00:00\",\"2023-01-16 15:00:00\",\"2023-01-16 16:00:00\",\"2023-01-16 17:00:00\",\"2023-01-16 18:00:00\",\"2023-01-16 19:00:00\",\"2023-01-16 20:00:00\",\"2023-01-16 21:00:00\",\"2023-01-16 22:00:00\",\"2023-01-16 23:00:00\",\"2023-01-17 00:00:00\",\"2023-01-17 01:00:00\",\"2023-01-17 02:00:00\",\"2023-01-17 03:00:00\",\"2023-01-17 04:00:00\",\"2023-01-17 05:00:00\",\"2023-01-17 06:00:00\",\"2023-01-17 07:00:00\",\"2023-01-17 08:00:00\",\"2023-01-17 09:00:00\",\"2023-01-17 10:00:00\",\"2023-01-17 11:00:00\",\"2023-01-17 12:00:00\",\"2023-01-17 13:00:00\",\"2023-01-17 14:00:00\",\"2023-01-17 15:00:00\",\"2023-01-17 16:00:00\",\"2023-01-17 17:00:00\",\"2023-01-17 18:00:00\",\"2023-01-17 19:00:00\",\"2023-01-17 20:00:00\",\"2023-01-17 21:00:00\",\"2023-01-17 22:00:00\",\"2023-01-17 23:00:00\",\"2023-01-18 00:00:00\",\"2023-01-18 01:00:00\",\"2023-01-18 02:00:00\",\"2023-01-18 03:00:00\",\"2023-01-18 04:00:00\",\"2023-01-18 05:00:00\",\"2023-01-18 06:00:00\",\"2023-01-18 07:00:00\",\"2023-01-18 08:00:00\",\"2023-01-18 09:00:00\",\"2023-01-18 10:00:00\",\"2023-01-18 11:00:00\",\"2023-01-18 12:00:00\",\"2023-01-18 13:00:00\",\"2023-01-18 14:00:00\",\"2023-01-18 15:00:00\",\"2023-01-18 16:00:00\",\"2023-01-18 17:00:00\",\"2023-01-18 18:00:00\",\"2023-01-18 19:00:00\",\"2023-01-18 20:00:00\",\"2023-01-18 21:00:00\",\"2023-01-18 22:00:00\",\"2023-01-18 23:00:00\",\"2023-01-19 00:00:00\",\"2023-01-19 01:00:00\",\"2023-01-19 02:00:00\",\"2023-01-19 03:00:00\",\"2023-01-19 04:00:00\",\"2023-01-19 05:00:00\",\"2023-01-19 06:00:00\",\"2023-01-19 07:00:00\",\"2023-01-19 08:00:00\",\"2023-01-19 09:00:00\",\"2023-01-19 10:00:00\",\"2023-01-19 11:00:00\",\"2023-01-19 12:00:00\",\"2023-01-19 13:00:00\",\"2023-01-19 14:00:00\",\"2023-01-19 15:00:00\",\"2023-01-19 16:00:00\",\"2023-01-19 17:00:00\",\"2023-01-19 18:00:00\",\"2023-01-19 19:00:00\",\"2023-01-19 20:00:00\",\"2023-01-19 21:00:00\",\"2023-01-19 22:00:00\",\"2023-01-19 23:00:00\",\"2023-01-20 00:00:00\",\"2023-01-20 01:00:00\",\"2023-01-20 02:00:00\",\"2023-01-20 03:00:00\",\"2023-01-20 04:00:00\",\"2023-01-20 05:00:00\",\"2023-01-20 06:00:00\",\"2023-01-20 07:00:00\",\"2023-01-20 08:00:00\",\"2023-01-20 09:00:00\",\"2023-01-20 10:00:00\",\"2023-01-20 11:00:00\",\"2023-01-20 12:00:00\",\"2023-01-20 13:00:00\",\"2023-01-20 14:00:00\",\"2023-01-20 15:00:00\",\"2023-01-20 16:00:00\",\"2023-01-20 17:00:00\",\"2023-01-20 18:00:00\",\"2023-01-20 19:00:00\",\"2023-01-20 20:00:00\",\"2023-01-20 21:00:00\",\"2023-01-20 22:00:00\",\"2023-01-20 23:00:00\",\"2023-01-21 00:00:00\",\"2023-01-21 01:00:00\",\"2023-01-21 02:00:00\",\"2023-01-21 03:00:00\",\"2023-01-21 04:00:00\",\"2023-01-21 05:00:00\",\"2023-01-21 06:00:00\",\"2023-01-21 07:00:00\",\"2023-01-21 08:00:00\",\"2023-01-21 09:00:00\",\"2023-01-21 10:00:00\",\"2023-01-21 11:00:00\",\"2023-01-21 12:00:00\",\"2023-01-21 13:00:00\",\"2023-01-21 14:00:00\",\"2023-01-21 15:00:00\",\"2023-01-21 16:00:00\",\"2023-01-21 17:00:00\",\"2023-01-21 18:00:00\",\"2023-01-21 19:00:00\",\"2023-01-21 20:00:00\",\"2023-01-21 21:00:00\",\"2023-01-21 22:00:00\",\"2023-01-21 23:00:00\",\"2023-01-22 00:00:00\",\"2023-01-22 01:00:00\",\"2023-01-22 02:00:00\",\"2023-01-22 03:00:00\",\"2023-01-22 04:00:00\",\"2023-01-22 05:00:00\",\"2023-01-22 06:00:00\",\"2023-01-22 07:00:00\",\"2023-01-22 08:00:00\",\"2023-01-22 09:00:00\",\"2023-01-22 10:00:00\",\"2023-01-22 11:00:00\",\"2023-01-22 12:00:00\",\"2023-01-22 13:00:00\",\"2023-01-22 14:00:00\",\"2023-01-22 15:00:00\",\"2023-01-22 16:00:00\",\"2023-01-22 17:00:00\",\"2023-01-22 18:00:00\",\"2023-01-22 19:00:00\",\"2023-01-22 20:00:00\",\"2023-01-22 21:00:00\",\"2023-01-22 22:00:00\",\"2023-01-22 23:00:00\",\"2023-01-23 00:00:00\",\"2023-01-23 01:00:00\",\"2023-01-23 02:00:00\",\"2023-01-23 03:00:00\",\"2023-01-23 04:00:00\",\"2023-01-23 05:00:00\",\"2023-01-23 06:00:00\",\"2023-01-23 07:00:00\",\"2023-01-23 08:00:00\",\"2023-01-23 09:00:00\",\"2023-01-23 10:00:00\",\"2023-01-23 11:00:00\",\"2023-01-23 12:00:00\",\"2023-01-23 13:00:00\",\"2023-01-23 14:00:00\",\"2023-01-23 15:00:00\",\"2023-01-23 16:00:00\",\"2023-01-23 17:00:00\",\"2023-01-23 18:00:00\",\"2023-01-23 19:00:00\",\"2023-01-23 20:00:00\",\"2023-01-23 21:00:00\",\"2023-01-23 22:00:00\",\"2023-01-23 23:00:00\",\"2023-01-24 00:00:00\",\"2023-01-24 01:00:00\",\"2023-01-24 02:00:00\",\"2023-01-24 03:00:00\",\"2023-01-24 04:00:00\",\"2023-01-24 05:00:00\",\"2023-01-24 06:00:00\",\"2023-01-24 07:00:00\",\"2023-01-24 08:00:00\",\"2023-01-24 09:00:00\",\"2023-01-24 10:00:00\",\"2023-01-24 11:00:00\",\"2023-01-24 12:00:00\",\"2023-01-24 13:00:00\",\"2023-01-24 14:00:00\",\"2023-01-24 15:00:00\",\"2023-01-24 16:00:00\",\"2023-01-24 17:00:00\",\"2023-01-24 18:00:00\",\"2023-01-24 19:00:00\",\"2023-01-24 20:00:00\",\"2023-01-24 21:00:00\",\"2023-01-24 22:00:00\",\"2023-01-24 23:00:00\",\"2023-01-25 00:00:00\",\"2023-01-25 01:00:00\",\"2023-01-25 02:00:00\",\"2023-01-25 03:00:00\",\"2023-01-25 04:00:00\",\"2023-01-25 05:00:00\",\"2023-01-25 06:00:00\",\"2023-01-25 07:00:00\",\"2023-01-25 08:00:00\",\"2023-01-25 09:00:00\",\"2023-01-25 10:00:00\",\"2023-01-25 11:00:00\",\"2023-01-25 12:00:00\",\"2023-01-25 13:00:00\",\"2023-01-25 14:00:00\",\"2023-01-25 15:00:00\",\"2023-01-25 16:00:00\",\"2023-01-25 17:00:00\",\"2023-01-25 18:00:00\",\"2023-01-25 19:00:00\",\"2023-01-25 20:00:00\",\"2023-01-25 21:00:00\",\"2023-01-25 22:00:00\",\"2023-01-25 23:00:00\",\"2023-01-26 00:00:00\",\"2023-01-26 01:00:00\",\"2023-01-26 02:00:00\",\"2023-01-26 03:00:00\",\"2023-01-26 04:00:00\",\"2023-01-26 05:00:00\",\"2023-01-26 06:00:00\",\"2023-01-26 07:00:00\",\"2023-01-26 08:00:00\",\"2023-01-26 09:00:00\",\"2023-01-26 10:00:00\",\"2023-01-26 11:00:00\",\"2023-01-26 12:00:00\",\"2023-01-26 13:00:00\",\"2023-01-26 14:00:00\",\"2023-01-26 15:00:00\",\"2023-01-26 16:00:00\",\"2023-01-26 17:00:00\",\"2023-01-26 18:00:00\",\"2023-01-26 19:00:00\",\"2023-01-26 20:00:00\",\"2023-01-26 21:00:00\",\"2023-01-26 22:00:00\",\"2023-01-26 23:00:00\",\"2023-01-27 00:00:00\",\"2023-01-27 01:00:00\",\"2023-01-27 02:00:00\",\"2023-01-27 03:00:00\",\"2023-01-27 04:00:00\",\"2023-01-27 05:00:00\",\"2023-01-27 06:00:00\",\"2023-01-27 07:00:00\",\"2023-01-27 08:00:00\",\"2023-01-27 09:00:00\",\"2023-01-27 10:00:00\",\"2023-01-27 11:00:00\",\"2023-01-27 12:00:00\",\"2023-01-27 13:00:00\",\"2023-01-27 14:00:00\",\"2023-01-27 15:00:00\",\"2023-01-27 16:00:00\",\"2023-01-27 17:00:00\",\"2023-01-27 18:00:00\",\"2023-01-27 19:00:00\",\"2023-01-27 20:00:00\",\"2023-01-27 21:00:00\",\"2023-01-27 22:00:00\",\"2023-01-27 23:00:00\",\"2023-01-28 00:00:00\",\"2023-01-28 01:00:00\",\"2023-01-28 02:00:00\",\"2023-01-28 03:00:00\",\"2023-01-28 04:00:00\",\"2023-01-28 05:00:00\",\"2023-01-28 06:00:00\",\"2023-01-28 07:00:00\",\"2023-01-28 08:00:00\",\"2023-01-28 09:00:00\",\"2023-01-28 10:00:00\",\"2023-01-28 11:00:00\",\"2023-01-28 12:00:00\",\"2023-01-28 13:00:00\",\"2023-01-28 14:00:00\",\"2023-01-28 15:00:00\",\"2023-01-28 16:00:00\",\"2023-01-28 17:00:00\",\"2023-01-28 18:00:00\",\"2023-01-28 19:00:00\",\"2023-01-28 20:00:00\",\"2023-01-28 21:00:00\",\"2023-01-28 22:00:00\",\"2023-01-28 23:00:00\",\"2023-01-29 00:00:00\",\"2023-01-29 01:00:00\",\"2023-01-29 02:00:00\",\"2023-01-29 03:00:00\",\"2023-01-29 04:00:00\",\"2023-01-29 05:00:00\",\"2023-01-29 06:00:00\",\"2023-01-29 07:00:00\",\"2023-01-29 08:00:00\",\"2023-01-29 09:00:00\",\"2023-01-29 10:00:00\",\"2023-01-29 11:00:00\",\"2023-01-29 12:00:00\",\"2023-01-29 13:00:00\",\"2023-01-29 14:00:00\",\"2023-01-29 15:00:00\",\"2023-01-29 16:00:00\",\"2023-01-29 17:00:00\",\"2023-01-29 18:00:00\",\"2023-01-29 19:00:00\",\"2023-01-29 20:00:00\",\"2023-01-29 21:00:00\",\"2023-01-29 22:00:00\",\"2023-01-29 23:00:00\",\"2023-01-30 00:00:00\",\"2023-01-30 01:00:00\",\"2023-01-30 02:00:00\",\"2023-01-30 03:00:00\",\"2023-01-30 04:00:00\",\"2023-01-30 05:00:00\",\"2023-01-30 06:00:00\",\"2023-01-30 07:00:00\",\"2023-01-30 08:00:00\",\"2023-01-30 09:00:00\",\"2023-01-30 10:00:00\",\"2023-01-30 11:00:00\",\"2023-01-30 12:00:00\",\"2023-01-30 13:00:00\",\"2023-01-30 14:00:00\",\"2023-01-30 15:00:00\",\"2023-01-30 16:00:00\",\"2023-01-30 17:00:00\",\"2023-01-30 18:00:00\",\"2023-01-30 19:00:00\",\"2023-01-30 20:00:00\",\"2023-01-30 21:00:00\",\"2023-01-30 22:00:00\",\"2023-01-30 23:00:00\",\"2023-01-31 00:00:00\",\"2023-01-31 01:00:00\",\"2023-01-31 02:00:00\",\"2023-01-31 03:00:00\",\"2023-01-31 04:00:00\",\"2023-01-31 05:00:00\",\"2023-01-31 06:00:00\",\"2023-01-31 07:00:00\",\"2023-01-31 08:00:00\",\"2023-01-31 09:00:00\",\"2023-01-31 10:00:00\",\"2023-01-31 11:00:00\",\"2023-01-31 12:00:00\",\"2023-01-31 13:00:00\",\"2023-01-31 14:00:00\",\"2023-01-31 15:00:00\",\"2023-01-31 16:00:00\",\"2023-01-31 17:00:00\",\"2023-01-31 18:00:00\",\"2023-01-31 19:00:00\",\"2023-01-31 20:00:00\",\"2023-01-31 21:00:00\",\"2023-01-31 22:00:00\",\"2023-01-31 23:00:00\"],\"y\":[17858.329,17014.355,16066.001,15740.754,15634.053,15088.098,15042.398,16892.003,16803.626,15750.884,14640.759,14450.729,14120.324,14215.972,14863.414999999999,15072.082,14566.667,13286.535,13770.893,15621.855,16119.826000000001,16385.13,17057.45,17369.383,16547.233,15343.803,14470.098,14116.843,13307.893,12767.339,12795.861,14168.205,15336.96,15198.582,14226.66,13295.844,13121.577,13910.776,14268.631,13704.253,13979.771,13371.016,13078.467,14779.863,15678.499,16096.755,15798.962,15288.605,13276.197,11914.981,11623.124,10829.127,10396.027,10172.344000000001,10659.275,12164.792,13023.765,13632.844,13629.728000000001,13510.419,13420.302,13978.305,13793.336,13297.44,14103.946,14538.553,15383.792,15933.877,15554.172,15195.497,14744.105,13894.944,12913.164,11832.538,11252.711,11509.643,11213.356,10872.539,10764.102,11906.866,12602.92,12752.525,13195.112000000001,13189.233,13344.06,13503.563,13966.246,14826.203,14617.173999999999,13726.133,13537.747,14758.987,15101.463,14980.738,14671.492,14411.813,13212.892,13092.178,12860.875,12634.449,12373.296,11986.891,12404.852,14105.657,15786.166,14917.717,13733.793,13318.161,13250.889,13499.326000000001,14055.626,14869.901,14874.432,14132.919,13891.735999999999,14807.034,15009.601999999999,14166.556,13595.388,12792.182,10858.859,9708.041,9536.243,9600.308,9369.541,9332.535,9540.951000000001,10585.897,11629.151,11912.507,11655.476,11745.723,12375.211,12745.891,13603.624,13809.036,13842.074,12810.998,13225.507,14325.262,15069.682999999999,15563.785,15866.710000000001,15517.417,13681.003,12931.461,12658.318,12536.654,12371.592,12925.082,13633.071,15002.317000000001,15436.911,14389.455,13814.975,13771.431,13907.699999999999,14739.648,16495.953,16822.834,17044.509000000002,16654.393,16688.685,17520.935,18145.82,18227.03,18252.619,17984.999,16123.136,15136.735,15224.704,14326.954,13308.025,13268.148,13763.676,14502.389,15020.755,14037.880000000001,13248.26,12582.842,13717.908,13949.491,13730.266,13538.575,13002.528,12785.361,13057.181,13837.175,14445.272,14558.332,14726.228,14947.602,15243.298,15111.797999999999,14559.967,14170.979,13652.657000000001,13106.096,12899.976,14297.349,15851.533,14922.302,14063.851,13417.871,13246.065,13223.112000000001,14030.863,15205.618,16376.547999999999,15589.762,15472.651,16131.164,15908.392,15996.151,15803.293,15855.202000000001,15288.572,14220.282,13854.538,13946.159,13762.077,13560.012,14003.371000000001,15931.265,16191.946,15616.024,14918.51,13892.501,13671.619,13994.673999999999,14562.976,15195.966,15791.761,14706.839,15132.099,16448.57,16642.56,17011.346,16997.311,16123.741,14985.134,14384.398000000001,14453.130000000001,13859.455,12922.851,12589.637,12196.659,13713.777,14733.501,13737.032,12823.605,12543.054,12802.991,13367.526,13919.366,14379.613,14557.026,13479.720000000001,13481.23,14505.195,14823.982,15582.528,15443.945,15516.634,14595.864,14545.792,15217.559,15106.19,14709.185,14686.253,14999.742,16722.313,16535.242,15284.702,14026.507,13445.439,13162.787,13981.423,15106.639,16186.364,16896.878,15694.164,15795.033,16797.473,17523.850000000002,17457.04,17276.077,17146.125,15929.551,16020.234,16730.249,16663.172,16007.481,15479.006,15771.537,17049.315,17132.781,15610.063,14748.243,14427.124,14203.594000000001,14423.686,16239.047,17352.306,17408.008,16552.157,16557.333,17240.882,17506.499,17182.148,17644.343,17597.308,17021.492,17342.785,17077.78,17199.018,17185.636,17158.065000000002,17186.499,19330.546,19831.804,19182.26,18214.719,17391.644,17496.74,18357.401,18259.528,18431.485,18646.204,17860.001,18411.419,19822.299,20311.496,20876.803,20901.145,20820.5,20818.857,19792.421,18474.381,17480.573,16792.721,16667.17,17085.585,18697.653,18337.836,17306.508,15930.858,15474.414999999999,15657.894,15088.251,14930.938,15561.633,16359.236,16095.978,16527.862,18816.87,20332.414,20129.039,19389.408,18249.757,18061.375,18240.695,17674.441,16754.049,16171.642,15904.724,16008.196,18055.587,19848.728,19592.912,18748.122,18170.407,17592.735,17483.702,17353.331,17773.034,17890.25,16943.845,16022.658,16331.376,16927.555,17424.051,17463.961,17511.008,17856.48,17818.468,17560.193,17604.392,17802.979,18107.477,18158.679,20109.016,20985.734,20573.46,20698.58,20001.343,19429.597,19409.019,19041.894,19080.228,19026.072,17785.422,18924.169,20073.792,19904.363,19920.737,19752.41,19638.333,20072.572,20027.504,19026.255,18123.749,17610.436,17033.508,17123.757,18187.093,19482.452,18760.09,18503.435,17943.916,17735.363,17329.617,16357.841,16659.402000000002,16467.614,15125.21,15976.98,17371.577,18455.219,19002.644,19298.69,19176.184,17905.454,16676.952,15652.476,15119.298,14499.563,13823.348,13668.033,14224.407000000001,15296.14,15512.76,14896.295,14877.168,14784.632,15162.761,15817.432999999999,15903.593,15509.551,14406.894,14832.205,14766.356,14670.128,14648.036,14176.283,13264.354,12487.886999999999,12123.349,11540.122,11591.411,11803.172,11341.203,10875.548,11002.594,11293.998,11543.718,11565.544,11526.262,12078.071,12593.025,13735.901,13846.735,14087.332,13017.759,12973.836,13125.629,13193.631,13459.068,13108.792,13250.095,12633.441,11864.521,11468.765,11565.045,11345.401,11120.832,10938.774,10249.097,10629.867,10165.414,10483.236,11335.528,12345.636,12651.445,13653.553,14219.056,14025.688,13878.703,14005.088,13981.643,13587.841,13207.527,12465.354,11542.373,11225.906,11872.579,12746.275,12448.582,11825.559,11634.92,10668.975,9925.045,9571.11,9840.197,10105.946,10858.289,11192.875,11537.074,12407.079,12415.372,12255.557999999999,12621.523,12993.784,13522.2,13704.411,13673.907,12794.385,12000.489,11921.802,11575.891,11044.959,10996.648,10247.69,9887.099,9752.548,10324.333,10882.488,11623.238,12040.637999999999,12474.278,12905.554,13474.009,13816.807,14022.377,13623.846,12436.086,12422.724,12426.544,12426.1,12467.949,11984.289999999999,11397.083,10873.817000000001,10653.891,10082.507,9876.349,9919.169,10008.405999999999,10964.486,12502.592,13385.425000000001,13072.489,12921.154,12749.62,13211.633,14420.295,16348.282,16418.497,16193.886,15317.761,15041.94,15542.108,15227.152,14264.751,14150.083999999999,13868.646,12634.908,13061.533000000001,13021.333,12396.627,12396.092,12385.646999999999,12323.853,13566.088,14221.666000000001,13669.802,13158.831,13246.963,13524.754,14030.766,14398.289,15011.467999999999,15429.636,15410.827000000001,14680.138,15314.348,15642.747,15687.303,14888.962,14068.314,13401.045,12624.912,11436.693,10587.756,10378.501,10577.82,10872.521,11937.764,12480.717,13052.175,12997.529,13281.268,13959.456,14125.536,14531.135,14532.599,14690.604,13756.228000000001,14027.529999999999,15378.799,15347.741,14863.948,14448.269,13576.409,12840.716,12724.776,12543.57,13028.838,13370.1,13376.545,14163.961,15940.642,16472.361,16281.277,15963.659,15861.141,15954.748,15921.012,16231.270999999999,17254.628,16829.535,16028.05,16230.718,16574.9,17107.697,17477.168,18039.742,17776.113,17485.032,17227.542,16754.756,15979.864,15303.178,15816.309,15557.228,16558.608,18000.242,18566.434,18464.636,17904.372,17429.369,17283.6,18098.068,18850.54,18877.047,17713.501,17548.608,19260.854,20315.221,21038.742000000002,20793.863,21125.525999999998,20231.534,19566.44,18790.193,18149.262,17477.983,17068.437,16414.920000000002,17724.904,18184.542,16086.202000000001,14863.947,15491.422,15950.145,15854.585000000001,16401.001,16875.886,18345.649,18196.347,18140.693,19289.010000000002,19430.468,19206.916,19305.691,18521.828,18202.072,18521.369,18098.402,17385.175,17019.932,16461.920000000002,16335.3,18368.544,18568.911,17280.214,16049.617,15888.435,15286.694,15222.23,16026.112000000001,16407.298,17343.773,17047.096999999998,16736.032,17569.925,17803.375,18216.485,18048.576,17509.035,18287.667,18960.082,19127.99,18845.865,18517.888,18306.07,18571.203,19760.691,20491.693,19393.479,17922.774,17065.32,16430.075,16783.351,16971.262,16852.546,16911.046,16535.312,16781.443,17932.263,18710.107,19441.534,20316.084,19610.684],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"G\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"MWmed\"},\"height\":800,\"width\":1500},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d9e50058-1a41-4eb2-8da2-26c60319a26c');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig = go.Figure()\n",
        "fig = make_subplots(rows=1, cols=1,subplot_titles=(\"Geração\"))\n",
        "fig.add_trace(go.Scatter(x=geracaoNE.index, y=geracaoNE['val_geracao']),row=1,col=1)\n",
        "fig.update_layout(title='MWmed',height=800,width=1500)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hZQWg97XAUc"
      },
      "source": [
        "#Análise estatística de Séries temporais"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teste ADF ( Augmented Dickey - Fuller )"
      ],
      "metadata": {
        "id": "5vEyXSV2iPgB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## O teste ADF (Augmented Dickey-Fuller) é um teste estatístico utilizado para determinar se uma série temporal é estacionária ou não estacionária. Ele é comumente utilizado em econometria, finanças e outras áreas que lidam com dados de séries temporais. O termo \"augmented\" no nome do teste se refere ao fato de que ele é uma extensão do teste Dickey-Fuller original, que é um teste para verificar se uma série temporal tem uma raiz unitária. A adição de mais termos no modelo permite que o teste lide com mais tipos de séries temporais. A hipótese nula do teste ADF é que a série temporal possui uma raiz unitária, o que significa que ela não é estacionária. A hipótese alternativa é que a série não possui uma raiz unitária, o que significa que ela é estacionária. O teste usa uma estatística t para testar a significância estatística das diferenças entre os valores observados da série temporal e os valores que seriam esperados se a hipótese nula fosse verdadeira. Se o valor-p do teste ADF for menor do que um nível de significância pré-determinado, então a hipótese nula é rejeitada, indicando que a série temporal é estacionária. Se o valor-p for maior do que o nível de significância, a hipótese nula não é rejeitada, indicando que a série temporal é não-estacionária. \n",
        "## Teste de hipótese ADF\n",
        "##    H0: Possui raiz unitária ( não é estacionaria )\n",
        "##    H1: Não possui raiz unitaria "
      ],
      "metadata": {
        "id": "Xxmbz9ClgMxq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-rYM0PdEgD9",
        "outputId": "217d6c86-3066-4b10-bf73-95e521c6a61e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carga Norte p-valor: 0.7316677972052505\n"
          ]
        }
      ],
      "source": [
        "adf = adfuller(geracaoNE['val_geracao'])\n",
        "print(f'Carga Norte p-valor: {adf[1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## O p-valor indica que a hipótese nula não pode ser rejeitada."
      ],
      "metadata": {
        "id": "CucGKb-qiYeB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autocorrelação e Autocorrelação parcial"
      ],
      "metadata": {
        "id": "Qg-u39uQi8GQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A autocorrelação mede a correlação linear entre valores de uma série temporal em diferentes pontos no tempo. Em outras palavras, a autocorrelação mede a correlação entre um valor observado e um valor observado em um determinado número de períodos anteriores (lag). Por exemplo, a autocorrelação de lag 1 mede a correlação entre um valor observado e o valor observado um período anterior. A autocorrelação parcial, por sua vez, mede a correlação linear entre dois valores da série temporal, controlando os efeitos de outras defasagens intermediárias. Em outras palavras, a autocorrelação parcial de lag k mede a correlação entre um valor observado e o valor observado k períodos antes, levando em consideração o efeito das defasagens intermediárias. A autocorrelação e a autocorrelação parcial são comumente usadas para analisar a estrutura da série temporal e ajudar na seleção de modelos adequados para a previsão. Quando uma série temporal apresenta autocorrelação significativa, isso indica que os valores da série temporal estão correlacionados e podem ser usados para prever valores futuros. No entanto, é importante levar em consideração a autocorrelação parcial para garantir que as relações entre os valores da série temporal sejam adequadamente modeladas e para evitar a superestimação da correlação entre as variáveis."
      ],
      "metadata": {
        "id": "Mn7Vr3KMjCOu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "id": "HHLZ82t_madv",
        "outputId": "1facaba6-2c24-4588-b801-3c9ffc2fe078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/statsmodels/graphics/tsaplots.py:348: FutureWarning:\n",
            "\n",
            "The default method 'yw' can produce PACF values outside of the [-1,1] interval. After 0.13, the default will change tounadjusted Yule-Walker ('ywm'). You can use this method now by setting method='ywm'.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "dat = geracaoNE['val_geracao']\n",
        "fig = plt.figure(figsize=(12, 8))\n",
        "ax1 = fig.add_subplot(211)\n",
        "fig = sm.graphics.tsa.plot_acf(dat.squeeze(), lags=48, ax=ax1)\n",
        "ax2 = fig.add_subplot(212)\n",
        "fig = sm.graphics.tsa.plot_pacf(dat, lags=24, ax=ax2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo ARIMA"
      ],
      "metadata": {
        "id": "KRAOLuSQjWtK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## O modelo ARIMA (Autoregressive Integrated Moving Average) é um modelo estatístico utilizado para modelar séries temporais. Ele é uma combinação de modelos autoregressivos (AR) e de médias móveis (MA) com um termo adicional de integração (I) para lidar com a não estacionariedade da série temporal.\n",
        "\n",
        "## O modelo ARIMA é composto por três parâmetros principais: p, d e q, que representam a ordem do modelo AR, a ordem de diferenciação e a ordem do modelo MA, respectivamente. O parâmetro p representa a ordem do modelo AR, que é o número de defasagens da série temporal que serão incluídas no modelo. Em outras palavras, o modelo AR assume que o valor atual da série temporal depende linearmente dos valores passados até um certo número de defasagens. O parâmetro q representa a ordem do modelo MA, que é o número de termos de média móvel que serão incluídos no modelo. O modelo MA assume que o valor atual da série temporal depende linearmente de um erro aleatório, que é uma combinação linear de erros passados até um certo número de defasagens. O parâmetro d representa a ordem de diferenciação, que é o número de vezes que a série temporal é diferenciada para torná-la estacionária. A diferenciação é realizada para remover tendências e sazonalidades da série temporal e torná-la estacionária.\n",
        "\n",
        "## Para seleção do modelo ARIMA adequado a nossa série temporal vamos utilizar um grid onde os parametros p,q e d variam de 0 a 2. Para avaliação será utilizad a métrica BIC."
      ],
      "metadata": {
        "id": "0QAJEbUljbje"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrtCm_SSiEGq",
        "outputId": "5f7dcbdf-0151-4928-c274-192b3b5c5c71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning:\n",
            "\n",
            "Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/statespace/sarimax.py:966: UserWarning:\n",
            "\n",
            "Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "p = d = q = range(0,3)\n",
        "pdq = list(itertools.product(p, d, q))\n",
        "bic_lista = []\n",
        "best_order = []\n",
        "min_ = 1e10\n",
        "for param in pdq:\n",
        "    mod = sm.tsa.statespace.SARIMAX(geracaoNE['val_geracao'], order=param)\n",
        "    results = mod.fit()\n",
        "    bic = round(results.bic,2)\n",
        "    if bic < min_ :\n",
        "        min_ = bic\n",
        "        best_order = 'ARIMA{} - BIC: {}'.format(param, bic)\n",
        "    bic_lista.append('ARIMA{} - BIC: {}'.format(param, bic))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pL9aAt0h8lxd",
        "outputId": "5dc2bcda-e31c-4351-ea4b-06020a05eeb5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ARIMA(0, 0, 0) - BIC: 16457.42',\n",
              " 'ARIMA(0, 0, 1) - BIC: 15458.55',\n",
              " 'ARIMA(0, 0, 2) - BIC: 14750.45',\n",
              " 'ARIMA(0, 1, 0) - BIC: 11858.32',\n",
              " 'ARIMA(0, 1, 1) - BIC: 11678.88',\n",
              " 'ARIMA(0, 1, 2) - BIC: 11684.92',\n",
              " 'ARIMA(0, 2, 0) - BIC: 11953.88',\n",
              " 'ARIMA(0, 2, 1) - BIC: 11885.68',\n",
              " 'ARIMA(0, 2, 2) - BIC: 11657.88',\n",
              " 'ARIMA(1, 0, 0) - BIC: 11887.09',\n",
              " 'ARIMA(1, 0, 1) - BIC: 11683.56',\n",
              " 'ARIMA(1, 0, 2) - BIC: 11689.91',\n",
              " 'ARIMA(1, 1, 0) - BIC: 11741.92',\n",
              " 'ARIMA(1, 1, 1) - BIC: 11685.17',\n",
              " 'ARIMA(1, 1, 2) - BIC: 11650.66',\n",
              " 'ARIMA(1, 2, 0) - BIC: 11956.96',\n",
              " 'ARIMA(1, 2, 1) - BIC: 11725.69',\n",
              " 'ARIMA(1, 2, 2) - BIC: 11663.8',\n",
              " 'ARIMA(2, 0, 0) - BIC: 11750.11',\n",
              " 'ARIMA(2, 0, 1) - BIC: 11689.97',\n",
              " 'ARIMA(2, 0, 2) - BIC: 11696.71',\n",
              " 'ARIMA(2, 1, 0) - BIC: 11677.56',\n",
              " 'ARIMA(2, 1, 1) - BIC: 11683.44',\n",
              " 'ARIMA(2, 1, 2) - BIC: 11651.96',\n",
              " 'ARIMA(2, 2, 0) - BIC: 11860.68',\n",
              " 'ARIMA(2, 2, 1) - BIC: 11657.51',\n",
              " 'ARIMA(2, 2, 2) - BIC: 11663.38']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "bic_lista"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## O modelo selecionado foi o ARIMA(1,1,2) com BIC = 11650.66"
      ],
      "metadata": {
        "id": "9PYAUBk3kZSP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZspOO5QANke",
        "outputId": "cc43389b-e100-4d1e-d43f-c8d4a6d4ed15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning:\n",
            "\n",
            "No frequency information was provided, so inferred frequency H will be used.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                               SARIMAX Results                                \n",
            "==============================================================================\n",
            "Dep. Variable:            val_geracao   No. Observations:                  744\n",
            "Model:                 ARIMA(1, 1, 2)   Log Likelihood               -5812.110\n",
            "Date:                Wed, 08 Mar 2023   AIC                          11632.220\n",
            "Time:                        19:29:41   BIC                          11650.663\n",
            "Sample:                    01-01-2023   HQIC                         11639.330\n",
            "                         - 01-31-2023                                         \n",
            "Covariance Type:                  opg                                         \n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "ar.L1          0.8125      0.035     23.110      0.000       0.744       0.881\n",
            "ma.L1         -0.3700      0.041     -9.049      0.000      -0.450      -0.290\n",
            "ma.L2         -0.5475      0.029    -19.106      0.000      -0.604      -0.491\n",
            "sigma2      3.531e+05   1.66e+04     21.241      0.000    3.21e+05    3.86e+05\n",
            "===================================================================================\n",
            "Ljung-Box (L1) (Q):                   3.07   Jarque-Bera (JB):                25.85\n",
            "Prob(Q):                              0.08   Prob(JB):                         0.00\n",
            "Heteroskedasticity (H):               0.80   Skew:                             0.26\n",
            "Prob(H) (two-sided):                  0.08   Kurtosis:                         3.75\n",
            "===================================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
          ]
        }
      ],
      "source": [
        "model = ARIMA(geracaoNE['val_geracao'], order=(1,1,2))\n",
        "model_fit = model.fit()\n",
        "print(model_fit.summary())#BIC: 11650.66'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Podemos também aplicar uma análise de diagnóstico aos resultados do modelo através de uma análise de residuos, verificando sua distribuição e autocorrelação."
      ],
      "metadata": {
        "id": "gbNxbgRskqFk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "sLgU8gHcA41p",
        "outputId": "c90723de-b210-4835-95e5-d4dd58867805"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x576 with 4 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA64AAAHwCAYAAACmHTLcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOydd5gURfrHv++kzSxpyTlnUBGMmMCcz5zzmU7P8wKed/c743l65nCKOZ5iRAVBRRETKAgoOSNLZoFdNk7o+v3RXT3V3dU9PZtmd6nP8/Cw011d9XaYnnrrTcQYg0KhUCgUCoVCoVAoFE2VQKYFUCgUCoVCoVAoFAqFwguluCoUCoVCoVAoFAqFokmjFFeFQqFQKBQKhUKhUDRplOKqUCgUCoVCoVAoFIomjVJcFQqFQqFQKBQKhULRpFGKq0KhUCgUCoVCoVAomjRKcVXssxDRkURUXI/9XUZE3wify4moT331b/Q5i4iuqs8+XcZxld1+nnUcZz0RjXfZl0NEHxFRKRG9XR/jKRQKhSIJES0hoiMzLUcmaazf1drSEHOJ+oKIGBH189n2n0T0WgPL8wkRXdqQYygyi1JcFRmFiA4jou8M5WQXEX1LRAca++pNQcoEjLF8xtjaTMtRG5qI7GcB6AigHWPs7Lp2ZixUzDL+9lXAmoheMp7Dy4jopbrKoFAoFI2FbGHQ/rvKGBvKGJuVop9ehoISaiBRFQYyJbqhfo+b+xxLBmPsBMbYy0DLPD+FUlwVGYSIWgH4GMDjANoC6ArgDgA1mZTLD83hB7w5yJiCngBWMsbi6R7YAs5doVAo9gnU+1qhUPhFKa6KTDIAABhj/2OMJRhjVYyxTxljPxPRYABPAzjYcJPZAwBEdBIRLSCiMiLaSET/5J0Jq8KXEtGvRLSTiG4X9ucYFrTdRLQUwIGiMEQ0kYjWENFeIlpKRGcI+y4zrMEPE1EJgH8SUTsi+tCQ5QcAfW39MSLqR0RdjHPg/ypFix8RXUFEywy5ZhBRT2HfBCJabliknwBAbhfTcMN5h4heI6IyAJcRUSERPU9EW4hoExHdTURBo30/IvrK6HsnEb1ll9342/U8ZSvx4ooxEfUloi+IqMQY43Uiau12DkIfdwD4B4BzjWt2JREFiOhvRLSBiLYT0StEVGiT40oi+hXAF6nGMI47l4jm2bbdQkQf+jleoVAomjOiVZaIxhDRPONdv42IHjKazTb+32O8jw/2eh8bfV1i7Cshor/bxpH9Vo0hou+JaI/xe/UEEUWE/hgRXU9Eq4zf6LuM35fvDHkni+1t58h/v58wfu+WE9ExLm0t7qz23zijr7WGDOuI6EKXfgKUnFOUGPK1NfZlG+deYpzvj0TUkYjuAXA4gCeM6/yEcO789/glInqKdJfYcuO8OhHRI6TPIZYT0X6CHNJ5DbnPsbKI6D+kz6G2EdHTRJQj9Pcn4/5sJqIrZOcutO1N+hxjLxF9BqC9bf9Bxv3bQ0SLSHBZJ30ecZdxfnuJ6FMiau91/YTjrpKdHxEdaJxTUBjnTCJa5HUeiiYGY0z9U/8y8g9AKwAlAF4GcAKANrb9lwH4xrbtSADDoS+6jACwDcDpxr5eABiAZwHkABgJ3Xo72Nh/H4CvoVt3uwNYDKBY6PtsAF2Mvs8FUAGgsyBLHMDvAISM/t8EMBlAHoBhADaJ8hqy9JOc9+sA/mf8fRqA1QAGG/3+DcB3xr72APZCd5kNA7jFkOEql+v5TwAxAKcb55AD4H0AzxgydgDwA4DfGu3/B+B2o202gMNksnudp3DNQ8Kxs7iMAPoBmAAgC0AR9AnQI0Lb9QDGe5zPa8LnK4xr1QdAPoD3ALxqk+MVQ84cn89grnGN+wvbfgRwXqa/H+qf+qf+qX91+Sd7v8L2uyq2AfA9gIuNv/MBHGT8LXvPe72PhwAoB3AYgAiA/xi/TXwc2W/VAQAOgv472AvAMgC/F8ZjAKZAnzcMhf7bPtMYvxDAUgCXulyHy6D/dt4C/bf0XAClANoa+8XfLPvvjnnuxm9LGYCBxr7OAIa6jHkzgDkAukH//XsGyd/93wL4yPj9CRrn3soui+3c+e/xSwB2GsdkQ1+kXQfgEqOvuwF8KRybal5jn2M9DOBD6POkAkPOfxn7joc+5xpmXIs34DLPEZ6nh4zzHwf9t/Y1Y19X6PO/Ew3ZJhifi4TrsAa6gSPH+HxfOtfP5fyWAjhB+Pw+gFsz/V1V//z/UxZXRcZgjJVB/2HjyuYO0i17HT2OmcUY+4UxpjHGfoaufB1ha3YH0623iwAsgq7AAsA5AO5hjO1ijG0E8Jit77cZY5uNvt8CsArAGKHJZsbY40x3XY0C+A2AfzDGKhhji6Er4J4Q0V8ADIL+ow8A10L/UVhm9HsvgFGkW11PBLCEMfYOYywG4BEAW1MM8T1j7APGmAb9B/5E6D/+FYyx7dB/lM4z2sagu+N2YYxVM8YcsSDGymTa58lhjK1mjH3GGKthjO2A/iNmv19+uRDAQ4yxtYyxcgC3ATiPrG5m/zTkrPIpXyX0ydD5AEBE/aHfH2VxVSgULYEPDGvTHsOq9pRH2xiAfkTUnjFWzhib49HW6318FoCPGGPfMMai0L1n7HkFzN8q4/d6PmNsDmMszhhbD13Rs/9W3M8YK2OMLYG+8PypMX4pgE8A7Ad3tkNfNI0Zv+8rAJzk0d4NDcAwIsphjG0xZJFxLYDbGWPFjLEa6ArxWcb1iQFoB13hSxjnXpaGDO8bx1RDV7yqGWOvMMYSAN6CcB18zGtMiIgAXAPgFmOetBf6nITPGc4B8CJjbDFjrMI4JylE1AO6V9vfjd//2dCVTc5FAKYxxqYZsn0GYB70OQvnRcbYSuP3fDKAUcb2uly/l42xYVjAj4OugCuaCUpxVWQUQ2G7jDHWDfoqXhfoCpoUIhpLRF8S0Q4iKoX+49De1kxU7iqhrwbD6HujsG+Dre9LiGih8AM/zNa3eGwR9BVY1/4ksp8AfRX2dEGx6gngUWHMXdDdgbva5WWMMdt4MsT9PaGvLm8R+n8GuuUVAP5sjPUD6ZklZW4/aZ+niOH+9CbpbsplAF6D8375pYtt7A2GbOJCR6rrI+MNGIorgAsAfGAotAqFQtHcOZ0x1pr/A3C9R9sroVu4lhvulyd7tPV6H9t/uyqhW9NELO9qIhpARB8T0Vbjt+JeOH8rtgl/V0k+58OdTcZvqChvF4/2Dgxl7Vzo844tRDSViAa5NO8J4H3ht3cZgAT06/MqgBkA3jRcbu8nonAaovi+Dj7mNSJF0K2Y84X2043tQIo5lI0uAHYb10zWvieAs22LKodBt2Jz3OZydbl+rwE4hYjyoCviXzPGtvg8VtEEUIqrosnAGFsO3Q1mGN8kafYGdGtYd8ZYIfQYBte4TxtboLsIc3rwPwwL57MAboSexbY19BVdsW9Rnh3QXY+k/dkhooHQV/rOMay9nI3QXXdbC/9yGGPf2eU1VkO7wxtRxo3Q3anaC323YowNBQDG2FbG2NWMsS7QXW+eImda+1TnyX+UcoVtnYS/7zVkGs4YawV9pdPv/bKzGfqPnShHHNYfbV/Zgm18BqCIiEZBV2DV6qtCodjnYIytYoydD31x898A3jEm+LL3qtf7eAt0F1kAen4J6BYyy3C2z/8FsBx62EYrAH9F7X8rZHQ1fkNFeTdL2lXA/fcMjLEZjLEJ0BWs5dDnDTI2QndJFX/bsxljmwyr7x2MsSEADgFwMnRXX6B2v2FSfMxr7GPthK74DhVkLmSMcYXRdQ4lYQuANsbzI2u/EbpruXh98hhj96U6rxTXz9JUcuwm6C7MZwK4GLoSrGhGKMVVkTGIaBAR3UpE3YzP3aErDtw9aRuAbmRNuFAAYBdjrJqIxkC3kPllMoDbiKiNMebvhH38x3mHIcvlSCrQDgyXnPegJ2nKJaIhAKS1w0jPnjwFutuQ3R33aUOmoUbbQiLipV+mAhhqJA8IAbgJth9RL4xVxE8BPEhErUhPFtGXiI4wxjqbX3sAu43z19I5T8P9dxOAi4goaFhtxSRVBdBjnUqJqCuAP/mVX8L/ANxCesKHfOhK8VusFlmHRZjuhv02gAegx/V8Vpf+FAqFojlCRBcRURHTQ032GJs16L+LGvR4Uo7X+/gd6FatQ4zf738itRJaAD1+tNywYl5XT6fF6QDgJiIKG7+xgwFMk7RbCGAcEfUgPdnUbXyH4UF0mqGM1UD/bdMkfQD6b/s9hvIIIioiotOMv48iouGkh+KUQXd95f1sg/U614VU8xrLHMu4788CeJiIOhjHdCWi44z2k6En0hpCRLkA/s9tYMbYBuiuv3cQUYSIDgNwitCEWz6PM+YO2aSXrOsm7VAgxfUTkc0hAT0Xxp+h50t5L9V4iqaFUlwVmWQvgLEA5hJRBXSFdTGAW439XwBYAmArEe00tl0P4E4i2gs9bmZyGuPdAd1VZR10hc5caWOMLQXwIPSVuG3QX2jfpujvRuiuK1uhW4pfdGm3P4CB0H8MzOzCxrjvQ1/ZftNwj1oMPVEVGGM7oSdWuA+6m1V/HzLZuQR6coyl0JXTd5B0xTkQ+rUvh27FvpnJa8WlOs+roSukJdCTZnwn7LvDOP9S6Ip4XX4kXoB+z2ZDv4fVsC4+1IU3AIwH8HZdFWGFQqFophwPYInxm/Ao9CR1VYar7z0AvjXcOg+Cx/vYiPv8HfTEflugK3jb4V3q7o/QF6L3Qlee3vJoWxvmQv8N3Wmcy1mMMbv7MoxYy7cA/AxgPvSSfZwAgD9At9Tugh6D66ZgPwr9d/VTY74yB/p8B9AXoN+BrnQtA/AVkvORR6HHwu4mosdQB3zMa2RzrL9AT7o1x5iTfA59/gLG2CfQQ7m+MNqkyt5/AfRz3gVdyX1FkG0j9OSUf4WuWG+EPo/wo5d4XT8R2fkBelxwT+ixwiosqJlBVpd/hUKhUCgUCoWifjAssnuguwGvy8D4l0HPNHtYY4+taJoQ0RroYVqfZ1oWRXooi6tCoVAoFAqFot4golOM8JI86OVwfoFeekehyChE9BvoLtS+6r0rmhah1E0UCoVCoVAoFArfnAbdfZOgxzqex5SLnyLDENEs6HWGLzZiehXNDOUqrFAoFAqFQqFQKBSKJo1yFVYoFAqFQqFQKBQKRZNGKa4KhUKhUCgUCoVCoWjSZDzG1ajDNA/AJsbYyV5t27dvz3r16tUocikUCoWi5TN//vydjLGiTMvRnFG/zQqFQqGoT9x+mzOuuAK4GXodplapGvbq1Qvz5s1reIkUCoVCsU9ARBsyLUNzR/02KxQKhaI+cfttzqirMBF1A3ASgOcyKYdCoVAoFAqFQqFQKJoumY5xfQTAnwG4pqQmomuIaB4RzduxY0ejCaZQKBQKhUKhUCgUiqZBxhRXIjoZwHbG2HyvdoyxSYyx0Yyx0UVFKgxJoVAoFAqFQqFQKPY1MhnjeiiAU4noRADZAFoR0WuMsYsyKJNCoVAoFAqFQqFQNBixWAzFxcWorq7OtCgZJTs7G926dUM4HPbVPmOKK2PsNgC3AQARHQngj0ppVSgUCoVCoVAoFC2Z4uJiFBQUoFevXiCiTIuTERhjKCkpQXFxMXr37u3rmEzHuCoUCoVCoVAoFArFPkN1dTXatWu3zyqtAEBEaNeuXVpW5yahuDLGZqWq4apQNEf+/M4ivDH310yLoVAo9jGI6HgiWkFEq4looke73xARI6LRwrbbjONWENFxjSOxQtGMqC4DFr0FrPkC2PMroLnmGFUoXNmXlVZOutegKdRxVShaLJPnFWPyvGJcMLZHpkVRKBT7CEQUBPAkgAkAigH8SEQfMsaW2toVQK+lPlfYNgTAeQCGAugC4HMiGsAYSzSW/ApFk2brL8DkS4Bda5PbQtlA2z76v3b99H/t+wPdDgQCwczJqlB4kJ+fj/LycvPzSy+9hHnz5uGJJ57A008/jdzcXFxyySXSY2fNmoVIJIJDDjmkscQFoBRXhUKhUChaGmMArGaMrQUAInoTwGkAltra3QXg3wD+JGw7DcCbjLEaAOuIaLXR3/cNLrVC0ZRhDFjwKjDtT0BOW+Cid4FgFlCyGti1BihZA+xcCaycAWgx/ZhehwPnvALkts2s7IomT3Usgexw/S1y1LW/a6+91nP/rFmzkJ+frxRXhUKhUCgUdaIrgI3C52IAY8UGRLQ/gO6MsalE9CfbsXNsx3ZtKEEVimZBtBKYeiuw6A2gz1HAb54D8trr+3ofbm2biAOlG4HVnwMz/go8ezRw/ptAh0GNL7ei2ZAdDqLXxKn11t/6+06q0/H//Oc/kZ+fjz/+8Y947LHH8PTTTyMUCmHIkCG477778PTTTyMYDOK1117D448/jsMPPzx1p/WAUlwVCoVCodiHIKIAgIcAXFaHPq4BcA0A9OihQiEULZidq3TX4O3LgCNvA8b9ydv9NxjCgvgeTCr7CXuGHqxbY6ecAbTpDWQXWpoObjcY1428DkW5RQ18EgqFk6qqKowaNcr8vGvXLpx66qmOdvfddx/WrVuHrKws7NmzB61bt8a1115rKraNiVJcFQqFQqFoWWwC0F343M3YxikAMAzALCMxRicAHxLRqT6OBQAwxiYBmAQAo0ePZvUpvELRZFj8LvDhTUAoS3cN7neMZ/PivcV4eP7D+HTDpyjKKcLAtgOB3HbA5oXAjpVA+wFAm54AgISWwPur38fHaz/GlcOuxKVDL0V2KLsRTkqh0MnJycHChQvNzzzG1c6IESNw4YUX4vTTT8fpp5/eeAJKUIqrQqFQKBQtix8B9Cei3tCVzvMAXMB3MsZKAbTnn4loFvRa6vOIqArAG0T0EPTkTP0B/NCIsisUmSdeA8y4HfjxWaD7WOCsF4FCd4/5vdG9ePaXZ/Ha0tcQCoRw/cjrcenQS5EbztUbRCuAD64HlnwAjOwJnPIIEMrCr2W/4uH5D+OJhU/gnVXv4Ob9b8aJvU9EgJpE0Q+FAgAwdepUzJ49Gx999BHuuece/PLLLxmTRX0zFIp9lCWbS/HI5yszLYZCoahnGGNxADcCmAFgGYDJjLElRHSnYVX1OnYJgMnQEzlNB3CDyiis2OeYcoOutB58I3DZVFelNa7FMXnFZJz8/sl4cfGLOKH3Cfjo9I9w3ajrkkorAETygLNfAo78qx4n+9LJwN5t6NGqBx4+6mG8cNwLaJPVBrd9fRsumnYRFmxf0DjnqVCkQNM0bNy4EUcddRT+/e9/o7S0FOXl5SgoKMDevXsbXR5lcVUo9lFOe+JbxDWGm4/pr2qJKRQtDMbYNADTbNv+4dL2SNvnewDc02DCKRRNmbWzgF/eBo74C3DUX12bfbPpG/znx/9gTekaHNDxADw1/ikMbTfUvV8i4Mi/AEUDgfevBZ49Sk/a1HkEDux0IN48+U18vPZjPDr/UVzyySU4tuexuOWAW9CtoFv9n6NC4ZNEIoGLLroIpaWlYIzhpptuQuvWrXHKKafgrLPOwpQpUxo1ORMx1nxCU0aPHs1kvtcKRVOFZ4ira3a3hoDLtvbeExEIKMVVsW9CRPMZY6MzLUdzRv02K1oM8Sjw9KFAIgpcPxcIy2NOn1n0DJ5Y+AS6F3THrQfciqN7HJ3eAvCWRcD/zgfi1cA1s4DWyQRnlbFKvLzkZby45EUAwHPHPocRRSPqclaKJsiyZcswePBg83NTK4fTmNivBeD+26xchRWKfRytGS1eKRQKhULRYMx5Uq/FesL9rkrrW8vfwhMLn8DJfU7GB6d9gGN6HpO+11LnkcAlU/TSOf87X4+BNcgN5+K6UddhymlT0C67Ha6feT3W7FlTl7NSNAPqW8lsLkpruijFVaHYx9GU3qpQKBSKfZ3SYuCr+4GBJwEDjpM2mb5uOu6Zew+O6HYE7jz0TkSCkdqP174/cPYLwPaluuuwpll2d87vjEnHTkI4EMY1n12DzeWbaz+WQtFCUIqrQrGPoyyuCoVCodjnmX4bwBhw/L+ku7/d9C1u++Y27NdhP/zniP8gHAjXfcx+44EJdwLLPgRmP+DY3b2gO54e/zSqYlX47We/RUlVSd3HVCiaMUpxVSj2cZTeqlAoFIp9mtWf68rjuFvNOqsii3Yswi2zbkHfwr54/JjH67fe6sE3AiPPB2bdCyz90LF7YNuBeOKYJ7C1Yiuu+/w6lEfL629shaKZkTHFlYiyiegHIlpEREuI6I5MyaJQ7MswKM1VoVAoFPso8Rpg2p+Btn2BQ25y7F69ezWu//x6tM9pj6cnPI1WkVb1Oz4RcPIjQNfRwPu/BbYudjTZv+P+ePDIB7Fq9yrc9OVNqEnU1K8MCkUzIZMW1xoARzPGRgIYBeB4Ijoog/IoFE2a6lgCf3nnZ+wsd/5gFe+uxM/Fe2rVr4pxVTR1fve/BZg0WyUnUSgUDcB3jwG71gAn3g+Esiy7NpVvwm8/+y2yglmYNGES2ue0bxgZwtnAea8D2YV6sqaKnY4m47qNw92H3Y0ft/6IP3/1Z8S1eMPIolA0YTKmuDId7u8QNv6pKbRC4cJHizbjrXkbcd8nyx37Dvv3lzj1iW9r1a+KcVU0dT5atBn3TnM+9wqFQlEndm8AZj8IDD5VjzcV2Fm1E9d8eg2qElV4ZsIzDV9PtaCTrryWbwMmX6KX5rFxUp+TMHHMRHyx8Qvc8f0daE4lLRVNj/z8fPPvadOmYcCAAdiwYQP++c9/omvXrhg1ahT69++PM888E0uXLjXbHnnkkRg4cCBGjRqFUaNG4ayzzmo0mTMa40pEQSJaCGA7gM8YY3MzKY9C0Ryo798ppqVuo1AoFApFi2P6bbqrri0h097oXlz3+XXYUbUDTx3zFPq36d848nQ9ADjtCWDDt8D0v0ibXDj4Qlw38jp8sPoDPDT/IaW8KurMzJkzcdNNN+GTTz5Bz556jPctt9yChQsXYtWqVTj33HNx9NFHY8eOHeYxr7/+OhYuXIiFCxfinXfeaTRZM6q4MsYSjLFRALoBGENEw+xtiOgaIppHRPPEC6ZQKOoHZXFVKBQKxT7HyhnAiqnAEX8GCpPWVMYYbv/mdqzevRoPHfkQRnUY5dlNdSxRv3KNOAc49GZg3gvAj89Jm1w38jqcN/A8vLTkJXy09qOUXda7jIoWw+zZs3H11Vfj448/Rt++faVtzj33XBx77LF44403Glk6J6FMCwAAjLE9RPQlgOMBLLbtmwRgEgCMHj2aAcDjM1fhwc9WYv19JzW6rAqFX5rLKqhSXBUKhUKxTxGrBj75M9CuP3DQDZZdn6z7BF9u/BK3HnArDut6WMqussNB9Jo4tV7FC+BAPBveD+M+/jPOea8cC5jM4jsCOT3n4K9f3YWbX6wAi7snjVLz5SbOJxOBrb/Ub5+dhgMn3OfZpKamBqeffjpmzZqFQYMGebbdf//9sXx5MmTnwgsvRE5ODgBgwoQJeOABZzmnhiCTWYWLiKi18XcOgAkAfAUxPfjZygaUTKGoH5qLPthMxFQoFAqFon749hFg93rgpP8AoYi5uaSqBP/64V8Y3n44Lh5yccbE0xDALbHrsJW1xeORx1EIWQmcAKq3/AagOLI6ToH6NVekSzgcxiGHHILnn38+ZVu7MUZ0FW4spRXIrMW1M4CXiSgIXYGezBj7OIPyKBT1SnOxZNrl3Fleg1+KS3HUoA4Zkmjf4E9vL0LbvAhuO3FwpkVRKBSKfYfKXcC3jwJDTgf6HGnZdd8P96E8Vo47D7kTwUAwI+JxypCPG2O/w9uRO/Cf8DO4OvYHAGRpw6JFiO6YgKyOnyBe9gvie0dkRlhF3UhhGW0oAoEAJk+ejGOOOQb33nsv/vrXv7q2XbBgAUaPHt2I0snJZFbhnxlj+zHGRjDGhjHG7syULApFQ9BQamt9112169cXPTcXl7/0I6JxlbWpIXl7fjGemb0202IoFArFvsW854FYJXCENfnRzA0zMX39dFw74lr0a9MvQ8JZWcT64b74BZgQnI8rgtOlbaK7DkOiqhuyOk0BBSsaWUJFcyc3NxdTp07F66+/7mp5fffdd/Hpp5/i/PPPb2TpnGQ0OVNdaS4xhAp/FO+uxD8/XIJEAxcW3VMZRa+JU/HVyoZN9lXfFlciSt2oFtjlXLuzQrpdoVA0D4joeCJaQUSriWiiZP+1RPQLES0kom+IaIixvRcRVRnbFxLR040vvUKRpN6TCsWqgbmT9NI3HYeYm0trSnH33LsxqO0gXDH8ivods468kDgenyYOwMTQGxhJqyUtgqjechYoWI2sjqkTNSkUdtq2bYvp06fj7rvvxocffggAePjhh81yOK+99hq++OILFBUVmcdceOGFZjmc8ePHu3Vd7zSJ5Ey1hTE9i7miZfCHtxbhh/W7cPKIzhjdq22DjbN4UxkAYNLsNThiQFGK1rWnueh99nWCgPGdai7yKxSKJEb4zZPQ80YUA/iRiD5kjC0Vmr3BGHvaaH8qgIegJ0cEgDVGtn+FIuPUd+Kjc4Nf4t/h7Th/6Vh8L/Sb3XkyQoW7sGHJ+ej/7adp9dnwiY8If4r9FlOz/oonwo/jpOi9KEOepYVW0wnRnUchq+hzxMpGIFE+xKUvhSJJeXkydrp79+5Yt24dAODUU0/FP//5T9fjZs2a1cCSudO8La6ZFkBRr8Q03TW1oRcjuKstofYDlVbFcOKjX2P1dlnCBGOcDDygWi2s1XbPBX5dlMVVoWiWjAGwmjG2ljEWBfAmgNPEBoyxMuFjHtTPqWIfgKDhmuDHWKz1wvdaUrEL5q1AuPVPiJYcAa2mawYldKcU+bgxehM60S7cH54E2Vc2uvNIJKo7IbvTB0CgqtFlVCgag2atuKqJdcsieTsbVnPl49RFQf5y+XYs3VKGx2aucm2TieczUYsx7Yfw61KbvhQKACgxEnwpMkJXABuFz8XGNgtEdAMRrQFwP4CbhF29iWgBEX1FRIc3rKgKReNxdGAB+ga2YFL8ZJjzjEA1sju/h0RNB0R3Hp1R+VKxkPXDv+Pn4fjgj7gsOEPSIqS7DIfKkdWxfsvzKBRNhWatuKp5dcuC385AA1tcG0uhzIjiWguLq11OfvmZys2kqCVnPPUdTnniG+m+LaVV9R+3pkgbxtiTjLG+AP4C4G/G5i0AejDG9gPwBwBvEJG0OCQRXUNE84ho3o4dDZsvQKGoD64JTUUxa49p2hhzW1aHT0ChMlRvPgtg4QxK54/nEifis8T++GvodQwnZ3I/rboboiXjEGk9D8E894V1haK50qwVV2VxbVlwl9V0khD9WlKJ0Xd/ho27Kv2PY/zfUMmO7OM0JrVTXK2fA8Z1URZXRW351eP7ePC/vsC1r81vRGn2OTYB6C587mZsc+NNAKcDAGOshjFWYvw9H8AaAANkBzHGJjHGRjPGRosJOxSKpsgoWo2xgeV4IX4C4kZ6l2DuGkTazEVs16HQqntkWEK/EP4YuxY70BpPhh9FKzizCEd3HoNETRGyO70LUE0GZFQoGo5mrbjWFz+s24UVW/dmWoyMcP/05fh6VdNYLTddeNM45q15v2JneRRTFnrNy+wDpT+OHT86b4NZLD30yXg9WFz5hVELQ4qGYtaKpvHOaaH8CKA/EfUmogiA8wB8KDYgov7Cx5MArDK2FxnJnUBEfQD0B6BqNimaPVeHPkYZy8VbiSP1DRRFdud3oUXboWbHsRmVLV1KkY/fRX+HzrQL94WfhWNSwMKo2fIbULgUWR3kJXQUiuZKs1Zc62tifc4z3+O4R2bXS1/NjZe/W4+Zy7ZnWgwAQtKkNDRKnkgonUeBj9PcXJL9iFs/yZlq35dC4YUqYdbwMMbiAG4EMAPAMgCTGWNLiOhOI4MwANxIREuIaCF0l+BLje3jAPxsbH8HwLWMsV2NegIKRT3Tg7bh+MCPeC0xHhXIAQBkFX2KQGQXqrecCbBIhiVMn5/YADwQPwcnBn/ApUFnFuREVS/Edh+CSNvvEcxZlwEJFYqGodmXw1HUjZjGmoxljYsRSENz5U3TOQMjeXG9uAp7jVvfV9VPf7WxuDqTMylX4YamqSlw2/dW46qX52HSxaPRqTC73vrVNIaAsELUxE67xcIYmwZgmm3bP4S/b3Y57l0A7zasdApF43JlcBoSCOCl+HEAAIrsQLjtd4juHoNEZd8MS1d7nk2chAMDK3B76DUs0vpiIetn2V+z/TiE8pcgq9OH0Nj1CFCztlUpFACUxXWfhjGGWEKrVVxkQ1AXMdKzuOo0dAng+n4+/VhA6yPGlUi+XVF/NJXvHGf19nL8XFyKVdvrN2TCvpDidtYVNXFl4VcoFPVOa+zFOcGv8EHiMGxHGwBAVtEMQAsh2sxchO0wBHBr7FpsY23xZORRtIbt/c0iqNlxHILZWzB9nXIZVjghItx6663m5//85z+W+q2PPPIIXnnlFQDArl27MGHCBPTv3x8TJkzA7t27Hf2VlJTgqKOOQn5+Pm688UbLvvHjx0uPSZdmrbiqaU7dSGgMjDUdBSWZnMn/MbVRPmszTqq+ZNS34urHAlobK6ldTm7xVopEwxFLNK1ry+Wp71tuV9Bl34my6hiG/t8MPPTZSmkfTc06rVAomg8XBz9DDkXxbOIkAEAg+1eEWy1GdNc4sER+hqWrO2XIx3Wxm9EepXgk/BQI1uQa8bKRSFR3xuMLHkcsEcuQlIqmSlZWFt577z3s3LnTsS8ej+OFF17ABRdcAAC47777cMwxx2DVqlU45phjcN999zmOyc7Oxl133YX//Oc/jn0XX3wxnnrqqTrL3LxdhVtQuY5nZ6/FUYM6oF+HxnuRcmtIs54YGkoWS2MZoz6yCvs6tpaXdUupXji8c2GOZbsfK12iFgqRWzkc5dHQcMS0pvXyiid0edJZrKiOJXDmU9/h7jOGYf8ebaRt7AspsmdqT4U+mZqyaBP+eNxAx371GCoUitqQhSguDX2KLxKjsIp1A8CQ1eETaPE8RHe1nBLFi1kf3Bm/BPeEX8AN2hQ8kThD2BtAzfbjUZz9It5e+TYuGHxBxuRUuPPvH/6N5buW12ufg9oOwl/G/MWzTSgUwjXXXIOHH34Y99xzj2XfF198gf333x+hkK4qTpkyBbNmzQIAXHrppTjyyCPx73//23JMXl4eDjvsMKxevdox1qmnnorDDz8ct99+ex3OqtlbXFvGjCYa13DPtGX4zX+/a9xx+WS1AWaG0biGHXvTS8PO5UhHHLPmaDquwvWQVdjsy2Nfba1XB//rCxz8ry8k/bGUY8ZroRA5Y1z1/5uaO2tLIt5ELa7p3PNlW8qwdEsZ7vhoqWsb+0KK7Hua6j2uFlAUCkVtODP4NdpTmWltDeatRChvHaI7jwG0rAxLV7+8njgG7ycOxR9C7+CQwGLLvkTFAIzpNAbP/PwMKmLO8jmKfZsbbrgBr7/+OkpLSy3bv/32WxxwwAHm523btqFz584AgE6dOmHbtm1pjdOmTRvU1NSgpKSkTvI2a4trS5lX84lZaVXjunHE4rqSk2gA48/Nby7AJ4u3Yt2/TvRt2eTz09rMU9M7pP5chb2od1dhHw98bcZ0HmO4CreQ71dTJNYQX7o6wBc80nl+wkF93TPucS52i6tUcU2RlE09hwqFIl0IGq4KTsPPWm98rw0BoOnW1mhbxHaPybR4DQDh9tiVGBpZj0fDT+DkmnuxDW3Nfb/f//e4YNoFeGXJK7hu1HUZlVThJJVltCFp1aoVLrnkEjz22GPIyUl6+m3ZsgWDBw+WHkNEtfJa7NChAzZv3ox27drVWt6MWVyJqDsRfUlES420/NIsh140axdXgdpkgq0tO/bWYGd5jWXcdK7jez8V4+fiPSnbfbJ4q2UMP/CW6Uyea6N8cpGogdMz1fdd9aO41kdW4YCZnKllfL+aIk1OcTVjXP3f81CQLMdK+7V5AMj659vcvo3qOVQoFOkyPvAT+ga24Nn4SQAIoVaLEMzeatRsbdY2G1cqkY3rYr9HLmrweORxhBA39w0vGo4JPSfgpSUvYWeVM55RsW/z+9//Hs8//zwqKpIW+ZycHFRXV5ufO3bsiC1btgDQldoOHTqkPU51dbVFOa4NmXQVjgO4lTE2BMBBAG4goiHpdCCbo5/46Nd4fe6GehGwsahNXGJtOfCezzH67s8B6O68QHoTwz9MXoRTn/g2ZbuQof3UxP1P0LkCnZbiyqe7aRxjugrXQW9tqJqqnv35Sc5Uq6zCthhX5Src4DQ9V2H+LvB/TCig/3x4xevad8m6TxVzrvRWhUKRLleHpqKYtcc0bSxAcWQVzUCiugviZSMyLVqDsoZ1xcTY1RgTWIE/hd6y7Ltpv5tQk6jBpJ8nZUg6RVOlbdu2OOecc/D888+b2wYPHmyJVT311FPx8ssvAwBefvllnHbaaQCAH374AZdccknKMRhj2Lp1K3r16lUnWTOmuDLGtjDGfjL+3gu9UHrXtPqwTYMYY1i6pQy3v7/Y5YimSW3iEusDPlltiDk0t8ZE01Jcjf/TGKc2dVxZI7kK1/eE24+Rrl7K4ZiuwkpjaCianMVVSz/GNeBjgcOPxTXVQpJ6DhUKRTqMpNUYE1iB5+MnIIEgwq3nIBDZg5rtx6OZp3bxxUfaIXg5PgG/DU3FcYEfze29CnvhzP5n4u2Vb2Nj2cYMSqhoitx6662W7MInnHACZs+ebX6eOHEiPvvsM/Tv3x+ff/45Jk6cCAD49ddfLVbUXr164Q9/+ANeeukldOvWDUuX6nkw5s+fj4MOOshM9lRbmoS/BBH1ArAfgLnpHGefz6Rj3WtKZMqyxSerDTExDAcCqIaGmnjC9zFcitq4gNcqOVO91MPx2tX4FtfauQrby+EY4zXPr1OzwG85nK2l1fjp1904cXjnBpYnfe8L3tLLeuywuEqfKeUqrFAo6o8rQtNRxnIwOXEkEKhGpP2XiFf0Q6Kif6ZFazTuiV+EkYE1eCD8NJZFe5jbrxt5HT5e+zEeX/g47h93fwYlVDQFysvLzb87duyIyspK83PPnj3Rrl07rFq1Cv3790e7du0wc+ZMRx9z587FDTfcYH5ev369dKxXX30V119/fZ1lzvjSExHlA3gXwO8ZY2WS/dcQ0Twimrdjxw7LPvt8pjLqriS9MfdX9Jo4Ne1Mt/XJzW8uQK+JUx3bGzPGVYRbQxsiVphbXGtitXEV9j9ObVTPVDF19UVD18SUjlkfFldSFteGxq/F9bxJ3+P6139qcAttrBYxrvz76uUxYt8nW8xJNaTyWFcoFH7phBKcGJiLtxJHoQI5iLSdjUCowrC2NvSvftMhijBuiN4MDQE8Fn4CSOjxrkW5Rbho8EX4ZN0nWFayLMNSKpo69913nxnX6sYDDzyAESNSu+APGzYMxxxzTJ1lyqjiSkRh6Err64yx92RtGGOTGGOjGWOji4qKrPtsk6DKqP7FzA47T2vyPN0t4tddlY59jcWUhZul2zNlcTVdhRtg/JCRcTSaxoTbTM6UhjxJV+H0z6EuFlfTOuwxbkNlFfZaaKjNIoibnPaMsF5URROYsnBT2mPvq/gNDyjerdf0behFhLj5LvB/DH/UPC2ujjquzjZ8k1tW4ZaShE+hUDQ8F4c+QwAaXk4cCwruRaTd14iVjYBW3S3TojU6m1CEv8auxKjAGuCbh83tlw+7HIVZhXjkp0cyJ5yiWTBw4ECMGzeuXvq6+uqr66WfTGYVJgDPA1jGGHuoNn3YJ0Hc4podDjraBg3/x6Y4CcqUxTXpKlz/fYcD6Vtc3eqUTv15C3pNnIptZdWOY7jyWRtX4UAdFl/9KNf1/ajx6+PlZVqbRQi3Oq7pfFfumroUN7+5ED+s25X2+A3Fpj1V6DVxKmav3JG6cSPj11WY09Bu2+a7II3nhz+PXtZg+7vNM6uwa4yrb5EUCsU+TDZqcH7wC3ymjUYx64BI+5kAJVCz/dhMi5YxpmkH4YPEIcBX9wGbFwAACiIFuHr41fhu83eYs2VOhiXct2mKOkljk+41yKTF9VAAFwM4mogWGv9OTKcD+8lyxTUr5DytZImPWsnaoGTM4tqgrsLc4ppGjKshhn1yy63lSzc7PMmTx6YhW21dhX/6dTdKK2OWPryo7+ua8KFc1E5xdcsq7L+P7caiQmPXIvZiwa+7AQBv/dj0klCk6/ors373mjgVf/+gfhLR1SbGlSvTXgtv9udR1j1v41aeqrbW5gufm4Mzn0qdAV2hULQMTg9+i7ZUjhfix4PCOxFu8wNie8aAxdpnWrSM8o/YZUBeEfDeb4GY7sVz3qDz0DmvMx6Z/4hSnjJEdnY2SkpK9unrzxhDSUkJsrOzfR+TseRMjLFvUMeAA0eMa43uKpwVclpcm3LcXn0rrtvKqpEbCaIgO+zZLtaAFtfaxbha/+fwhYh0Ej35GScdV+GExnDepDm4ZfwAXHdkX3/xpvUd48otrvWsuLplFU6nL+7RkGhCGZ34edR3kqz6wG85HHMRwaX9q3M24K7Th9WbPOm4h/Pr6nUuTsXVPca1vrMKf7u6pFbHKRSK5gjDFcFPsFjrhR/YIGQX/Q9gQUR31D2mrrlThnzgtCeB184EvrgbOO4eZAWzcMOoG/C3b/+GTzd8iuN6HZdpMfc5unXrhuLiYtjz9+xrZGdno1s3/678TSKrcG1xS84ki3FNWlxTT6QaGzHejTFW52y3Y++diQ4FWfjh9vGe7bjFtSEsvuEAVzbTV2Qciqvh+u3VV1quwsb/6VzlWEJDNK6hyoijNt2aPcat96zCWmrloj5iXAO1cBXmNT0z5fYuo6HLHaVLZTSOymgC7fOz6sXiWp+YFtc07h8XySte1/5ukXWf6v3TBF7RCoWiiXNYYDEGBDbh1ui1CGRtQbjwZ9TsPBosUZBp0ZoG/Y4BDrwK+P5JYMDxQO/DcXKfk/HSkpfw+ILHMb7HeAQDTqOPouEIh8Po3bt3psVodmQ8q3BdsE+4K6LuFteASyxkptx03WRIJ5mRF9t9ZE+ujXugX0yLa1p1XLkF2CqPaXGVWG9rk5yJT87TWSBIXitY/vcex33fK9+vx/TF3pna7PBHo75dhe3Xm1+XdJSlpMU1898nO01F8Tn5sW8w+u7PAfiPca2N9bs2JLMKJ7c9+OkKfLRInlBOb5vaY8NhcZV8T/lz5vZ9bIpeMs0BIjqeiFYQ0WoimijZfy0R/WKE6XxDREOEfbcZx60gImWKUTR5Lg9Oxw7WCh9pByPS/kuwRBaiJYdnWqymxYQ7gba9gQ+uB6rLEAwEcf2o67GhbAM+3fBppqVTKHzRrBVX+3SmytPiKp8A1saS8dOvu9Fr4lT8ZMTQicQTGu74aIk0kZAbopWqMedo3FW4IcbkMa61qePqqrhK+jLj4tI4h1TJYGTEbK6U/lyF3dv8Y8oSXPvaT9ha6v85SSZnqucYV9tnflnS6Yorrn5dYBsDfh5NRe9Zu7PC/Ls6lp7be4NnFdac3hePf7Eav/vfAg+Z/PSb2uJqLiTVYRyFFSIKAngSwAkAhgA4X1RMDd5gjA1njI0CcD+Ah4xjhwA4D8BQAMcDeMroT6FokvSmLTgmuACvxScgHtmNUMFiRHcfAmg5mRataRHJA854BigrBmbcBgA4pscx6FPYB5N+ngRNXmhboWhSNGvF1T6Z88oqTK6uwt5jbCipcGybtUL3R/9qhdMv/ds1JXjx2/W47b1f3OW2K8/C58a0LjSsq7B+waNpWVyt/3O4BV1mva2NO6hp4UnjmLjNlZJbh+t6u9KpK8zvk2eMay0EckvOlI7baENbXJdsLkXv26Zi054q38c0NVdhkUq/iqtxDg3tgl2bOq5+2lbFEpaszrJnij8zS7eUodfEqSg3chV4HSNjV0UUSzaX+mq7DzAGwGrG2FrGWBTAmwBOExvY6qbnIbmGdRqANxljNYyxdQBWG/0pFE2Sy4LTUcNCeD0xHpF2XwIshNiuQzMtVtOk+xjgsFuABa8By6ciQAFcNfwqrN6zGrM2zsq0dApFSpq14uqMca1fV+GPf96MIx6YhS9XbLf1xceXJRrRt3nFsNmVC9FK1ZjWhcZ2FS6rjmGjRx3dZDkcm8U1nDpeNp0zSLoK+z8martWdbW4cmJpJDPyl5wp/RVT+yG1SWQWNu53QylYr8/9FYwBXyzfnrqxjaaYnInHSkckGdBlpLOI4MXv/rcA/521xrE9Xot3gf39xxjDiq17Ldvu/ngpLnnhB/xcvMe1H/v7cKdtMcevSKc8/g1Oeuwbf41bPl0BiOm0i41tFojoBiJaA93ielOax15DRPOIaN6+nlxEkTlaoQJnBWfjw8QhKAnHESpchNjusWCJ/EyL1nQ5YiLQaTjw4U1A+Q6c0PsEdMvvhmd/frZJ5H1RKLxo5oqr9QvGrXuy+pwBF8uFl4Xql2J99X75luRkrDqWwPTFW/XxJcf4iZt0uCt7WFx3VUTxyS/pxUL6JV1X4XReaGFeDkdQNk9+7Bscfv+X7v0b/9sVqWSMq8xVOH3Z+OW2l9+IJzT84a2FWLOj3HGM6SrM40z9xLj6caVMw7VW82FxrY2rriPG1fi/KWUV5vc3vdq76df4bSxM7xCJ4rppTxW2lFoty/Vhyd64qxIfLdqMf09f7tgX16zPtx/sIs3fsBvHPTLboryu2aF7rOzxKCNl3xS2XRO/ynQ61niFDmPsScZYXwB/AfC3NI+dxBgbzRgbXVRU1DACKhQpOCc4C3lUgxcTxyPS7iuAEaK7xmVarKZNKAKcMQmoKQM+/j1CFMSVw6/E4pLF+H7z95mWTqHwpHkrrrbPycQ5zokOt7jGbTMzL0uGJpks3/fJciw3Jma1nRDbj7NmFbbuu+rlH3Hd6z9hV0U0Zb818URaCpzpKuzzmHTONxRwWlx/9bC2iv07Y1x1C3q1h6twOrIlXCyuSzaX4b0Fm3DLWwsdx9gtUvVVx9X+PHph1nH16Lc21nNHORwXt3ovGjqrMP+KBJqy/69PNI2Z8fgBiSZ+6H1f4OB/fWHZVh9ZhXlMfsdWWY59du8LP8+uvQlXTksqnO7vyWfK2Y9dKbdfEZWcqVZsAtBd+NzN2ObGmwBOr+WxCkVGCCKBy0IzMEcbjGXBNggXzkesdDRYvFWmRWv6dBwCHP13YPnHwKI3cWrfU9ExtyMm/TIp05IpFJ40K8V1V0XU0zrp5cbJLaExzX6M+3iy+oLiqr7MBdFPQhj7JFSU1z5h5MqeV8kJACiviWPg36bj0ZmrXNvY+7ZPVvlk2o20FJlaJGfiSxH2exLxsLim4uXv1uOql+dZtiWTMyVvbDSumVbiCluMHeB0FXZza7aOk1o++/PohR9X4doojo4YV3BXYf99JBeGGkbJ4Nc5HbU1mXG6aRHTNNPi6tcF2N6uNq7D/Jnlz7lFJlsMt5+sx/b3AX9HSbN/m9ZvZ79e70N9HPn41746Hx8scOpTytUNAPAjgP5E1JuIItCTLX0oNiCi/sLHkwDwH48PAZxHRFlE1BtAfwA/NILMCkVaTAjMRzfaiRfixyPSbjZADNGSIzItVvPh4BuAHocA0yciEqvC5cMux/xt8zF/2/xMS6ZQuNKsFNdNe6rw2pwN5mf7/MSrVAmfq9ktXF5KAN8jupSKE2fZ/MiPQcg+ZtyijNtkcHFrtbPbsMi+Pa847XE1BizeVIrB/5iOT5dsdT2+Nsa0dMrhJPuXDyRNzpTiuvzfh0vw+bJtlm12i+vh93+BAX/7BCc+9jWApBunSNJV2L9LZW0srp4eAGYdV/f+6iWrMHn3FUtojnMLNXCMK+82HYtrU7LNijHvsQQzn7FUjwg/B2d23looroYIskPjtqzZfspyORVX/bMsY7KXxdUrWZ0ur/xcpy/Zit9LvCNSKd3by6rRa+JU/Lh+l2e75gxjLA7gRgAzACwDMJkxtoSI7iSiU41mNxLREiJaCOAPAC41jl0CYDKApQCmA7iBMZb+qqFC0cBcEfoEv2pF+JwGItz6B8RLR4HF2mZarOZDIAgc/y+geg/w3RM4s/+ZaJvdFs/+/GymJVMoXGlWiisAi8usM0OwuyulW7kOrwmgzOJq2e8hp6clLo0YV2b+X3eFwD755fGnjDEs3LgHAPClJFOym2xe2OMxpyxM7WmWvH/y7fWWnMlcDNDZuMsaGydTXOOOOq7cpdJ9HD8yXfnyPMxdW2J+9ix1w8dupDqubve7/+2f4LevWldkuWt4Q7l11qaEEacpGODKq5NW/FhcQ1VM/+z3evm1QnrhNVZMs373/GQDd4Q8GA9otbRsFT9GYnFNkXcg3XP1SowHAHPX6QrrS9+tT6/jZgZjbBpjbABjrC9j7B5j2z8YYx8af9/MGBvKGBvFGDvKUFj5sfcYxw1kjH2SqXNQKNwYRmsxJrACLyeOQ6jtdwDFUVNyVKbFan50GQUMOR34/knkVJfjkiGX4NvN32LxzsWZlkyhkNLsFFdx4uO0uLq7UiZdhTXpMdKxZK7AwsRZanH1kRDG21XYJoPPLLZmPK7HHbX3wSd4CY2Z43gpBukoAPZYuZvfXJjyGN69W8kir8l0bWRzO1eZy3TU5krpx1XTrzunaBH2us+8Py+rZjqKq5sVLFnH1dnXeqMW6adLrVbsUEPXcTUXkfxrrkn5M6+57hUU12hCM58xv7fLLSxCxns/FaPXxKnYbEtWxA+RKY/2ck9+FFd3i6vkWA+3bfs1cLhFp7nyYH8GHdmP0+pNoVA0RS4PTUc5y8ZkNhaRNt8jvnc4WFQlCasVR90OxKuAbx7GuQPPRatIK2V1VTRZmp/iKv7tUFz1/2WTd7cYPE9X4RSTZS/F1muuZZ+IecW4MkkbeZ/G+B4OknaFR3QV5nu81IJ0rL6mdTAdhdIlyzG/XjIXRD+xpg7ZuKuwy9lyJbU6lsDz36xDQmOOOpcyy+hh//4C50+aI8hm3X/3x0txyL9mOo4T3V+9JukJH0pzbSye7nVcnW3nb9gNAOhTlGfZHjRWTB7+fCVKq2K+xi3eXYnh/5yBtZIszg4Zjf/TySq8dMve1I0aiSrh2Y3GhRjXWltcvRRX3bvBnh07+V1x4nAV9qW4Jv9mjJkZpWXf04CHFd9NAXbbz8dzI2pzZbe7DpueHRrz/awqFIqmQxF245TA93g7cQRq2i4EBWsQ3XlkpsVqvhQNAEZeAPz4HPKr9uDCwRfii41fYOXulZmWTKFw0PwUV3GyBPkER55VWP/f7kbmp3oHWf4WTa7ubb1dha2f/cS4yhTXV75fj+/W7DT2652KOnaqeF4+OV22pQz/mKJ7iXnFEKajhHq5bbseY44jV95lcXd1cZlMZbx7+qs1uOvjpZg8b6MjA7Msnrp4dxW+F9x+7c/Ac9+sw+bSasc4YmZZT2uqh9JstkmjnAkzz8HaH38GZONwd+38rJBlO49xBYD//fCrr/E/WrQFe6vjeGvexpRt03UVnrJwEx4zEpU1BVdha4yrZiqyqURzizeu3XOv/y+7HtwThV/naMKqfDLG8I8pi7F4U6nQX7KjmrhmKogyi6upuEqeT6/yYG7yim3+/sFii7Ic1zTL98gtsd0ni7di5B2fSvcpFIqmy8WhzxCChhe1oxBp8y3iewdDq+mSabGaN0f+BQADvrofFw6+ELmhXDz3y3OZlkqhcNDsFFdxspSOkmdaXFPEU1n7c06Wxb+llgBJP7e99wvu/nip65hi7Uu7suPlKvyPKUtwwbNzASStCuK83h4Tap/AyWLBvBSndJTQhM162q1NTuqDXCbWXi7gfmJNHcf4nPVz5WJ3ZdS8dnZXYS/Lj1+ZRCuin+RM9W1xtc/rkxZXZ1/8mQnaTJ/igkdEkrXWEx8i89Pym5xp6eaydLpvcMRn15qcqf4trm54eSdwiyu/5/Z3x66KKF75fgMueUFILit0UxVNmDJ6JWeSjZ3KDVp2ruJ76tU5G/C+kF04nmAWz5pYvCk8AQqFoj7IRg0uCn6Oz7X9saX1elCoEjU7VWxrnWndAxh9BbDgNRTu3YFzB52LGetnYEPZhtTHKhSNSEYVVyJ6gYi2E5HvKHC7e5qIW3IffSz9f0cWV88YV+NYST/6eM5j7AoboFugnvtmXXLMWmQVTuUqzCdqoluzffLpyCosiUfcW+3uOsfSsObZrd9ccQ2QfGILpI5xra+MtQmfyi6vH1sT0xBNWJ8tL5dhjn/FNT2Lq6xNqkzAMtzKxSRjXJ3HmIqrhwLJyxfVdnwZshJGXtQmSVVDIi4aReP+Y1y5h4f4nGka81y8cPP28Ho/xmzJx+zvDr4wFubZoxMaHv8iWXqrMpbwzipsyuAc2yvLupu8Xvc3mtAs3hn2vAZNwQKvUChqx1nB2WhL5Xg6cRwi7WYjXt4PWnWPTIvVMjj8ViCUBcy6F5cMuQThQBjP//J8pqVSKCxk2uL6EoDj0zlAVFYdST0EpaK00qqA8QmgPd5JnAA6FWFrv9vKqi2xX7L5j6kUeZyDl2scl+eL5dvw4rfrkjGuKWZbMYmrsL1UhF1RlVlcxSQydtLLKmw9xozPZMCgv09Py3oqxqQ5x3G3fM60lcFJjmMdT8aqbXuRxevHxjWHq7Cfmqp+r5eojPnJGCxNPmZrkw5uWYVlzxz//tgtrmIfvhXXNGQ0480BfLRos+cCC2CVPZ26nvGEht/89zvMXumeXbs2iN89UbHy+4zw79P2vdXo89dpeH2uP3dsSx/GUFJXYSFRG+CMceX7Q0Ys8/sLNuGnX/eY+6uiCXNRsCLqfIckE4E5B3dYk31Yl+3Krfgs6RZXzfJZxE/8rkKhaHoEoOHK4DQs1Pril8IyBELliKpMwvVHfgfgoOuAxe+ifekW/Kb/b/DRmo+wuXxzpiVTKEwyqrgyxmYDSKuYnnUSI5/g/FxcipF3foqV25LJWfjkNa5pqI4lcNoT32Dhxj2WCa4jtgpWRWHsvTPx+bLtQp8S+RzxWald48SJFd81+cdiPP/NOt9ZheMSV2H75HvaL1sscsYkfXopBGkprjYl1D7RlI3jFnPJD523YTfOeOpb6T4ZV748Ty4bV3bdD8W7P20yFddoXDMtZsx2Xl7XxO/1EnVArwUKTXiG7bhZq/3glpxJ9uyaCkzQXe0MpZNByWUcRxvjDFdt24vf/W8B/vzOz57tLQnP0pClpCKK+Rt249a3F6VxVGrE5z+W0CyeGX7Onz8XG3dVAgDe+jF1XLAdryzLyURtVsWVSFdKT39S/97xRQm7VbUqmrS4VtY4La58aNmp2rf5qeNq95wRvRZiCc1xvUVqJOV6FApF02d8YD56B7bhmfgJurW1sicSlX0yLVbL4pDfAdmFwBd34/JhlwMEvLj4xUxLpVCYZNrimhIiuoaI5hHRPMCafMbN4srZJJSDMN0sEwxLNpdiUXEp7vhoiSW+z6408I8xTZNawmQueeaky/ivyiMTruMYoc89VVG9TI2kjQw+kfNypfzXJ8uTYzJmWhFFvC2uniJYcCQxsh0sy+bJz9ZpcU3+vUCw8uj9p1ZCAf1ZeHzmKiP7qbuVlhMJUlJxTSRMV2G71VNqOU6hGNvHtbgKe5STcRuTMebbpdx6nCGv7RAv6y1XAuwZmcX767ckTjo1Wfn3tMJwsS3eXeXatrQyhle+Tz8uZ+nmMnOxJzuc+tV42Ys/YMDtnyCW0LCtzJl0S8SuSInKlJfemnQB5+0Na3itLOvu48VtWbO54hoKEBZs3I0So342X5Swd1EZjZt9yCyuXl4OXuXBxGO92hTvrjT/tl9f+6KZVz1ohULRdLkqNA0btSLMLAghEN6D6M6jkZ7vjiIlOW2AQ28GVk5Hp5INOK3vaXhv1XvYWbUz05IpFACageLKGJvEGBvNGBsNWK1Nbi6lnLBQ1JRPdGIJZjlOnEg5+uPHJpgjTkrWXuyPK2G7K50Kmt1DVxbjWloVt8iaaqLKrafiK7xVdkje2JBT5ipcKalhykmn5ExyksythNZj90iui7vF1X1cN0uj/Xr9/s0FePCzlViyucxzAs+JacwS42q6CmvW/mUJS/v8dRo+XLTZVTG2b7YkZ/KyuBpjecUApnIpl/br4iosj4W0Kjgc8VON5Llau6PckjDJcqwPke0WfK9n8Y6Pl6TdPwCc+NjX+JNhyeX33otZK3YgmtDw9w8WY+y9M6X1fzmihVC0uAL+LML2S+pHcXV7P8qOTLoK65+jgmuwuEgRMhJv2fuujCVM5bpCYnFNxrw7x3aETti//5KD7N+Bx75YLZwLs4SEOC2uSnFVKJobo2g1xgRW4PnEcQi1+xqJ6s5IVAzItFgtk7HXAnlFwMw7ccXQyxHTYnh92euZlkqhANAMFFc7ViXPW8ERrZ2imyVvFSCyTJouem6utT+u7GrMtxWJz5G4KLsNS4W1jV3JSk6kuJyllVEkNM3hrsyxK0VO1zmgrDru2G6Oo0HqKlwpsZYkx7R+jsY1nP30d5grlIBJ9m9VcOzySy2uplJi2+4qkZh12bp9+16rBYxPZMuqY47EUaEAOeqDxhOa6RZZI3UVNsZlDFtKqxzX+ZNftriWWvrjO1Y3VNFK7qWQmHG19jhtMe67FsmZ3CyuXlmFvb57shjCox/8Cic+9rVv2ezw3pduKTVkc29bIynHYufXkkpPi3tWKIDKaBzPzl6bUknkLvgySyNHfG9F45rlfbJy2148PnMVNpRUuB6fXHjTHP258fu3FqK8Jo7tZdX4bs1OQflPHpvQGErKa5KuwrYYV7tLeMT4bL921YKrsNziyts75U616JRucqZ4QnMsFIjUuCSHUygUTZerQlNRxnLxdk5nBLN2IFpyBJS1tYGI5AHj/gRs+AY9dq7B+J7j8dbyt1AeTV1zXaFoaJqd4pqQxINy7HMZUQnjE13RilkVTWCJYAWat2G35Xiu7OgTIfdJvFUGq1Vjd6VTcXXEuGrOc9pTFUPcw+JqP1d70qm2eVlmPzLcXIVlrs1ucu+qiOLH9bstSVrsbbmcDourh6uwM6uwhxVSMhkHgM17rIprXpZuQSuvjjsyPycYw4COBZb24vWsiSfMz7LkTAf/6wsc/6hVKSNyV7jf+2mTy54Uiqu5kOKeGTu5cMLwzaqd/hITucS48nP8uXiP2Y89+2xShuTfDZH8hos4Z+0uYzxvpdNyrG3/xl2VGPfAl3jwU/fi6lmhAP4zYyXumbbMEhvO+XxpMvGX+D6piiakiz/W5EwMcU0zF0tOePRrPPjZStzx0VLHcRx+vjy21E8s866KKF6fswGnPvEtLnh2btLTQGjzwIwVOODuz7HLWGCzuwqHgwFUCzGhYW5xtY1VKSquNc7zd3NLB1KX+pHGuHp8T2Ka1eJqf3dXK4urQtGs6EbbcULgB7yeOAas3Rxo0TaIlw3PtFgtmwMuAwq7m1bXvbG9eHfVu5mWSqHIeDmc/wH4HsBAIiomoitTHWNV8lJYXAXXvWSMa3LSsnRLGf76/i8eY+ltn5q1BjvKnTFsMmXWLkO5JGbUK6swYwzRuGZOBJnLMXal2bQIGp/b5UUAAHskijPvT6Z4V8fk8byA+8KAbKKazCJsteRwvCyuTqXIS3G1jsexJ2D5drVuFS6viVvibzVNXxwosLlVxxKaOW5NXDMn8ppNRt5m9XbrSuS0X7binfn+EuiIsvtJzuS0vjvbvDO/GBc9PxfveijJnL9PWYL/m5KsSJV0FWaYvXIHTn3iW7xmZLHlCoH43Vu7oxyVwjMge65kcBdUPzbiVN91zsZdlXhvgfWc7cdyi+ATX66GG1mhIEoqagDIz+eqV5KJv3jvldEE9r/rMwz5xwxHezHEoSaWgMac2Ze7tM52lYe/97ibq5snhZ1/fbIcW434W9OjQbgcM5ZstbRPmM+8/v0JBghLNpWa+0OmxdU6TmUskYxx9XIVFp7dS1/4AVe9PM+hsNvfq3Jl1/38Y4KHBOBMZqYsrgpF8+KK4HRoCOD58FAEczcguutwAKnDORR1IJQFHDkR2LwAw3aux5hOY/DK0lcQS3hn9FcoGppMZxU+nzHWmTEWZox1Y4ylLBhliXF19Gf9bHEVNmY/cY2ldP3jiBPWOz9e5twvmTzZE//UCNk5TVkYw8ptezHqzk+xrazaWg6HJZW6uKaZJ+mVwKR4dyVufGOBZdx2+briumOvXHF1yyoMOK2uP6zbhfcXFDuUT96u3MPCwuW3W0hKPSzRoqKxtbQab/1YLJVTPMZ+Km76X3lNXIj1Y+Z1zcuyKq7xBEvWtIwlJ8KmC7QQM+3GjCXycjx2xGvjJzmTM8aVOdpsNJIX8Sy0qXhZSGYkugqv26m7r64yMnTbLa6MMRz94FeWOsUNYXF1yzRt59IXf0jZlx+3/6xwwGzH4zrd4M9/RTTu6rEgjsmtpmFbvx0KnIqreC9Kq2L47avz9c/+XmE2Gazu7gAcLvL8ua423K137K3BfwTLtF1mTlU0bn5H+DU4Y7+uyX4l1t6vVu7A55KSVX5i3L2+d3HNmpwpltDr3vLrrmJcFYpmRNVunBv8Eh9qB6Oi3QJo8VzE9ozOtFT7BiPOA9r11zMMD7kU2yu3Y+q6qZmWSrGP0+xchacsTNaT4hOauz5eij++vchhWamUWFztGSe9iMYF9z5JCQXZBNhUXI3P3HIhlgjRGMNL363HnsoYPlu6zaa4MpRW6UqdbnGVKyvi5+/XJGNM+dahXVohEgxg6i/y+ltursKAU3E955nvcctbi5wLA8b1lWUiTlo15VbC2at2usb0ieNMePgr7CyvkbbTG8MyDsfNIrfX5irM/862JeMRM0lbXIVtlmS/z5KXy65oPfOyLotya5ZnRmjjNxORB2LsK3/OeN1We4yrOHYoQMgOB8zEPn7H8eXNbPvsdp3KqtzjTDl+5MsKJc8j7LO8j1dyJvH555mRIzYl0MuKmtAYpixMWpJlJZFSwRU28coFbKmduZj2cjccN1fhqqjmcBUOB63vPPF/L+yXQXbMmz+417GNSpIzPfjZCgz6+3RURuNKcVUomhPzX0Ie1eC/gYMRKliG2O5DABbJtFT7BsEQcNRtwI7lOHTvHgxoMwAvLX4JGlPvUEXmaHaKqwifzzz/zTq8M7/YYYWwuApza1VC7iIrQ2xnL/8ByCeP9klWjVlWQsxwnLSkMDhjXLnFlQmKg93aKU5yZa667fKzcGi/dpi3frfs1HSLq8t1cJuA28+NLwyU1zhdR5LJmfTPdsX1h3W7cMQDsyzbeAs+zk+/7vYszyO2TZXghaMrrsZ4jCUTNNmS0OgWV31fNCG6CnMFVm/nexHEo514/728AcRzjEkSegHJ607CvmtfnY/5G+TPgQwSSq5wl0y+8JIsm+KUl0hXxhrG4mr9nI5+bm/rx+KaHQ6a3zG/iwGy7yFHvF9uFlevuM0EY76TeLlhukYLh9oVV36u1S61TsMuyZkqY3Ez/0CNEB/Lsdc/9sL+XrUfU1oVs3gIOI635SSIJxjenqd7beytju8TdVyJ6HgiWkFEq4loomT/H4hoKRH9TEQziainsC9BRAuNfx82ruQKhUA8Csx9Bl8nhqG47WowLYzo7oMzLdW+xeDTgMLuoLnP4PJhl2NN6RrMLp6daakU+zDNW3EFHNZKEbeswn6VDXECJas5Kbe4GrIZu3iGU9HimtBYsj/GHBY3sVQM78c+qZVZcEQCpLu/RiXugfo4zj557cr/fLrC0Z9MBq64epe/kFuMZdhjXN/3EZ/pphi7uwrHzGuhCRZXpxKhWVyF7ZZGM1mRTyWt2iPTrfgcuSkkc9eWYOW2cmk7cfGTb+fP1/ayGkxfstV0MU0Hxph53wLG88ufp0Ub9+Cxmass3zkiQiTk3+JqjpMiypUxZomhBbwsd6mfMz/f/817qvDlCr2mq58sxYB3YjPxfvFnwR7j6vUd0TSGYB0VV454pP29xp9rt+fVzW26KppwhE6I3ynN9l70ImW2eA/LNuD0qoklNFNBZ8z//WyuEFEQwJMATgAwBMD5RDTE1mwBgNGMsREA3gFwv7CvijE2yvh3aqMIrVDIWPwusHcLnqKjECpciNieA4FEXqal2rcIhoAxVwMbvsFxWV3QJa8LXlz8YqalUuzDNGvFVWMMm4xYPkCSMERicY0lGKI+S9vE4t7tZBNNbrEo3l2F934qTq7u22JcuVVLY7DIw5i8xqnD4ip8tlgljc0BIkSCAdcssAkjCZRIflYYgNUdW6Ss2ipXVUwfd68sOZPNwuKWTOWNuU6XPz553ludOgmAvb6nfbud8upkciaG5IQ6bLO4xgSLa41QvsRUlE1rrL9nyc31EgC+Wb3DvBcyhYQxhnMnzbFscysLZbcOcoVTZhV3w7QqM2Za0UI2V2EAeOizlRZ5Ay4WV7sL7PWvz8cHCzZZLIhevPTdekfGb43pcYub91RZtstuu/1Z8KNY/yh4KrhZH+3IvrecmCTG1aG4Sp4lfo28avfOWrHdl3zJY5MHB21u0Px+uj2vbnesMppwPLvi+dXNVdj6WRZTLxJLMItVVWPMjOVNMJb2wkozZAyA1YyxtYyxKIA3AZwmNmCMfckY4wHwcwB0a2QZFQpvGAO+fwLoMAQ/td4FgCG667BMS7Vvsv8lQDgX4XnP45Khl+Cn7T9h4faFmZZKsY/SrBVXMGBLaXLi6lyZd5bDiWuab1dGcYIjm2NLy+EYs6yd5TX4w+RFpvIsiqYxJsT3OS2usoy7XhZXWa1YIkI4GDCVb7v7ncxVuJWQWVcWk2mXy3QVliiYfDgxxlV2DWVZnfnQbhNUUbakYux+fURiQnIujSWTM9ktSfGEZo4TFyw4/Fh7Xc1UeFmJVm4rx50fL9H7lVx3e8ZiANiwsxLPGwmRvOq4isl27PfUTQnhrRJaUp6g4epuV65EeQmEzaXVeGd+saVcTKVNCZr2y1b8/q2FyfFS6DKf/LLVsU3TgKdmrcYh932B9Tvd658Ckvhwn4sNHL8Wuv/7cInrvoQPV+GXvluHXhPliS80xlxrLF/24o++5EvKIi422BVXLqP8nO2lpAAgLxJElZBVmGON6+f/+1Fc3cs9AakV13hCs8SxJrTkAkAiodfkzgoFcHj/9illaaZ0BSCmNC82trlxJYBPhM/ZRDSPiOYQ0ekNIJ9CkZq1s4Bti1E25kqEW89FvGwEWKxtpqXaN8lpA4w8D/j5bZzRZRwKswrxwuIXMi2VYh+lWSuuGmOWOqlersLJ5Ez+Y1wtrsKyGFeP5Ewcnt01aplIMfcYV8hrnNrPTTwHXrYDANYak3gCEA6RQ+HqU5RnfrZP6PMFxdVM5CKMW2aTq8qMcY1ja2k1/vLOz6alw24JTWjMNSMpIE9QVOYS32ovHyQek+zDfRyzKRNchW2Wp7iWzCocTSStNPbz8hsvl8pq99OGPQDkCvfPxaWObZe9+APu+ngptpVV25IzWduJ9/guW2Zs+0jRuIab/rfAzCTMWFLJD9lchTmaRQlKbp+5PKm4iko7syi6/sgKO58bxhhmr9oJAGa5F0DuKGxX5v1+/zl+La5eiBZX/l6K2Kz8smeWt0hoLKXCxkmlG4rfFXveqaSrsEt2ZM35fcvNCqEqmnAsjkljXL1FA+C0uNoXXGQlxkRiCWZZbEgIC4UxTUNCY9i/RxucMrKLD2laNkR0EYDRAB4QNvdkjI0GcAGAR4ior8ux1xgK7rwdO3Y0grSKfYrvnwDyO2JyKA4KRhEtGZdpifZtxl4LJGqQu+hNnD/ofHy58Uus3bM201Ip9kGateL69rxiXPvaT+Zn+4RH5iocT/iPcRVdhaUxrj6SM320SHe7jdoUs2StTOtEWmNMWirGYekSZrk7y53tA6RPHPm4fOJcYJR9kWUVzoskFVc+cRWvod0VMmlxjWPiez/jrXkbMWftLvM8xP/jGvPMzmq9Pvr/bomZrG6y/H/9j6tfmYfxD32FJZudyh6gK2fJzM9icqbkVyEUIEsd17gmugpbLa5esav2cb3gtUVlimuFxNLG3bMrhPI+gJiciSdYSo77wre6RW/zniqs3LbXoeDM37AbHy7ajB179YWQrWXV5sIQv3P27441OVPy/rbJTWZ9FJ8hv4moROzZdwH9vvPzTqUAxzWGJ79cjcVGPVLxHLyyPXPqIyZSXABws7imOt4r+VNtZAHgcNdOeCiuw7q2ktZ4zs8KoTIad9xPq6uw/r+f683DGO6ZuhTbbQszQGq392hCsywoMcZMy3IsoZe2CgXJYW1uQWwC0F343M3YZoGIxgO4HcCpjDFz9ZMxtsn4fy2AWQD2kw3CGJvEGBvNGBtdVFRUf9IrFNuWAqs/R83oK/HaijcRLx8ArUYtNGWUooFA36OBH5/H+f3PRlYwCy8teSnTUin2QZq14vrFcmtsl936JSp7ogLl11VYVExlJRRktQT9xnBZXYWtFkSZq7DdhVRUAHZJXIUDAWuMK59U8smkpjljvcR4N66QibLYLa5mcqZoAtvK9HlPPleMTVdh/j9DOOT+uImLBDxZj9sE1a7o83HKa+L4bOk2rN5ejme/lq8ExhLJ66tp8uRMkVDAiHHlsomuwtZx/ZKqBAe3Isn6FS2W3PLJlbmqWMJqcbVbFyWKxrItZTj2YWdWQPu6wpSFm/HanF8t/Xi6CgvHWxXXpMIlHr9LskAjwx4LysflpxYQBJcpRjVxDQ/MWIHTnvwWgPV760d3TnXvurXJSdkH9yjICgVQ5ZKcyQvd4urP8ptKHxOVftcYV9u79PWrxiIYCJjvHfGy5WUF9eRMtmdDjBvnIR1+qvj8/YPFGHvv53j263V47ItVju9Eqkzjc9aW2FyFkzGusbjuaRIMENJYN2hu/AigPxH1JqIIgPMAWLIDE9F+AJ6BrrRuF7a3IaIs4+/2AA4FsLTRJFcoAOD7J4FwLj5q3wkl1SXK2tpUGHsdsHcL2q6djdP7nY6P1n6E7ZXp5VhQKOpKi/rptscRJiTWnZitxp8XonIos0DILLd+jLm6q3ByUicqyIzJXYW9YjhliqsZ45pIWg2B5GQ5wZyuwoM7F6Bra30Szt0ZRcXVrlCL12TZljKLXMnyF4LF1WOmWJMQLST6/3ur41Jrm0XRN/5PaAxbhEQ9bpbQaFzDDqMuLAMTFNfk/cgKBSwxrjHBVdjNNTkVMqvdLeMHmH9zC6ooNx9LdHnPMu4fl7c6lpAmZ+LKS0LyrOdlhRzbAKsCaCdmWu7trsLJv92OFr+XYuZZv5ZMmYLHGPNtcd1luNLL4pK96qG2zYsgEgp4JtYC9DjRyw7p5dkmrjGEAoRQMIDZK3W3Sl8WVyGpkJ9kZYDfzL36//ZbHk8wXPnSj/h2dYll+7CuhQgS8N2andhSWmUZIzcSQlXMmZxJPL+7py7D7JU7fLkKA8Buw7ujU6vstJMzfb1qp+VdpSuuhsXV8J4IBVquxZUxFgdwI4AZAJYBmMwYW0JEdxIRzxL8AIB8AG/byt4MBjCPiBYB+BLAfYwxpbgqGo+924BfJiMx8ny8tOptDGk3BIlKqbe6orHpNx5o2xeY819cOvRSaEzDa0tfy7RUin2MlqW42iaY4qSUT37iCf/JmUQFSZZcR9aPH4Xm/hnLBYur0wIky07qsKQJk2/ZRI67CieMZER2y2I8wRx9hoIB/O2kwQCSSqmY+Mk+jixZDLd6JwQFT9MYGHPGkYqI11Jvz1BeHUernLCjrczVU2MMm0v1WMcsD0tWNKFhp6G4aszd4rqouBQ//brbPIY/C8nETq5DSJHFwnYVLHX8/EV3UP4oic91xFRc9f/La6yKqzP7tPMZdUtO5HF7TLdyR4yrGC8pdCCer6iMi8oqb5PKfVS2eLGzPGrGQIvurrKeSmyu9BaLvceroENBFlplh1NaXIMBwoQhHS3b7Bm44xpDKEiWBZJ0LK6LNu7Bxz9vAQAcPaiDZ1t/Xh96G7vytqsiipnLnSvokWAAoYC+EHb8I19b9umuwt4xrgCweHNp2gs+rXMjace4AtZFNo0xcwEgZoQKhAKBFqu4AgBjbBpjbABjrC9j7B5j2z8YYx8af49njHW0l71hjH3HGBvOGBtp/P98Js9DsQ8y73kgEcOXvfbHhrINuGLYFfCfEUHRoAQCwNjfApvmoXvpNhzb81hMXjkZe6N7My2ZYh+iRSuulhqv3NVRkk3XDXEiVilRXGVJW/zE7a3dUZGctIPZFGyGsqqYQ4nwmzWXQyCEQ0Jcl6GscCVAZkUKBQjZ4aBlf4mguNot1bJrwhUTTVDwuGXXy1XYorgyXdmJawyFOU7rYMxyX/kxydIogzu3ch2noiZuLgwwBiGrsFOhmCZks7XXcU23jqZskUNmcBOvKR+rOuqhuFbHLdYvccFAl1vieuxiQfT6WvDztyu9361JWuYCRPj0Ft2lS1T2oglRiU3+nUoh5LgpeDzbspfCDTizCovXhH/3bp28yHFcbiSI7HAgZQIuvkgkMuKfn1plSOjKkohMIXdjyeYy8+8rDu3t2dbPs8mfD7vytmKbfAISDpLpVlxaFbMooHk8OZPt2bCfH2OpFynsxIVYc46XxZWPaVVcIcS46u/bYMuOcVUomiexKuDH58H6H4cXNkxD94LuGN9jfKalUoiMugDIagXM+S8uH3Y5KmIVmLxicqalUuxDtCzFVZjgh4NkTQRjTuS9kzOJEytxAihT9ETrUTSuYcaSrb4VmqiZtVefTPE5lMYY9lTF0DYvy9Le3q+shqwIr6kJ6JM4binLMhRTnoBHJCgorly5Ed2Q7RYVmRWaKyNmMhYkJ8lerpExi/tvMg61UGJxlWUg1jRgS2k1iIABHfNdx9laKmSgNazBgHWSbVcwZOelMYaCbLnLrQxZ7UjZxFlMxMSviNVVWL8/3HJXURO3WlyNP/kzLlOYuSXZjtf3gtertbf549tJhY8ADOhYYCh7ciurTHFN03hda8w4R4nF9d2fih3tcyMhbN9bg/d+2oSNuyod+znBADnqANvhCYHEr22qYxhj5sXht/i5S0ajTZ7zO2EdKw2Lqx9vZdLPUXxcRct+flbQsLhaS17xhTOO7t6dejyRuMYcVnHZghknN0v/fjhdhfW/Y5pmum2nWvBQKBSNzM+TgcqdmDfkWPyy8xdcNvQyBAPBTEulEMkqAPa7CFj6AYaE2+CgzgfhtWWvIZrwl7NCoagrzVpxZbYpr32CL7W4JrwL0ItzvliCYVCnAkffHHES/uBnK/DbV+fjm9U7fckeFRSheEIzFSfG9ElX+/yIpX26FteAEeMKAGPvnYm7PtbDlPg4YgkRjm5x1fdzZaOkPKng2i0qldGEI7kLt64ly8YkY2m9FFe7xXXNDt2a1rfIqYTGEgwbd1WiOpZIxrgyPetqbjjoUPpF9tZYFUPT4iqch0yB4y68yWzCCXQuzHYdx44snlN0ceXjV9Y4La5VwrHc+sj/31sTtzyz4nMOyL0C/jtrjVTGC5+b6yp/3CXGVYSfT1YoiBrhuyF+30S3Yb7w8cr3G7Bd8jyax6ewzPp1P+XPqphN2yvGNScSNMf+fNk213bid00kboml1ZUlUdZUMa6a4BHAFzRGdCtE27yI12G+Fs8SLhZXGZFgAERk6VdUjnmMayyhIV/ITC47v3Rd7PUkacmDzp80B6/O2eDanmdGL6uKmd8pjSVzCsTimmn99orpVigUjQxjwJz/Ap2G44WSeWib3Ran9j019XGKxmfMNYCWAOY9j8uHXY6dVTvx0ZqPMi2VYh8ho4orER1PRCuIaDURTaxrf5U2l0o3i6tsIsyL0YsT2YTGcGi/9ujUKluquIpWpQ07dYvMbkmiJBlJa5Ou2JmKSHUMCY2hnV1x9ajjCgCjure2fCab++KsFXpCGD4OV1zbCZPgQICQE9FXNz9ZvAX9/joN60sqTWXWPmZlLOFQsLmClowFZdhjZI/1sjBFLcmZmJnsaUgXp9tvNK7h8Pu/xA2v/2RRkKtjCWSHg2id622R4mhinVLhWsmeD67wJpXJBFpl+xsHkMe4ivNmrkBYLK7GLRcXSPjCA7cK2y2uCY1hyeZSPDNbz6rMlUP7AkO6JJMzuWseXAfKCtksrsLf60oqzL+rYslz/fO7P6cc2w1xt5cOayquPkvy5EWSK/2dC5PxyHZ3V93i6nyVila/eEJDKBCwWCpTxbiWVydLzPAFjexI0JKxWYaf5HNcDr+KKwCbZV9wFTauU0VN3FIL2n5NGEs/qZml7jKA79eWuDcGzPdXaVXM/DshWIJjRmx/S07OpFA0S9Z8AexYhhUjz8Y3m77BhYMvRHbI/+KwohFp2xsYeAIw70Uc3H4/DG47GC8teQkJre41zxWKVGRMcSWiIIAnAZwAYAiA84loSF36FBWOiJGYiCNmFJVNhAd0LLC04231TKAknRDXxJOZZ+2KZSpqBFfhaDxpcd1VoU922+d7uwrbP3coyLJYAHUrkHNixhMXbTNcZkUFORQgZBuuqJPnFSOuMfyyqRRFBVmOMZdsLkVVNI4OBdYfFvG8AN0V87B/f2n274ao3DAGrNy2F+3zsxzXAUjGuH25Yrs5TkJjqI5pyA4Hpe7FdkIB/Z7ydQrRVVhmkecWVz7hr4wm0nIVlsVzBoWJM39+RIurVHHlWaENOcptdVwTjOHRz1c5xs2NWN2tcsLpuV/FXFyFRfjtzbK7Cgt/3/S/Bebfoqu5l/unl4cEoLuzn/rEN1i7o9xXDKV4Dl7f25xICLdO0DM/79hbbdaBtX/3zh/TQ/pdE7OD8xIs4nCpLK4j7/zUvHb8GmSHgp7Jx3T5UscOiwtLMn47rg+OGqjX5uSx6XEXiyvPUr27MmbJWG2/JmLYgF9iGkvrmDxTcY2bz7gY4xrXNDPGtQWXw1Eomh/fPwnkd8QL0WLkhnJx7sBzMy2Rwoux1wKVO0FL3sUVw6/A+rL1+GLjF5mWSrEPkMmf7jEAVjPG1jLGogDeBHBafXWeFQ5Ykx5ZkjM5J0IRyeQsYWQC3S6JB+UkFbV0FddkRlXR4rrbsE62SzPGNSsctJwXkdyiY7e4itabACVjXDnVsYTZRrRUnfTYN6iMJkyl1n5e9iRBgP8YV40xlNfE0To3LLUU8nqykVDAUsdVt7gGfCmUeVkh3eIqSc4UkyiZXLHil6A6mkB+WhZXb1fhhJFJ2Rrjalh3o6ILvOHKbVzncomrsHgu/Fi7daljK3d3ahlRH67CAcFVWFxEcnP1FZVVL8tnNM4wxCPh1owlW/FzcSme+HK1axvASPiV0Kyuwh7WydxIECcM7wwA+PuUJTj58W/0YwxZ/3z8QKy/7yRcdFBP6bMtZgePJxjCQburcHoWPz0JFFmeGxle58Thz71b2wvH9kR/YzGPyylbCASAXENZLa2KWZ4rmcXVjXYu7s8JTUvLvTiXuwpXx8zFGk2wuEbjyRjXVNdRoVA0EtuXA2tmYuOo8zB9w6c4Z+A5KMwqzLRULYpUZd3Spvc4oMMQYM7TmNB9PLoXdMfzvzyf9lxYpN5lVLRI/JuM6p+uADYKn4sBjE2nA6/JbnUsgZpYAm/P04fgVrqamGbGT4qs3qZve/+nTeaEJ64xrNhajoTHZP1vHyzG2N5tUbxbz2grq7U4pldb/LB+l2Ubr5M4afZaBAgIGq6fP6zTt28prbK0/6W41DwXAFhUXGrZv2VPlUXp+XH9LmmSoTVGJtafNuxGQXbIEsP6c3GpIxNoaVXMVGY377EmqNldEXVk+Jy/YTfenrfRvDfby5L9y+rNAsBf3v0ZHy/abH5euqUMO/bWoLw6jjkS18DPeLwhAzaU6DLtLK9BTSyBqlgCP6zb5TjGDgHYVlaNz5ZuM+XmeL08K6JxvD1vI/ZUxbBjr3tcpp0HZqxwbJuz1hoPPXlesXl/AOC9nzYhKxTAZuFZ4Asb3P161da9mPbLFnP/9r3VlkWNUuN5rLGdE6VZXuDXXZV4e95GTzfUKuPaVEbjWLez3Hxe562X3w8xQdj2smqzfU1cs1gVf91VaXErtrNup+5+/GtJZcp42Nfn/oplW5MZeqf+stmxSMTZUFKBz5ZutWzrNXEqhnfVleilm5PfSXuNYwCY+vNmrDXeNetLKlARjVusx6u2Od9DXoQChHfmO5NIAbC8G+x1oE8f1QUfLNxs2fbhws0ozAljq/BsnTKiMz4ySu7MXL4NK40Mw9G4hrfnbTTLSAHJus2Afh044nfnW1u8/+LNpdhaZn2vcdwyTC/ZVIbNe/x/z/h9iMY1s88FG3ej1FhE+GjRZuypjGHdjgpkhfzlI1AoFA3MnKeAUDZezmYIUhAXD7k40xK1OLLDQfSaOLVe+zw3eCj+HX4WF/ztEawqHI3szu+j312PIVHZr1b9rb/vpHqVT9EyafLOUkR0DRHNI6J56RwXDgQgzrH5XD7BnPVLgaTFze5CFwwA9rk6IRlTyieSXu5sXdu4x2mUVcexpypuutGWG66i+VnWNQV7/5rNHTAUJIuCTZDHNfLzjCYYDuzVBmIvRFbLo95OEywu1r5iCQ054QD6dcjDhWN7gCBbTEh+douzfOvHjagQXUWZbiUJBmDJUsr/5JNj3YU7eb9imoZwMOArW2h2OAiNMfN4q9uu+3Hcch+Na2aGXy/sscciBMJQIYZXY5plAr++pAJfrdxhsXLy54QrkHGNmUppkHSrlnj+MusxABRIygx5kdA0H+7w+sDhALm6lYqIShx/bn4uLsXfPliMTXuqhH0aQuT+quJJkLxuO493rI4lbJZD92MiwYD0mf1lk660BQSZZO0qbBblIAWsVsc0DX6pXIs59nfDiG6tnW0Y8OnSbVhXklyM2r9nG/PvrFDAFM9McqSJxzNLW06h4IUQtC+cMa/kTPIdiTRdhUUvE/43Y8n3yOxVurIaCFDaizcKhaIBqNgJ/PwWSoafiQ/Wf4JT+56KDrnetaoVTYMPEodiF8vH5aHpiJXuDy1egEi7WZkWS9HCyaTiuglAd+FzN2ObBcbYJMbYaMbYaPs+L1evjoXZiAQDOHt0d5w9urtlQtNOEjd5gDFpO3F4Z5w9ujtOG9UVADBSonhMGNIRF47tYX4+e3R302U2J+JUCA7s1c5VTk574/jWRnzmcUM7WfYP6FRgnsvZo7tjdK+2AGC6xeq1S5PX4+C+7XGkEaMmsn+P5OT0lJFdUCRci1HdW+O8A3tY2scTDD3a5oIIaGNLehTTGEZ2b4PP/3Ak7jljOLLDQfQpyseZ+3cz27QV+u/RNjfldeDn2r4gC0UF2TisX/Ic3rnuEABAn/Z6puFW2WF0a5Nr/l2YE0H3Nrk4vH/ymBcuczw2AIAurbPRoSAb4wbobfn/qYiEAvjN/t0Q15inUsrhWallHD6gPabedDj+euIgAMBpo7paYgSf+3odPv55i8XNt7dx7vzZ79w6G2N6689XYW4Ehblh9BEyMXOl0a5YHT2oA/p3yMcLl43GeQd2Ryra5mbh1JFdPNvkZ4dw9uju6NI6F61zIuaz2r+DS3ki5jyWKylt85LHt86NoIvH4k8nI7a7T1G+VLn7buLRePDskQCAw/q3R/c2yedwwpCOOHu0/PzH9mmHU0d2dR33gJ5tTBl/c0A3x/7Bwne2U6tstMuPWO6ll/uzjNa5yWtih28/bVRX7KmyWqfPGu2U7dghHU1vAwA4Y7+uuFyoD3v+mB4Y2kV31Wubl4WzR3e3JF7q3T5P6Cv5rjpyUHLCedzQjpYxB3dphQON95Ydt0Wg3kV5aV2nwZ2T3zf+LA3t0srxzh/SpZX0/ahQKBqZeS8A8Wq83q4jookoLht6WaYlUvikBhH8L3E0JgTmoRv2IFZyGEL5qxHIlnsGKRT1QSYV1x8B9Cei3kQUAXAegA/ro+P2+RH075DviFflVEoK2PP6pjwu1izhInG3Feud8r4TFktcAB//7jChfWqZHTGuKcrhcPl4IqKsUBAxwSRCBIfbLwCL3KFAwGHNkK0FhAIBBIkcljPGrEl+ssIB1NgsWmL/dmuuG+/OL0bMsPSKp8Atv2WG+2tYiHGNawxVUT3GVVTSHFYf4Zw0oY5rOEXCG05CY2aJmZxIaourVxuuxCQTx1hjXDnbBHfriC3GNRrXzGNaZYeQ0ORJsOw2qza5EXz2hyNw9KCOvsqCRBNaymy1ZoxrOGDJouzmBiqeK4+15M9ndSyB3RVRzFqxHdvKqqXPsnlsipqkXVrnmN+TvdVxa3Imj3CDnEjQMxuzuE8mX7Vx3h8u2oyZy7cjKxSwlPBKN6ttVjj1M/rGXGepGNk77Mj/zDL/HtOrLR4+d5RlP1Gyzimvx2p9hybvr/iMd2yVXGBwXDvmbj11uwuxBJPGVQ/qVIAJQzo6tucKC4cJ45lKaHB4YYQDpMrhKBSZJl4D/PAsyvsehTc3forxPcejV2GvTEulSINX4xOgIYBLgzMQ3TMWLJGNSLuvMi2WogWTMcWVMRYHcCOAGQCWAZjMGFtS136PHFiEeX+bgPyskGsyEVkG0yxj4sljpLj7oWziGgyQxT2uMppMkBNNaGiVE0aPdrlC+9SXmU98d1fGEAk5Eww5FFdjUsZLsmSFrG6IASKpMpYtTH71ZDHJfQTrhNVsF9JrHsoUFzFbLS+DIk5OF/y6xyFzKkoqopizVo/RFa3q3JrGk95kicmZDIUyK2xVNmQJcPS6lLrinVygSLYbLbhM2mEs+fz4ycybJ7HAc7jiwhXNRIJZ6r3a3cW57EDSVTiaYGbG44LssCM5kyi3iPh8eWV75sS1ZDZuN2XOrRyOW9yp+Ozx+5BjxlNXY7+7PsNlL/6I4t1VnqVjks8VuSpA/HzLq+OWJGM/F+9xLWGVGwl6Xhvx2ZK14y7tPJNyp8Jsyzmnqze5PW9iYqOd5fq5vH5VMl1AqiRQ4iLD6aOSVnUyn0+euC55H8WYXlFZ7OShuDK4J7Fz2x53KV8WDgak5ajE99Fbvz0YgB4eYl8kCAYCqhyOQpFpFr8LVGzHOz2GYW90L64YdkWmJVKkyVa0wzRtLM4Nfok8jSG6+yCEChaDwiqHgKJhyGiMK2NsGmNsAGOsL2Psnvrok09GgkFKWk8TGspr4qbVRVaTlU+MT3pMzxzKFQPZpM9uca2oSZiWu5pYAkEiiwUmXYtr65ywQ9l1lsPRzy0vS5cjKxzAOYJLYIDkMXF2i6ssm6d9QhcOEoJE0jIbORbFNehQXEVSlTWxEwpaay3ya1RaFTU/86H0WE8N2aGgJV5Vdg1CQTIV12RW4WS7B84eiX+eIq/MlGDMzNTrx+Kam5Xa4ho0xk4YtWg5HSSZf+0KXDSeQIVh/SrIDiHBmDR2z35PRKVYNoE/sJdVeY/Fk5YvN+unmFXYWg4ndaZAvlDEF1Y277Em8fHOSK0Z41u3i67tBYaSs7m0yhL3+5d3f8E5z3wv7Tc3EkTQQ+kTv6PBADm8Fapj1ue9Y6tsa83dNLMv2jN+A8D+PVpbFirKa+JolR3Cof3aW2TzQrxXj5y3n5kgQ7awwhFjkHNdLK725+rDRZtdre9uVyKuMUQlC16BgLycjahEd2+biwDpSrG9h5Aqh6NQZBbGgO+fRLTDYLyy7TuM7TwWw9oPy7RUilrwXPxEtKIqnBOchdiuQwEWRKTd7EyLpWihtJifbj6Z5nO0UICQ0BgWbyrF89+sA6DXOgV0C6kd+8SYK4ri5JS7pgUDZFEgKqJxcxIaTWj6fovi6t/iuqcyhta5YYcFx664csWax9RmhYL415kjzP3kUsfVorgGCQ+cNdKhiNhd6CJGwiNZkh27xXVneQ1KyuUWrJpYmoprwGr95VZubnENBwPJpFuarvTlRAIW+WWWMD2BE4FBcBUWrlV2OICe7fIcx4njAFYLmJtykOthlRWfVd53VSxhnmeRJBbbXsMzlmDm81yQHYKmMamFqkvrHMtnMUZRJnvHVtm4+3R9EtE6N4xYQjMtm24uq1xPiYQClizGqTL9AslSS/z5tGfG9bK4cmUoQGSx3H1/2zFYftfxAJIW139MWYLVtqziq7bLs/vmRkKeFldxn/59s8pYHUvgiS+SNXXb52dZLN9+kwPxGM9syXUP2+pVl1XHTCVdlO3+s0bYDzVxUyb56fDnQ1S0VxgZh4HkAk5hTtjynbArrhtKKvGPKXKnGjcd3q3udkhIrjS2dzJu1v79CJD+O2B/dwVVORyFIrOsmw1sW4yPBhyGHVU7cOWwKzMtkaKW/ML64AdtIC4PTgcl8hArPQDhwvmgUFnqgxWKNGnWiqs4SeUTFj4ZCQYCiGsMJz/+Df71yXIASQuWzFXYPnnnkyXRmsETJwWNyRCnoiZuKkCxBEMgYFX+RAugGPsqIk7MC3PCjklwaVXMUs9z2ZYytMoOob1hMY2EAhaFOWCz+nLEiWU4GEBhbhjnjdGTvfBrZ5+rh4J6PJjM1deiuIYD+HrVThx+/5fSc6z2YXmzjhuwXDuewIXHAUeCAfMZ4Apldsjq3imz1IUNi6vGgCtfnudoFyCSKnPhILm6Cru5cQY9zDr8GeFjxRIaqmMJ85p61eHlxBIaymsSiAQDyA4HkWBMauF84oL98ODZI/HfC/fHUxfub9boFMcXISJcOLYHPrrxMBw9qAOiCc20mNuVA/MY4/9QgCxKjh9LO7e48vtQWmlTXD2uI/9e7KqIWlxxs8NBUxEWXaO3uJRXGdmtEM9dMtqsRZqbRowr4FwkqYkn8J9PV0qPvev0YY44djd48inZM2ZXXMur41IX835uCbLgXv6Jvw/4MyeOIyqaXK72+RGLhTodV2j+PT5uaEcMFJ7NeEK+EBOkZE3cw/q1R08jNMPuJh8wnkW7t0goQJZ3i0KhaGTmPIVEbnu8WLYMg9sOxkGdD8q0RIo68Hz8BPQI7MCEwDxES8YBpCHS9ptMi6VogTRvxVX4mydXEq1Y9lX8DgX6BFCmuLpZOMXtfBIcCVmTz1TUJCwTdW5p6No6B389cZDFJa1zoTw7qqg46Yqr081u3ANJhXD2qh04vH+Red68NZ+LEazur/ZzEM/Nfp3sE7qwURYkLlFAcsLJSXJBljPmTCTdaaKuYAqKa9hqcY3YkzPFEsgOBy2LBjLFtVV22GGdE61DBLkylx3SFUPuai66CsvcOG87YZCntdF0FTb+r45p0ISEV7LEQa1tmZ2jcQ2V0Thys4LmgorMglZUkIXfHNANJwzvjBOHd7bsk51rgHTFZXi3QkSCAYvly836aZ5PwLqwI7O0c7d9Tlwo7wMAe6qSixNeYwLJJE9Tf9kiDQMArFlrowlNqlSddUA3jBcS/ugxru7j2t8Z9u+N3VX4ACF2evzgDh6lYZIsueM4c6EgS6q4Wq91eU3cER8PeCeCcrO42l2F+b2xLyIkFdcsyzVJ5aIsws/gqsP74CghM/H0JVvx6hxnwqlgIBnPHAomS/dwmQ/vr7tKB4mgacyx6KZ7c7RcxZWIjieiFUS0mogmSvb/gYiWEtHPRDSTiHoK+y4lolXGv0sbV3LFPsHOVcDK6fhi6LHYsPdXXDn8SuUB0cz5TBuNX7UiXBWaBhZrh3jZCIRbzwUC8trdCkVtad6KqzAX4ZM7cfJsh5eskSkE9lg2Hh8bsrj86m3ys/QYMm4ZqKiJW+pB8gnstxOPxjXj+lpchd2y14oT86KCLEtZFM6OvTWm/NvKatCvQz4ivC6rMfnk7/5AQO4mK45jV2yTxzpdhYNElqQ2HNHi2tZmQbJPcK8Z19dxvBehQEDqKswtrmt3VODLFTsA6LHFGtPdKUUFwm6B6do6x8ygKp6O+LyQi8U1K6xbt2584ycAsCSH+YckJvaKw3pbFFf7/TAXWQwZucsvV4hlrtkF2WFLApxoQkNFTQJ5kRACAUJVNIH5G3Y7jvOyLsn2iVvCwQBiieTk3610Ce8mZKvjKrO42q2NvD1fHOGLE1wJay9xm+ZUSRaivEhozBILye8LX+Tg9ywnEvK0Grp9fzh7KpMu82fu3xUH9UmWxYoEA6aXhhd5WSHzO1sgeSc4LK41cUvZGo7X/a9xUfaTz6fV4mq/d4EAITscQFFBlkUZTEcx5O/yAJGvZGGBQDJuOyS4/QYDhCV3HIcXLjvQ/Kwx5zs/aCRoa4kQURDAkwBOADAEwPlEZH9BLQAwmjE2AsA7AO43jm0L4P8AjAUwBsD/EVEbKBT1yZz/ggUjeD6xAz0KemB8j/GZlkhRRzQE8GLieBwYWImRtBrRkiNAwRpE2szJtGiKFkazVlxFePyX3UogwmNcAae7o719XLC45tmS8ORlhZAVCuLJC/cHoFt8LNY7uyVGGCoSDJg1JUWsimu2RT5Rtmhcw2Uv/gBAVxr5ZJtbw3jcF5G83IMop1u2UfvWpKuwUwERFVd7oqdCwTr4x2MHSC1BXoRsJSu4IsznoGKCmHJD6cu2ZRW2T9i/nXg0RnZv7bC4ivcoQPKFj1aGlZBnbu3aJhk3OqhTAZ6+6ABL+yCRRXG1u3qSbZGlvMamuLq42PbtkIxPjcY1VNTEkWdYXEsqoti+twbZ4QAO6ZtUlLwshzI9gWzKfyye2lU4uWgUsCTyqYlpjnNvn2dVRO1lqLgVcJeh/A3t4l7LU1ZCSIZYe1m0lvPvUMimuOZFgp5WAPs7w67IlgjZiu2Kt+gtkAp+vVvlOD0awsEAKqIJfLdaz+Do5irspaS5x7garsI2xdVuLQf0+sJDurSyXJNAgPDoeaPcBxbg38VgGmVq+OULBghlRkx065ww8rJC5j0lSpYrmzCkI04crtecDQXki1MthDEAVjPG1jLGogDeBHCa2IAx9iVjrNL4OAd6HXUAOA7AZ4yxXYyx3QA+A3B8I8mt2Beo3AUs+h/mDp6AJbtX4PJhlyMYSJ3oUNH0mZw4EmUsB1eGPoFW0wXx8gEIt/0WoFjqgxUKn7QYxZVbgfgEzcviCsChRNnbc+tSKECY9aej8PkfjjBjwbiyxieIFTXW2qWrbcleLBbXYACdWzvdhUXrZMdWWZYJszhhXbK5FF+v0iepOZGgacG1u6QGSB7D1UGw1nFlxplz00rYsLjurnS+fEQFwF6eorUgd0iwcISDhI9/dxguEBQJGfaswkTk6jLKJ7EF2SFbHVcX5ZxgyVZqtxTJjmuTG7F9Tp5fgAijurfGiG6FyW0BQjSRtGbZkxrxMfhkn2cHzjXcr2WeAYxZEyvFEhr2VEVRkB22TPhzIyF0Lkwq1l7ZcWV3X2wdCQb0Oq5xb1dhs3xK0GpxrUlolgUOAGhrW+TgycbsLp28nNAQD8XV7pLrhvi8ifLw8+ELOVwBlbl/i9i/N/wZumZcHxzYqw127k3W37UvEkVCAd9ZhfliVCvJwg/v94Ln5gIA9rq4CnspaTLLPmC9n2I7u7s6AEy76TBcd0RfR2z/ySO6ONqKvHT5gVhyx3Hm5wD5K88ECBbXIJmLBJ1soRi6xVVPzpRvLDgCLd5VuCuAjcLnYmObG1cC+KSWxyoU6fHTy0CsEs9nMxTlFOHUvqdmWiJFPVGBHLyZOBonBuaiM0oQLTkCgVA5woXzMy2aogXRYhRXbnElD4urOKGzWyXslV7M+p5B3QWuX4d8U3Hlx/JSJ5VCVmEZogIZdEkKIlqxOhZYJ1+i3DuFjL3ZoSBGGooST7ZjuvuS7k4n8ukt4yxuppGQNcbVbRrnVYpEdLm0X3LRMiNOFMPBAIZ1LcTwroWW9qeOtE5yQ8GAo083a19yzIhlku5mvQkQISrEKVtdheWulW1yndlaxeM7FWbjwxutybfE+E67iy0fki9sVNgsrrK6uYB1gSCWYFi9vQJ92udZrMZ7KqPm/QW8lQGZ5U/cEjZiXPl3IlVyJmeMa8Lh+u6WmChu+yI+e8lo/OPkIZbntraIcosWYK648sWjyb89GH86bmBKxdWuMPPr36EgC9nhoOW7av8O+XUVBpKu1jKLq93K62Zx9VJce7TNlW5P5gvQx3jonJEY2LEArXOc947ImaU3EEidoKkgO4S8rJD5vLktGsnQBIsrx6G4GnHfCY3p717LopavYVo0RHQRgNEAHqjFsdcQ0Twimrdjx476F07R8kjEgLmTsKT3WMwpWYyLhlyESNBfkjpF8+Dl+LEAgEtDM5Co7INEVXejNE56IT0KhRst5qebKwWmMiCZlYiKg30ibU/q8s0q/YdYnOjwiSo/lluDyoWswgDwohFfxbFPxGQTM1Eee/1OcSK6aXel+Xd2JIjjh3XGzFuPwPHDdBc4rhwSnApy2zyrUuflPioSDpKrW6PFBdQ2nmiZ4SVodNl0RFlev2os/mNzoQ5LrCJu8ZXimOIxbrF9BKtiKJYmcYtxbZ3r/gPrNo7ohmkvZ2J3a+euwrlmjKszPpaBWa7BrooodpbXYEDHAosMGrPeXy9lgHsk/+m4gfjTcQONbaJLuV52iC/cuN0DPpwe45qUvVqmuErqB4vKMWdgpwJccVhvh1L07nWHuJ6PG6LcFotrkFtcA+aYNxzVL2V/9uzN/PoHA4SsUNAS28uV45NH6ImxiMhiEfczjt2jQZQZ0F3Lq2IJ5EuSpIm3/6Fzkt+zkd1b451rD5aOy58ZbtU9eUQXzLhlnDT+XkZAosw6x+Du/4KrsA9LKGPJY8LCc24vIUWUjHEVMwknNNaSk8FsAtBd+NzN2GaBiMYDuB3AqYyxmnSOBQDG2CTG2GjG2OiioqJ6EVzRwlk6Bdi7Gc+3LUJBuADnDDgn0xIp6plNKMJ0bQwuCH6BXNQguvNIBCK7EGr1S6ZFU7QQWozi6ifGVbS42K0SYkmIOWtLzDIWYnIfrtzmGZbWoJGUpDKasEy4u7WxTkjtSoPMCijG8NldUkXLz8bdybhOrjT2LUqWuuA9y+I07RYke+IiN8LBgKszsaiMDelcYNknWmPDEuupqGj1bJfrcEENCcouJ5XF1V4D1003J1v8qbhw4RbjKlpcP7JZVt3GEcewxwbak2E5YlxtyiOgT9hldVT7dczH3mprrKeo1Hgl5+HxhSS4aYoLFWHDcvvnd3529Gs5HyQVN43p5zNnbQmqYgmL2zgAtJMkW9pbHXfE9cpqlwIwS9akg/jsiM8mVzDdEqe5Yc+WzK2f/L0gwpXjR84dhV/+qa9In7l/V1x0kLu7PP9+19gWzKz9Ju8rdzWXJWcSv0dn7Jf0/Bw/qIMlfECEPwL2+213+3bDT7kZe2Zzvb6qr+4tcbFmfzZZgwHoWYUNiyv/riUYa8nlcH4E0J+IehNRBMB5AD4UGxDRfgCega60bhd2zQBwLBG1MZIyHWtsUyjqBmPAnKewtn0ffL7rF5w76FzkR9zLdCmaL8/FT0QrqsTZwa8QLx+MRE0HRNp9CcBfWI9C4UWLUVz9xLiKiluBzXrRq10ybvC8ScksaKLViiu32YLlJj8rhPKauJkcyT6OTBaZUj1AqF1oV+DE+LjtQtyctHao0VSWnMmu9PEJ6ZED9fITo7q3cfZntGMuFlfRanH8sM74w4QB0nahoNP6IirOsjqdenIm67aUiqvNVdgNomRCq6xQAP2FOpdumU3bCgmF+hTlWfa5jSla3drmZWHG78dZau0Cyeehkiuuxn3dLCSf4s8Ag/waFOVnYcnmMss2fozuNp7aVTgoWJpFxZXLy+MI3ZJ6JV1L9T9u+t8CnDdpDraV1aB9gVXRbCOxuJZWxRzu0W7W3dok1hH7EmOzebZut/NyY5jN1Z2fd4DIkfBITADF3z1EhKOM757sfLiCyPuSKfGiosZLCPHsw4+eNwr3/2aEo3/xe+jlDh2z1da1y5UKP0mWuFyiq7BfuFE/FCS8cNlo3HXaUGf/lKzjqidk4seyFhvjyhiLA7gRusK5DMBkxtgSIrqTiHhA4QMA8gG8TUQLiehD49hdAO6Crvz+COBOY5tCUTeKfwQ2zcczXfsiO5SNi4dcnGmJFA3EQtYP87X+uDw4HQEA0Z1HIZi9DaGCJZkWTdECSC/NaxMmfYurdfI1vFshThnZBR8t2mzZLipX1XwCGRFdDkOoqInbXEKtfXewTdrtE6Ybj+pntY7ZZBf38eyZAJAT8c4UK1oUThjWyTEB5ddowpCOWH7X8a6T2Egw4Kj16sZooValNU7SaUkRz1OW8MeenMmtnUjr3LAlm6ub3AFKWkPvOm2YZZLtFmcnTtgd7t8uk+Ce7ZLxg6EAYWCnAuREgohWaWYfyazC1uRfYgyleO9k1yA/K2S6lN535nAM61qI6Yu3SmW1ww274nmLoaaO58YtOFDIKgwAPxfvMXeJrsFHDixCtuQcSqtiNhdl93jH2igdoqVapnx5xXLbuXXCAKfiGkzez+Vb7YsI3n0XZIfMEkCmjFn8OXB30RbfT5v3VANIWlxPG5W0rLpdLy+332Scv/XYHL+Kq49bZL6nzWfQV9fGIUmL69GDOkrbBITkTMFAACTUfW6heisAgDE2DcA027Z/CH+71h9hjL0A4IWGk06xT/L9k1iX1wbT967CpUMuRdvstpmWSNGAPB8/AU9FHsP4wHx8WnYAtPYzEWk/E/G9Q9GCbGaKDNBinh5HjKtUcRUspRJ3us6FTpc5UQGujjotrnlZIVTUJKxlT2wTuy6tvV2H/3jcQMskKhyQK5gAUFadnNzKJrJmHKlN+br4oJ6OtqIC4mV5CXnEuNrh5961dY7lGL0ma1I2fVtSPtnEXjyGk5UiYU52OGjp101sApnWULvLNLm4CovtHDVZXWbcNx7VD8cO0SfVQUGxAZwWygqbxVXEvD6MSe97XlYIz116IO4/awTOG9MDw7oWmvKSa9otHS2Vq7Dt3oRdlUnr+YjhqqKb9JMX7C91y122pQyvztlgfs62nedxQ5PKSW2UDtGqX1fFNVei8HHvjCCRIx41lTVXllCJZ5c+2Chr1CVFNvItpbqFXpZV2O35lL0HOXGX74ff6+THKs7lEpVQv4tk3JnBK/FYwEjOVBlNWBbCeLImhULRCOz5FVj2ISb1HIysYBYuHXpppiVSNDAztANRzNrjytAnAAKo2Xk0gtlbEcpflmnRFM2cFqO4citU0uLqPDXR1U6WwEQ2Gba4ChsWLbGfvEjQaXG1Tcr9uAqLY3vFnlotrs7JtyWrsK2UjB2/rpE8OY8f+AT85JGdHTVj+WnzUcUyQTIrongMx8tVmI8tnnf7/IjUxTIQgKC4WvfbFdeJJwzCySM6WxYUvCyu/zl7pFkzNBQMYNwAPXGJ6Eqqj2OzuEZ5jKskljHESxfJr0F+Vgj9OuTjnNHJvCpmXGyKckc8sZieddWaLEfvx93FWyRgOx/RemqvmypzDb/tPWvyBnss7zMXj7aMNe9v6RWtF5W3nLDzGlfHvLMeTr3pMLM2ruy7w7cRAc9dOhqvXDHGbJ/KU8AeugAkLa6/Hz8A3/zlKHRrk7TeJ0tLiYqrYXGVZRV20fQLPCyuUbMkmFX2VNeJ48cqzuVigtXfL8kYV/drGwwQpizcjITGwBhLugqzlusqrFA0OX6YhPWhMKZVbcY5A85Bu5x2qY9RNGsSCOLF+HEYG1iOYbQW8bKR0KLtECmaCXkRPoXCHy1GcU0WnLdOnjlEVgul1CohmciIk/57zxiOoV1aWSaQeVkhlFVbXRxdXSn5OBLF1ZIJ19j/3wv3d5SIKRMS8Mgsc7wXu8VVakH0nVU4ILW4yibI/TsW4MMbD8VfjhvkKDFkv77iZZIp86FgIGWcrlVO570PBQP4+HeHOdoSkpYduwXR7ip87RF98cQF+7vGCQLWe3rWAd1wzxnDXeXi521X9Hispb3sjtgHY/JrIFPOxWO8EF2FQxKl06+rMJn7ubuxoLiGRcVVHkNsxyuDdIAI7SUJnvwis7iKbu5u8ohJhOyIrt+dC3MwbkCRVMEUMesPyyyukWQSOPGdAyS/L2G/FleXy+1lceUxrnalu14VV1uMazpW0GRcrJcMyb8XbSw1M4PnhIOuCdUUCkU9UlMOzH8Fz/YcjEgwgsuGXZZpiRSNxOTEUdjLcgyra9Cwum5GUFldFXUgIz/dRHQ2ES0hIo2IRqc+wpsv/3ikYHHVt9knxgSrBUemdMkmQOWConhov/aYetPhlolcXlYQu4WYSjc+u2Uc3r1OLzshs36Ikzw+GT1heGc8dv5+lrWpPZXJsaSKKyXdUMXzkZ2bf4ur033vwbNH4qe/T5C2H9GtNQIBsij9GnNatEVLCZd74gmDzG1i7VeOl+IaFFw1RWTWZosbs02pcItx9bKEe024+VB2i2vQprhu2l2FgqyQ1PomKigyd2m5Rd1pPZXB94vZlEULu39XYau3g1jbWFSsichXBl8vK6Vdgg9uOBTXHdk3ZZ8cu7fCNeP6pFxwEp89uzs/YM0qnJTTqWDKyM1y3tNcieWdI1MKN5TopbKk5XDcXIW9Yly5R4JjEdDfe8NvkjQgaT0Vz+uCsT3w+R+OkB4nlsPxUpBFGYZ0aYWrD++D208cjPPG9FAWV4WiMVj0P/yaqMBUbQ/OHng22ue0z7REikZiL3IxOXEkTg7MQUfsQrx0FLRoO2S1V1ZXRe3J1JrzYgBnApid7oHd2zprH/Zun2eWhTCzCjviFslWDsM9PlRkVI/WnvLkRULYVZlace3fsQAH9NSTEcgmdOIW+35R7xCzrnrFpdprKMomm34noLKswtnhYEr3R/EQmWuezOp27RF9MbhzK3O/01XY/Zy5bmC/97L7Wiq4XDtiXCFfXPBSPrwsiHHTFdfqzp48Vt++aU8VOrfOdllkMNx+GUuZWdns13QV9sZUAAKUtJZ6uAq7umbaFo3Ecj72Z1XmKmzHa2HFfg37FOXhgB7eFlMRZ4ZtHxbgcMASi2nHvjABJN9HboseSdd+wqUHW+PQ8zySIJ11QDfHtq9X7QQgt6K6uQp7Ka78XWNX6G84qh+uPry363EcP8ZTR1bhQNLLpSA7hL627N0i/PHyeo3xe9G5MBt/PXEwIqEArh7XB+FgoCWXw1EomgaaBsz5LyZ16YNQIIwrhl2RaYkUjcyLieMQgIbLQjOgW12PQjBnE4L5yzMtmqKZkhHFlTG2jDG2ojbHTr3pcMz96zGO7Xxi75awg2BV1FrlhB2TZ7sid+8Zwz0VJUB3Fa621XNMhWzSW6ssqRIFxowjdVg3az9Jk8W4+snPIh7DmMxVWC4Td3WU1nF1qesJWJPjWMaRXNu4sABgt57pSYqc43hdQ6/7x91u+TNpxoBK6lB2LsyRTsRTlcOREfFpUecu3QGyJq8xxxbGm3jCINdyKPbEaIy5K672RQCZq7PXd49szbNCAc+FHDutbbWS/SQcygom+5cpojKLK8fPnbjjtGGWLNSyBFCcO08bhkX/d6xDOSQCciXXwe359LS4Gg+G/TkqzAnj9pOGuB6XlMWHq7AtxtWPtwQnWX849feyT1GeY6FNWVwVigZm1afYWLYBHwdrcPYAZW3dFylmHTBNG4tLgp+iHUoRL90PWrStsroqak2zi/LJi4RQJIlt45OShDHZksW4irTKDuPH263JXeyTQD9WmFY5Tre8VIiyPXnB/rp8HneCJ3jh7NejNbq2znFx/3NaffTPaYtpEg6SI8GPv0kfs/xlymCzzNnhGWhlJXQ6tnJmVjVlClj/58hErRLi9JxZhZ31Y7k8bngptXHNqqDaa6WGLIprtqfbL2PJZz1VPU1+TCpFV3QVlmUV5gs8BVkhXHtEX9dkT9wtll/PhEuMqy6b9Rxlbu8yZZbjKJMUDHguathpnRPGun+diCOMxFm+FFehf9nChtziarUopkJ8jsb0auvZrjAnbLFqA/r7URpD73J6XuVwYnG5xbU+sT/rMjfr5Xcdj4fOGek4Vnxu3eD9FciS8TW7Xz+Fopkx50k8W9QJwUAYlw+7PNPSKDLEw/GzkIUYbghNARDU67rmFCOYVyv7lWIfp8F+uonocyJaLPl3Wpr9XENE84hoHsAtp852fOIZd8mEaZ8gFRVEHJO5dGuGAsCgTgUp29gRxzlpRGddPo/214zrg5uO7pf8fHgffDvxaGlb3rX9GtXFupAdDjosrn6ujdXiyhz3wG1CzEuJMOZUCLvYShYdN7QjHjhrBAAhZtSHZVdUXGUKqVwx8VKkXHc5YgV5W01zWlz7FOVJ79XYPvrixaDOBaYlUqbsWeQ1FVfvdnyhoCA77Bnj6icuFZDHyaayuMrOxTs5k/WzPRTADa4MR0IBEJGpUPpxXRbrGXu5CkvVVJ+aK+/jn6cMwen7dU3R2ro4ALgvUrgtrHh9j7kC7NfCXxvscgUk5XCyw0Gp/NxTwMvll59DOu7TCoWiHti6GMUbv8VH2UGcNeAsdMjtkGmJFBliLeuCdxLjcGHwc3TFDsRK94cWbYMslWFYUQvcl9vriFeB8zT7mQRgEgBkde7PiFwS0RiTK26B4O6mAzrmY+W2codi2D4/y1nSxPbZjxVmaJdWvs5DRGZp9FIsiQi92idjvbyse3yP0+Ja+0laTiRocfs8f0wPHN6/KOVxotXuwF5tHdlI3ZR+rkiVVccccrezWduzQkHTwscnqY7JsOTcq6Ki4ipxuZbceq84Vi93RdPiasjZq10e1uyoMJUGUd6hXQotsnHO2K8rzh/THZ0Lc7Bxl56EJ5bQMKRzK9fryF08Uy0y/PG4gejeNhfHD+2EWSu3A7BmBOaKfUSw+sqQWZA5OeEgZvx+HH41ZHe4Ckusx14Kk+ye+nEV/uCGQ/H4zNUYYnxv+XPtlXjLHFM4L3k5HF1eMQ49Va/2a8nPq3dRfkp5ADgsrm7XrDbf/78cPxD5WUGcYstsznn9qrHYapTgqS32R8VNTs8Eax6nxvv3m0VeoVDUE3P+i+fatAMFQiq2VYFH47/BGcFvcXPoPfw5/ltES45Cduf3EMxbiUTFwEyLp2hGNJji2lC4KQhZZoyrPpkZ1KkA0246HETACY9+LXUV5nU8k31b2/hRXHu0zU3Zxk6qcjgyROXDU3EleX91Kf2QY7O4Tjx+kK+YWT6vfPS8UejSOgfrdlZY9meHg3jhstHYVRGzbDcV16q44560y7PGJkZCAUc2YUepGomoohLt17paW5fJYwZ3wAMzVuCk4bp1/eHzRuHrlTvRs12eMVZSwCGdW2HBxt0SefQSK0DSZTWhMUy7+XDXcfk5pLImZoeDuPSQXgCSiZesyZm4xdX7nidLmjjHy4kE0K9DAQYaSrZd8ZM9/16uv7Kvix/L4KBOrfDkhfubn/l5+vmuA95lW2T1a5PHea8q897MRRifOlXCVnNKlnFa78/a4RtXj8Xq7eWefbfOjXjGsh7ar+7xavZ3oWgFFUWWXY9kORwPiytxV2GJ4qpchRWKhqF8BzYtfRdTunbAWf1/g455HTMtkSLDbEE7vJoYj8uD0/FM4mSs2bM/Iu2/QFb7maisGAB/mSAUisyVwzmDiIoBHAxgKhHNqGuffFLNaw8SEYZ0aWUqfAS7IucstWL/7CfGVVSSnrhgPyz8h7xEjIg0eUuKoUTlw9viypU325h1sbiGrRbXVJPwZDudkJlNl8uY5OhBHR0ZUtvl68ppNKE57skgI+NwtzY5Zlt7WRk7soWCVK7Csq5k/Q/vWigd0yJzp1ZYf99JGNGtNQB90YS7iNv7bZMXcTyruoxCORzDhdZubXMcE/IX4ypi1nGVuQqnyFLMPCyuHWyxyXa343jCmeAsO0UdV0f7NJIzcfhj7cdVWES+sGF9BwHAH48diB5tczHaJV6VZy2/8rDeANwzT7vBQyP4e87tPOzP7iF92+OSg3v5GqO+mHbT4Th/THfLNvt7yT1htcxVOHU5HL5AJSsxpSyuCkUDMe95PFeQDQoEceXwKzMtjaKJ8FT8NFQhC7eG3gYQ0mNdc39FMG9VpkVTNCMylVX4fcZYN8ZYFmOsI2PsuLr2GbZZXM3txkxINkdxuqlZP6c7me1cmOPIVipDpkSmVFzTtrjat9fNVTiFjiSFmVlzuUxyi6ids0d3w1WH9cYNR/ZzXKvCnDDW33cSBnTULXfDuxY6kh7ZkboKW5IzOe+zPEGSc9sbV491rTXpF2c8tqSNMHZWSP6s2+H1Vv3EI3PM+FShbz5Oqu8Dd5GV3YdWNsVB7Ou7iUdb3Gs5XhZXqYW2FrGYpsU1hTXZxEeMq3hfhncrxOw/H+U4f077/Cysv+8kHGJYL/lt9vt15YsXPFGXW73WuiRnqy+GdGmFe88YjqcEi7cj0zgRzj6gGwZ2LMBFByXLA8muh5/kTJWG272KcVUoGol4DbbMfx4ftCrAmf1/g055nTItkaKJsAut8FziRJwY/AEjaA1iew6AFitUGYYVadFsnaWKCqyxjnwibLdCJV3v9P9vnTAANx/TH0DqWEi/yWg4fifOtSmH49/iavzvkaDobycNxiW2mpFeiOd109H9fCnngFDiwmPxQD5eEH87eQgKc8Ou16W3EfN7QM82KRVX2QRVjC30il0VkVnZCrLD6NfBXzyiG7Kaw3bEkj38fpw2yjt5TzI5Uy0UV+ECcQsiV4DdYlxjtiRUXogW5C6tcyxWSs7Bfd1dUWVDpEpCJYO/Lvy7CvMSLM59/HrHarPKw/vg3xWfblO81qvdhd5OXRau6hMiq6eLLEFeh1bZmHHLOHRtnazZXWmL+2ZgQh1X93OrqIkDkMe4NpFLolBkFHvuiTqz6E08F4kBFMSVw5S1VWHlufiJ2MXy8afQW0haXTcgmLs606IpmgnNKsZVnGf8ePt4PPr5KgzqbMTMuVih+ISUH/s7Q2kFnBMe+2e/k9kA6RPghlRcxWO8LAX8HLzK4Vx1eB8/Yjr6BICTRsgTtcjQXCyuaY3tckn/dNxAXDC2BzoX5mD5lr2e/acqe+H3PvtJ4FMbuKI3oKOuAMuUMvEciAiL/nEs8rK8FTV+/dNR6GQZgYd2aYUz9++K64/UM1u7uYrHPSyubuOYx9q+t3NuOwadCt1LH8mUldpYXJPuze7H3n7iYKzdaY0HlZ0ht3DL3J79YtbA9bn6fP1R/ZCbFUJWKIA7Plpa63EbE693mZvFuEOBswTaaaO6YOHGPejeJkdyhI5pcZXEuBI5y20pFPsa2eEgek2cWi99hRDHWzl3492eBajadQAOvvunOve5/r6T6kEyRVOhHLl4Mn4a/h5+HQcnluD70tGItP8CkaKZYOzmJrPIqmi6NFuLKwDcPL4/jhuqu6FEzIye1kmj6d7p47tQmzqugF47EfDvkilVTFIcIypNfhQDe4v6iufyMzYn6conV6b94HZMdjiIvkbmVbdswqn64PhVSP1aZtMlOxzEMxcfgP9dfRAAp7WtY6ss8xnjFOaGUyaLqolbLaV+MOu4CopkKBjAQ+eMklqWRWXRtLjaruffT3ZP8GM/lsvrpbS6EQgQ3rzmoLSO4acZ8XAVvnpcH/zrTL3kEvOw8nUykme5uQX7QVYD14vscBDXHtE3ZU3fpoT42PLv5mEpEj0d3r899jfigTmXHdILK+4+3hE/LVIR5RZX+T0ZP7hlJo0houOJaAURrSaiiZL944joJyKKE9FZtn0JIlpo/Puw8aRWNHdOD36LD9rFobEAojuPyrQ4iibKa4kJ2Mza4i+hNwEWRLTkKIRy1+PrTV9nWjRFM6BZK64iEVs5HI6ZrMhHH446rj4tcbmG5cuvUieb9KbS6cRMrX5iXB11XOtJ6fKrzAPJSb49OVM6+IlDC9XCVVgk7DO9qF/LbG04bmgns9SP6KY7fnAHzP3r+LQWDDgxQ3Gtq6uwA2PX6J5tsPiO4/D0RQcAgJml255VmCce8pTVOPb1q8bi27/IaxT74SCj3q1fWJpZhb24+vDeePDskTjDR/1VN/g7KFXiLTvpLE5kGvH9x99Lz14yGl//2X2iS0TmQpW4LZU3AX+MW0lchfm4LQ0iCgJ4EsAJAIYAOJ+I7KtHvwK4DMAbki6qGGOjjH+nNqiwihZDEAmcnDMFU/LzUbP7ELB4m0yLpGii1CCCR+O/wajAGhwbmIfY7jHQatrjoXkPIa7FMy2eoonTfGY7KeDKi33Cl5cVRNfWObj3zOEp+7Ard34nsycN191ncyO197xO5R4hWvv8KK526stYmE5JGD5p5HoMP8d0DK/ptHVTUGWb7z0j+Tz4tbjWRnmsDaK1zUt/TMXhA9rjzP264s7Th/k+hi8yJHwMPGFIR4SDAVMxlsW4/n58f+mxdrib8fBuhY749VT0LcpL3ciFdGNcOW4xrr85oFudFolkFm8/1Ca+N1PIvqc5kSC6pygt1jbfX2y9DFlyphbMGACrGWNrGWNRAG8COE1swBhbzxj7GUDt/doVCoFTA9/hrXYJBLQwanbWfvFRsW/wTmIc1mid8cfQZARAqNlxPNaUrsGU1VMyLZqiidOCFFfD4mpzFQ4FA/h24tE42UdspsNV2KcV4/aTBuO7iUejbYoEKXUh6FdxNWzLdr2jvjJopuMuy+P0gqarcPrj+XEv5opeOq7CF4ztYf7t21W4gWJc7YiLL3XJs5cVCuKhc0dZktykQpZV2A7fwy9rUnG13ocAAb8fP8DXuJcZdWTz01z8WXH38Zj++3FpHSOSrsW1ofMeBl0W4FKRZZb9avrUdgHooN7pWdNF3FyFWyhdAWwUPhcb2/ySTUTziGgOEZ1er5IpWiQBaDi8YAq+yc1Bxc7xgJZ+fXvFvkUCQTwUPxsDAptweuAbxPcOxciikXhy4ZOojFVmWjxFE6ZZKa5eVkk+GfIbGybDkVXY5wQrGCB0SUM5qA3pWlztV6G+At7TUlxNiyu3tNYmxjV1G24ddLN0uV2vu04fhuxwwLersFcCn/okoSUXXzxddhsAWXImN/giScTF4pqOdf72kwZj1T0npG2tzAoF6+Tmy88z3fjlhlIQa/sea0quwoU53kpibV9FRw3qgIfPHQkAKCpILwY6txY1fvdhejLGRgO4AMAjRNRX1oiIrjEU3Hk7duxoXAkVTYqTAt/hzXYasmI5iO0+JNPiKJoJ07QxWKz1wi2hdxFGAreOvhU7qnbg1aWvZlo0RROm6cx26giPvUzXUiFSn7VP6xtR+fKaZPM9zKbw1JebazrKm1udxXQk8SM3tw66XRe3Li4+qCeW3+VfWcqIxbWRS5tx67iXwmx/tribasyMcTUU2jQUSiJq0BhiN+wJxFJx12nDcGi/dhjWtbBB5Km9xbXpKGaz/3wU5tx2jOv+unh/nD6qK+7/zQjce4Z/93eg/mL8mwmbAHQXPncztvmCMbbJ+H8tgFkA9nNpN4kxNpoxNrqoqKj20iqaNQFoGNn6QyzLiqB0+8kA26e8GxR1gCGAB+LnontgB84PzsR+HfbDMT2OwQuLX0BJVUmmxVM0UVqM4mpO+GpRiqJ7W91aaldUs8NN5/KICqPXJJufg33aW9t5Ww9b3Fk6ylty7s3dl3kNTP99+GnLJ/mu5XDqaQHCr2W2riTqyVW4NvBT9BNjyS9rxOYqzJ/VxlL060IyS7C/9kO6tMLrVx2E7Aay4HU2sinnpZklmN+DprDWVpgTtmSFPm5oR1xxaDJBV10W0YgI5xzYfV9z/U2XHwH0J6LeRBQBcB4AX9mBiagNEWUZf7cHcCiA5lFnSZERjg9+h7fbasivLkSsTLrGoVC48pU2AnO1Qfhd6H2guhQ3738zahI1+O+i/2ZaNEUTpcVkrDBjXNO0VHxx6xFol6cng+GKT7u8CN685qAmNTkKCkqAl9UzaXG1ba/FjPZ/Vx+E/Xu2tsqRlquw3OJa32hmjGvDjtNYyZl4oiLAad1saPy4CttFithqKPNnNRMW1HRJ1+La0Nx67ED071iAowd1SOs4v1bMdg0Yh+/GMxdbM/c2pifL+9cfgs17qhttvKYAYyxORDcCmAEgCOAFxtgSIroTwDzG2IdEdCCA9wG0AXAKEd3BGBsKYDCAZ4hIg76wfR9jTCmuCikEDb3bfoivwyFUbf4NWpAtRNFoEO6KXYQpkb8DM+9E75MexFkDzsI7K9/BhYMvRO/C1FUJFPsWLUZx5ZPndC0hfYQSC1wvyQ4H0b9jQb3JVh+IbrBehr82eRFgZ4VDyaqN0pUbCTpcENNRRpJJfBp2orpfDz3t/sUH9arXfnu1y8VQwSU0nVJAdaG+sgrXBq7A+ckqzLGX2zETHjUD98x0La4NTXY4iHNGd0/dsBZ8+ccj0TpF/Glj0FgLQID+btivR+p2LQ3G2DQA02zb/iH8/SN0F2L7cd8BSJ2CX6EAcEzoW7zfBmhbXoQNlf4S8SkUdhazPnglcSwu//F5YOT5uHbktfhozUd47KfH8PBRD2daPEUTo8Uorp0Ks3HbCYNw4vDOte6jqVhdZIiyeU38/nvR/pj28xb0bm8tEVKrGqqSg9Lpx0zOZBxTmBNGl8Js3H6SvaRg3ehUmI31951Ur30CwKw/HWX53FiWImtW4cbVXPlz5ierMMeeGIi7DKfKyv32tQenFQfrl9a5YZw2MnUWcQDo1zEfK7btRX5W834V+nlO7O+ETFFfGc4VCkXmIGgoKpqK8gChYvv5mRZH0cx5MH42Lm/zC/DRzWh/zSxcPuxyPLnwSSzYvgD7dVAu6IokzWq2lmq689sjpMkP/fffhOdTfrMKdyjIxmWHOl0raqOUyw5JR3njbpg8+2woGMB3HklbGpLjh3bCKT6VmUxzxMBkopNGT84USG1xTVop9bZ2i2uPtrk4bVQXXH14H8+xDuzVtg6SurPwH8f6bnv/b0bggjE9UtYQbeoM6FiAgR0L8H+nDM20KClpyu9ZhULhj8MjszGjkKFTWXesrGkev62Kpks5coET/g1MvhiY819cMuYqvLXiLTw470G8esKrTSpZqiKzqIAEgcZ0YUsXMca1NhaL2iiu4vWojbUmk26Y/7v6ILx/fTIt/9MXH4CTRtTeGt+YdG2dgzeuGgug8RVX7g7dvY27Ive7o/vhzP264rwDdZdWu8U1GCA8et5+DZZ5tz7Jywrh0H7tMy1GnckOBzHjlnEY07thFgPqk6b8nlUoFH5gyO0wHcSAtdsvyLQwipbC4FOAAScAs/6F3IqduGHUDVi0YxFm/joz05IpmhAZUVyJ6AEiWk5EPxPR+0TU2t+BDSsXV+4aS9FKZ5IpWlxrU0+0NpNFUUF+77pD8PHvDkvr+Ewmvjm4bzsz9rVZYlyyxq7jWpAdxqSLD8CLlx/o2qZNXgQPnTsKeYZ7bUO4+ypaLkpxVSiaNwflzMS3BUDX3X0Rjzf9xTJFM4EIOPEBAARM/SNO73sa+hb2xSM/PYKYFsu0dIomQqZmnJ8BGMYYGwFgJYDbMiSHBT6fagw9a/19J2Hybw92bD/ZxSoY9JmcyY3azBVF14w2eZG0LWhNLfFNfTGwERJ3cffqxi6HAwDHDu2E9vlZvtsrFx5FOii9VaFozmhgHWeiVYJh6U5lbVXUM627A0fdBqyagdCKabjlgFuwoWwD3ln5TqYlUzQRMhLjyhj7VPg4B8BZfo5r6PlOpifgXgmGRCtrbSyutTm3ulpGeMKYlqTXzP3rMY2SyMe8ZpnQXBWKBqQpJ8FTKBTe7FcwHUtzGAZvH4xNWn7qAxSKdBl7HbDoLeCTv2Dc9XMxuuNoPL3oaZzS5xTkR9Qzt6/TFHz8rgDwSaaFAARX4QZXkdNH1CFrY3Gt65i14ZKDewEAOhfm1FmWto1Qf3LObcfg8z8c4dmmY6ts00W2IeHPYmNnFa4LymVY4QflKqxQNE9CVIXyDl+hS1TDgpLzMi2OoqUSDAGnPArs3Qr68h7cOvpW7K7ejScWPpFpyRRNgAabgRPR5wA6SXbdzhibYrS5HUAcwOse/VwD4BoAyO5Ut6zBqWjK8ynRYlobi2ttqKtl5KKDeuKig3rWWY5Pbj4cRQX+XVdrS6fC7AYfwy9kxrhmVg6/vHvdIU3q+imaLsriqlA0T0YXPY8lEcLAjUcgBvW+VzQg3Q4ADrwK+GESho08F+cMPAdvLHsDJ/c5GcPaD8u0dIoM0mAaEGNsPGNsmOQfV1ovA3AygAsZc89AwxibxBgbzRgbHWhgha2xkzPVlsZSsANNRJMf3LlVWjGXLQHTU7ix0wrXkgN6tkHX1v/f3n3HSVle/R//nK0svXeQIiKLBRURO3asi8ZuEk1MTDMxT54YNfqzRRONiWmaJ5JoNBFLYgygYlCjC4qCgCC4Cyggbem9Ldvm/P6479Vh3cqWe3b2+3695rUz193ODMvOnLmu61z171mX5Jcof1dEpPa6ZyxhcefVjNyZyZzd50UdjrQEZ/w/aNsDXvohNx35PbpmdeWe9+6hNFYadWQSoaiqCo8FfgJc5O57o4ihMomesJZrqrm4B7LsjjSM8uWHrhrVP+JIRBqW8laR5iZGj95P0zbmLNnw9aiDkZaiVYdgbdf1C2g3/xluHXUri7cuZsKiKgdpSgsQ1aS0R4B2wOtmNt/M/hRRHPvRELb9NdVcWvmiLm0zWfHA+Vw2sl/UoYg0KH0hJtK8DO/0IiuyShi+aQhrS+s//Uek1rJzYMjZ8Ob9nNVhKKf2PZVH5z9Kwe6CqCOTiESSmrj7we7ez91HhLdv1+a4xi6aVF40RB+rAkrkJdE8dOkRfHdM4851l8alocIizUdm6ha2dJvNYYUx3tx2XdThSEtjBuf9Krg7+UZuHxWsnnn/zPubzVQqaVjNq0+tkT/vlOdpUS+LkyjUMyKJ5rKR/fjJ2EOjDkPqQV+IiTQfQ3v9heIUKF6XQwnpUYcjLVGng2Dsz+HT6fTKf5kbR9zI2wVvM3Xl1Kgjkwg0r8S1kekD1f70cohIQ9MXYiLNQ++27/Fpu22cvLUDc4tOjDocacmOvjYYMvz6nVzdbRTDOg/jwfcfZGfxzqgjkyamxDXO5+u4Jo/6VHpNxPVsRaR509z5xmdmY81siZktNbNbK9l+ipl9YGalZnZphW3Xmtkn4e3apotaEooVkd5zMgcVlzJj0zejjkZaOjO46A+QnkXapO9y93H/j637tvLbub+NOjJpYvoIEeezqVdJlK9Nuelkpt08JuowREQAjWxpbGaWCjwKnAtkA1eZWXaF3VYB1wHPVDi2M3AXcBwwCrjLzDo1dsySeA7t/ne2pjsDNoxks3eLOhwRaNcTzn8YCuaSveg/XDPsGv758T+Zt3Fe1JFJE2pWiWtjf9xJxrmtHbLSOahLmzodc8xBweeUtNTkez1EJFqpKs7U2EYBS919ubsXA88BOfE7uPsKd18AxCocew7wurtvdfdtwOvA2KYIWhJHm8xPWdfpE07fCa/uvizqcEQ+d9glcNiXYNoD3NjzVHq16cU9795DSVlJ1JFJE2lWiWtjK/881dI/Vj1y9dG8dONJtMlMizoUEUky6nFtdH2A1XGP14RtjX2sJIUYPXv/jY6xGCvWX0MZqVEHJLK/834FrbvSevJN3D7yZpbtWMZf8/4adVTSRJS4xtEHqkCbzDQO79sh6jBEJAmpwzU5mNkNZjbHzOZs2rQp6nCkgfTp/CobWxVy8sZefFh2eNThiHxR686Q8whsWsSpH0/nrIPO4rEPH2PlzpVRRyZNQIlrHA1hExFpXPo72+gKgH5xj/uGbQ16rLuPd/eR7j6yWzfNgUwGqRnr2dftbUbtLeal7d+IOhyRqg05C475Grz7B27tfSYZqRn89J2fUhLTkOFk17wSV63jKiLSrOnva6ObDQwxs4FmlgFcCUyu5bFTgbPNrFNYlOnssE2SnRXTq+9jtPUyMteOZQfto45IpHpn3wedDqL7lFu569hbWLBpAb//4PdRRyWNrFklro39cScZl8MREZGWw91LgRsJEs5FwD/cPc/M7jWziwDM7FgzWwNcBjxmZnnhsVuBnxEkv7OBe8M2SXK9ez7NjsxCLtrQjSklZ0UdjkjNMtvCuD/B9lWMXfwWlx9yOU/mPcn0NdOjjkwaUbNKXBubOgJERKS5c/cp7n6Iuw929/vDtjvdfXJ4f7a793X3Nu7exd2Hxx37hLsfHN5U8aQFaNN+Frs6fsyV24p5asd30df30mwcdDyc8H2Y+yQ/6XQUQzsN5afv/JT1e9ZHHZk0EiWulVACKyIiIslu+Y7lZPaayNGF+/hww/XspG3UIYnUzWm3Q4/DyJx0I78+6keUlJXwk+k/0XzXJKXENY578NP0baOIiIgksX2l+/jx1Bto46Vkrz+a9z/veBdpPtJbweV/g1iMg6bcyl2jbmPexnk8Ou/RqCOTRqDEtRn54P+dxfu3nxF1GCIiItLMPTjjTj4p3MA3N6bz531XRx2OyIHrMhguGQ/rPuS8vNe5dMilPP7R47y95u2oI5MGFkniamY/M7MFZjbfzF4zs961Oq6Re0I/63FN0A7Xzm0y6N6uVdRhiIiISDM2ZdkrvLDiVb6+cy9P7Pg+paRFHZJI/QwdC6f8BOY/zS1pvTik0yHc/s7tbNizIerIpAFF1eP6kLsf4e4jgJeBOyOKQ0RERKTFWLFjBffM+H+M2FfEjSfcwQrvFXVIIg1jzK0w+Axa/een/Grodewr28dPpv+E0lhp1JFJA4kkcXX3nXEP2wAeRRwiIiIiLUVRWRE/fuN7pJcW8VCHEaQffV3UIYk0nJRU+NJfoH0vBr5yC//vqB/ywcYP+OP8P0YdmTSQyOa4mtn9ZrYauIZqelzN7AYzm2Nmc0rLGvcbE1f+LCIiIknqoZm/YMnuVdy/O0bPi/6UuHOjpMXZV1LWMCdq3RmueBr2buHC95/hksHj+MvCv/Buwbv1PnWDxSgHrNEmNZjZG0DPSjbd7u6T3P124HYzu41gsfS7KjuPu48HxgN06H9oo2aWn89x1R9yEZHGcs7wHhw/qEvUYYi0KM8tfo7nl/6L67bv5NQLnwo+4IskiFbpqQy49ZUGO9+lqdfyqxWP0XVZe0r7dueGqT9k74pvEyvuccDnXPHA+Q0WnxyYRktc3f3MWu46AZhCFYlrU8rKSAWgT8esiCMREUlej31lZNQhiLQor376Kj+f9XPG7NnLTUOvhkFjog5JpFG9UHYqI2wp3097hblrv8ns/u+S1f9x9q74Dl7aKerw5ABFVVV4SNzDHGBxrY5rnHA+M7hbWx69+mgevuLIRr6SiIiISOObUTCDn759G0cXFfNQxkDSzrwn6pBEmsS9pV9lXuxgHuHvdF19AZZSTOv+j2Opu6MOTQ5QVHNcHzCzj8xsAXA2cFNEcXzB+Uf0on2r9KjDEBEREamXDzd9yP+89UMGl8b4w85SWl3+N0jLiDoskSZRTDrfKb6JfWTwVOxJWq8eh6XvIKvfXyGlKOrw5ABEVVX4S+5+WLgkzoXuXhBFHCIiIiLJaNn2ZXzvje/RNRbjTwVraXfpk9C+d9RhiTSp9XThG8U/prPt4sXYE7QrOI+UVuvI6vs3sJKow5M6iqyqsIiIiIg0vLW713LD6zeQXlbMY6s+pesZd8OAk6IOSyQS8/1griq+gyyKmFTydzquO4O0Nsto1fs5IBZ1eFIHSlxFREREksTWfVv51uvforBoF39atYJ+Qy+C478XdVgikcrzAVxR/P9wYPK+5+m44XjS2+eR2fPfoOUwm41mlbhqlRoRERGRyu0p2cN33vgO6/es45FNWxnafgBc9Ig+QIkAS70vlxffyV5a8cqel+i0+UgyOs0mo9vUqEOTWmpWiauIiIhUz8zGmtkSM1tqZrdWsj3TzJ4Pt88yswFh+wAzKzSz+eHtT00evByw4rJibnrzJpZsXcKv92VydOE+uOJpyGwbdWgiCWOl9+TyojvZ4u2YsvM1Om0fQmbXXNI7vx11aFILSlxFRESShJmlAo8C5wLZwFVmll1ht+uBbe5+MPAb4MG4bcvcfUR4+3aTBC31tqNoB99+49vMWj+Ln7UeyilrPoJxf4Ruh0QdmkjCWUtXLi++kwLvxqtbp9NxV19a9XiFjK5voGHDiU2Jq4iISPIYBSx19+XuXgw8R7Beerwc4Knw/gvAGWYaS9pcrd65mi9P+TLzN87n5/0u4MKP/gMn/hCyL4o6NJGEtYlOXFl8B8u9D//ZNIvuO/qT2e0NWvX6B1hp1OFJFZpV4mrofVVERKQafYDVcY/XhG2V7uPupcAOoEu4baCZzTOzaWZ2clUXMbMbzGyOmc3ZtGlTw0UvdTJv4zyunnI124q28eejfsyFMx6HgafA6f8v6tBEEt422nN18R0s8sG8tmUGp2zuTHrHeWT1exxS90QdnlSiWSWuIiIi0mjWAf3d/SjgR8AzZta+sh3dfby7j3T3kd26dWvSICUwZfkUrp96PR0yOzBh1D0c88pPoW0PuPSvkJoWdXgizcIuWvOV4lt5ouxcfrdzAXdt2EVG1kraHPRHLH1z1OFJBUpcRUREkkcB0C/ucd+wrdJ9zCwN6ABscfcid98C4O5zgWWAJkkmGHfnsQ8f45a3b+Hwrofz9OifcdCL34HUTPjqRGjTNeoQRZqVQlpxf+mXObf4AXrt6s2T69fSIW0L7Qf8gdSsFVGHJ3GUuIqIiCSP2cAQMxtoZhnAlcDkCvtMBq4N718KvOnubmbdwuJOmNkgYAiwvInillooKSvhjhl38Mj8R7hg0AX8edSddHz2yxArha9Ogi6Dow5RpNn6xPtyTclPGb/rO/yuYC/9Y7tpd9Cf6Nz+nahDk5DGkoiIiCQJdy81sxuBqUAq8IS755nZvcAcd58MPA783cyWAlsJkluAU4B7zawEiAHfdvetTf8spDI7inbww7d+yJwNc/jukd/l24PGYU+eB0W74LqXoPuhUYcokgSMV2PHkbvnSL6++kXyes9mbp+XOT5zAV50KqblpSLVrBJX1TwUERGpnrtPAaZUaLsz7v4+4LJKjvsX8K9GD1DqbEbBDO557x42F27m5yf9nAt7ngBPng+7NgTDg3sdGXWIIkmlkFY8Wnw1/VeeyrG9xzO76yq+89djuLPjkfTOvgwOOQdaVVoCQBpRs0pcRURERFqKHUU7+OXsXzJ52WQGdhjIk2Of5Ih2B8FTF8K2T+Gaf0K/UVGHKZK0VnkfVhXczcF7J/JBzzlcXJjP/7z+Qy6fVEzK4NNh2EUw9Fxo3TnqUFuESBNXM/tf4FdAN3dX6S4RERER4L8r/8t9s+5j275tfPPwb/KtI79FZlkp/P1i2JAPVz4TLH0jIo3MWLrtYmZ87x7unnE396fM5D/pnblnUx4HffwfSEmDASfDwWdArxHQ6who1SHqoJNSZImrmfUDzgZWRRWDiIiISCLZUriFn8/6Oa+tfI2hnYbyxzP+yLAuw6BkHzx7FayZDZc9CYecHXWoIi1Kn7Z9GH/2eCYunchDsx/iS11aceOxN/OV3cWkLn4ZXrvj8507DwqG8PcaEf48Ur2yDSDKHtffAD8BJkUYg4iIiEjk3J1XPn2FB99/kD0le/j+Ud/na4d9jfSUdNhRAP/+Fqx4Gy5+DLJzog5XpEUyMy4ecjEn9jmRn838Gb/+5HmmdjmMe7/yPEPSO8C6BbBuHqz7ENbMhbx/f35wh/7QIxu6Z0OP4cHPrkMgNT26J9TMRJK4mlkOUODuH1odKi6pNpOIiIgkm7wteTwy7xHeKXiHI7oewb0n3svgjuHSNnn/hpd+CGUlcMmf4YjLI41VpKXaV1JGq/RUALq37s7vT/s9/1nxH34x6xdc/vLlfCX7K1ybfS1dhpz5+UF7twZJ7Lr5sH5hMMx/6RvBElYAKenQ9ZAgoe0xPOih7X0UZHWsd4zJqNESVzN7A+hZyabbgZ8SDBOuzXluAG4AaNdrUIPFJyIiIhKleRvn8diCx5hRMIN2Ge348cgf8+VhXyY1JRX27YRXb4EPn4E+I+GS8VqnVSRCrdJTGXDrK19ot9TvkdnjFZ5Y+CRPLHiakm2jKN56Cl4aP8/1kPD2JTIoYZCtY6it4tCU1Qxdt5qhG96kj/3zs72XxXqxwAexIDaID2ODyfMBFJFRY4wrHji//k80gTVa4uruZ1bWbmaHAwOB8t7WvsAHZjbK3ddXcp7xwHiArgOGeWPFKyIiItJQqur5cHdmrZ/F+AXjmb1+Np0yO3HT0TdxxdAraJfRLthp1Sx48ZuwYzWceguccrOGE4okKC9ry761V5Cy+TQyuuSS3vk90jvNpGTHSIq3nIqX7D+3tZh0Fnt/Fnt/JsU+b2/Pbo5I+ZQjbBkjUpZxfEo+F6fOAKDUU1ji/ZgTO4SZsWzejx3KFlpeAagmHyrs7guB7uWPzWwFMLJWVYU1VlhERESagS/2zjipbReT2fVNUrNWEytpT/GWC1i1fRT3zc/gPqaTRinfT/s3N6ZOpMC78sOSO/lg6iEw9bVGiTHZe2dEmlKsuDv71l2ObT6DjC7TSe8wh/SOsyndMYKiLafhxd2qPX4nbXkndjjvcDiUBW092MqRKcs4ImU5R9oyLkudzrVprwOwJNaXWbFhzIwNY1ZsWItIZLWOq4iIiEgjsdRdpLVfSHrH2aS2WkesuBP71o2jZMcx4J/3oh5k6/ld+qOMSFnGC2WncHfJV9lN6wgjF5ED4SVdKFp/McWbTw8S2I7vk9ZhHqW7sindcTSle4aC1y4F20BnXot15rXYsQCkUcrh9imjUxYxOiWfL6VO56thIvtxrA+88hYMGgMDTjrgebKJLPLE1d0H1Hbfbm0zGzESERERkfrbWbyT/678L1n9/k5qm6WYOWX7elK49jJKd4wAgiHEKcQ4KWUhV6S+xVkpc9lLK75b/AOmxEZHGr+I1J+XdqBow4UUbz6N9M7vkN5xNunt8/CyVpTuGk7JzhGU7RlE+d+D2igljXk+hHllQ/i/sotIo5TDbAWjU/I5PiWfQ+Y/A7P/DJYCfY4JkthBY6DvKEireY5soos8ca2LNpnNKlwRERFpIQpLC5m2ehpTPp3COwXvUBIrISWjM8VbxlC6YwSx4h6f7dubzVyWOo3L0qbR1zazxdvxVNk5/KX0PDagtR5FkomXtaV401iKN51FapulpLf/kLR2H5HecS6x0raU7jyckp0jiBX2p67zIktJY74fzPyyg/lT2UWsuOusYK3n5bnB7e2HYfpDkN4aDjoRBp0KB50APY+E1OaXVzW/iEVEREQiVhorZfHWxczdMJc5G+Ywa90sCksL6Z7VnSsPvZLzBp7HBb9aQfkH0XRKOSPlA65MfYtTUhYA8E7sMH5edjVvxI6hGBVfEkluqZTtGUrZnqGwvoS0tktIa/8h6R1nk9H5PWIlHSndczBlewdStncgXtKJOhf4ScuAAScGt9Nvh307YMU7nyeyr90R7JfeBvqODJLY/sdD32MhI/GnJihxFREREalBUVkRCzct5IONHzB3w1zmbZxHYWkhAAe1P4gLB13I2IFjObr70aTGSmHTEi5OeYehKWsYaqs4MmUZnW03a70zfyi7mH+Wncoar75Yi4gkKU+ndNdhlO46DFL2kdY2n7T2H5HeNp+MjnMAiJV0oGzvgM8S2Vhxd+qcyLbqAIeeH9wAdq6DVe8Ft5XvQe4DgENKWrCGbP/R0OtI6HZosL5sequGfNb1psRVREREJBTzGOv3rGfZ9mUs37GcZduXsWz7MhZtXURJrASAQ9r2J6fHaI5p049jWnWnWwzYtR6mPwIb82HLMvAyfpMBxZ7KMu/DW7ERvFR2PNNjRxIjJdonKSKJI9aK0p1HU7rzaCBGSuZGUlt/SmrWp6S2Xk56hw+D3UrbENvXm1hxd2JF3YkV9aCsqDvE6tBT2r4XHHZJcAMo3A6r34dV7waJ7Pvjoaw42GYp0HlQkMR2z4buh0K3YdB5IKRnNehLUFtKXEVERJKMmY0FfkdQ9eMv7v5Ahe2ZwN+AY4AtwBXuviLcdhtwPcGCDD9w96lNGHr9lZXAnk2we+PnP/dugeLdULwHinZRWLSTjcU72FCyiw2le1gf28cKK2VZirM8FQrt816NLmVlDC4p5eqiIkYWFnFUUREdYquAd7547U4DoPtwGHYR9MjmzAmbWeE9KdXHLRGplRRiRT2JFfWkZNvxgGPpW0lt/SlprT8lJXMD6R3fx1JKPjsiVtr2s0T2rwu30KddT3q06UGP1j3omtWVtJRq/v5kdYRDzg5uAKXFsHVZ8AXcxsWwaVHwc8kU8LhFZ1t1gHa9oV1PaNdr/59te0BWp/DW8QtrUFe1xnVt6C+piIhIEjGzVOBR4CxgDTDbzCa7e37cbtcD29z9YDO7EngQuMLMsoErgeFAb+ANMzvE3cua9llUUFIYJqKbYc9GSnasJ33fZti9Cd+9gcI9G9mxdxM7921lR8ludqaksCMlhR2pKexMSWF7aiobUlPZkJbOhrRUdqaEialB+dTS7pbB4JTWfCmtDYPS2jE4vQOD0jvSMS0rGEaX3hoy20JmO8gIf5bfMtpC686Q0Wa/sJf6K4iIHDjDS7pQuqMLpTtGhm0xLG0HKZkbScncEPTQZmwkvcMHPPzBe/sd7W54aTu8tAOxkvZ4aXu8LAsva43HsvCyLChrvV9bsFRPK2BEeINMihlk6xhia+hrm+leuo0ee7bRY8NquttCurONDKv8bWKXZ7GDNmz3tmz3Npx0+JAg8c3qCK06VrjfsdplfJS4ioiIJJdRwFJ3Xw5gZs8BOUB84poD3B3efwF4xMwsbH/O3YuAT81saXi+/T8NxdmzeTGznjiNWGoasdQMYqlpeGoGZSlpxFLTiVkKZThl7sFPYpR+dt8p9TJKSvdRUlZEcWkxxWVFlMSKKY6VUBIrpSRWSqGXUZiSQqEZhSkW/LQU9qYY+8zwFIO2QNs2wP7JI56Cl7UmVtKBWFEHfHf74ENcaXu8pAOx0g54SQd2eQbL6vQy7wtvmyrduuKB8+t0NhGR2knBSztRVtopKPT0GWfe3SdyzC9ewNJ3kpK2A0vb8dn9lIzNpLRZDin7MPMqz+6eArEMPJYR/PR0PJbBilgGn8YygvWnvQ3uHcAHB4mup9DKY7TzYtpSRJaX0Ibiz25tKaKtF9GOfezbupCUoj2klOwhpawEIxgaZO6kQLUTKZS4ioiIJJc+wOq4x2uA46rax91LzWwH0CVsn1nh2D7VXWyFlfGN1M3Bg7LwdoDSHNLNSE9LIcPSyLBM0i2VVqkZZKVl0Sa9DV0z2pGV2YHJC3dSFmuFewaUtQp7D8p7Dsrvtw4+ZNW1oImISLNjdGrViVhRbyjqXc2f4liQvKYWhre9n/9MKYSUYiylOPhpcfdT92FpO7GUUrBSsDIs/ImVEjNnB7CjNqFmZQDVrStb+ReCzSpxnTt37m4zW1LHwzpQy9dQx0RyTFNeS8fo3yhZj2nKayXbMUNr3kUqMrMbgBvCh7s/uu6jur43J5KuwOaGPqk92NBnrJU6PZeIYqw1e7Bx/m0aUh1fw0ieTyP+OzfY80mA38Uan0sCxFijuBgT/v9ODQ6qtNXdm80NmHMAx4zXMYl7TKLHp2MSPz4dk/jxJfgxdX5fSfQbcDwwNe7xbcBtFfaZChwf3k8j+IBjFfeN3y9Zb8n0O5BMz0XPJ/FvyfR8kum5JOPzKb+1hHrsL+mYhD6mKa+lY/RvlKzHNOW1ku2YZDQbGGJmA80sg6DY0uQK+0wGrg3vXwq86cGnncnAlWaWaWYDgSHA+00Ut4iISJUszMqbBTOb4+4ja95TRESkZsn6vmJm5wG/Jah58YS7329m9xJ8Cz/ZzFoBfweOArYCV/rnxZxuB74OlAI/dPdXo3gOTSWZfgeS6bmAnk+iS6bnk0zPBZLv+ZRrVnNcgfFRByAiIkklKd9X3H0KMKVC251x9/cBl1Vx7P3A/Y0aYGJJpt+BZHouoOeT6JLp+STTc4Hkez5AM+txlcRS2QL3ZnY68CuCUmFzgevdvTTCMJOCmT0BXABsdPfD4tq/D3yPoI7nK+7+k4hCTCpm1g/4G9ADcIK5k78zs58RLBcSAzYC17n72ugiTQ5h7990IJPgC9UX3P2ucKjqcwTVbucCX3H34ugiFRERkagocZUDEi5w/zFxC9wDVxEU8jjD3T8Oh6WtdPfHo4s0OZjZKcBu4G/liauZnQbcDpzv7kVm1t3dN0YZZ7Iws15AL3f/wMzaESRN44A17r4z3OcHQLa7fzu6SJNDuH5oG3ffbWbpwDvATcCPgBfd/Tkz+xPwobv/X5SxioiISDRaQnEmaRyfLXAf9oA8B3wJKHb3j8N9Xg/bpJ7cfTrBPLR43wEecPeicB8lrQ3E3de5+wfh/V3AIqBPedIaakPQGyv15IHd4cP08ObA6cALYftTBF8eiDQoM/uZmS0ws/lm9pqZ9Y46pvows4fMbHH4nP5tZh2jjqk+zOwyM8szs5iZNcs5e2Y21syWmNlSM7s16njqy8yeMLONZvZR1LHUl5n1M7O3zCw//D27KeqY6sPMWpnZ+2b2Yfh87ok6poakxFUOVGUL3PcE0uLeWC4F+jV1YC3IIcDJZjbLzKaZ2bFRB5SMzGwAQQGbWeHj+81sNXANcGc1h0odmFmqmc0nGIL9OrAM2B431WANwd8dkYb2kLsf4e4jgJdp/v+vXwcOc/cjCEZG3RZxPPX1EXAJwXSCZiccofYocC6QDVxlZtnRRlVvTwJjow6igZQC/+vu2cBo4HvN/N+nCDjd3Y8ERgBjzWx0tCE1HCWu0pCcYNmF35jZ+8AugrmX0jjSgM4Ef2hvBv4RDrmUBmJmbYF/EVRW3Qng7re7ez9gAnBjlPElE3cvCxOHvgQjOg6NNiJpKZJtJIW7vxb3hc9Mgv9TzZa7L3L3JVHHUQ+VjVDLiTimeqliFFizVNUIq2ijOnDVjGBKCkpc5UAVsH9val+gwN3fc/eT3X0UwbejH1d6tDSENQTz/9zd3ycoGNQ14piSRjjX8l/ABHd/sZJdJqCh8A3O3bcDbwHHAx3NrLz6fV+CvzsiDS6JR1J8HUjq5YyagcpGqDXbxCiZVRxh1VxVHMHk7s36+cRT4ioHqtIF7s2sO4CZZQK3AH+KMMZkNxE4DcDMDiGo5Lw5yoCSRdhz/TiwyN0fjmsfErdbDrC4qWNLRmbWrXwenpllERR9W0SQwF4a7nYtMCmSAKXZM7M3zOyjSm450PxGUtT0fMJ9bicYBjkhukhrpzbPR6QxVTbCqrmqOILJzA6r4ZBmo7mt4yoJwt1LzexGgirC5Qvc54VFIS4g+FLk/9z9zUgDTRJm9iwwBuhqZmuAu4AngCfC4gjFwLWuMuEN5UTgK8DC8FtLgJ8C15vZUILe7ZWAKgo3jF7AU+FcsBTgH+7+spnlA8+Z2X3APIIvE0TqzN3PrOWuEwjWv72rEcOpt5qej5ldR7CE2hnN4X2hDv8+zVGlI9QiikUqUYsRVs2Su283s7cI5iM3+0JaoOVwREREpAUzsyHu/kl4//vAqe5+aQ2HJSwL1lh/mOB5bIo6noZiZrnAj919TtSx1EU43eFj4AyChHU2cLW750UaWD2Fw2pfjl9bvjkKR1g9BWx19x9GHE69mVk3oCRMWrOA14AH3f3liENrEEpcRUREpMUys38B+42kcPdm2yNmZkuBTGBL2DSzOa83bWYXA38AugHbgfnufk6kQdWRmZ0H/JbPR6jdH21E9RM/CgzYANzl7s1yRIyZnQS8DSwk+BsA8FN3nxJdVAfOzI4gSMTjRzDdG21UDUeJq4iIiIiIiCQ0FWcSERERERGRhKbEVURERERERBKaElcRERERERFJaEpcRUREREREJKEpcRUREREREZGEpsRVREREREREEpoSVxEREREREUloSlxFRERERBqQmV1nZu9EHYdIMlHiKtJCmFmumX0j6jhERESaipldbWZzzGy3ma0zs1fN7KSo4xKRulPiKtJAzGyFmW00szZxbd8ws9wIw6o1M8s2s8lmtsPMdpnZm2Y2upbHXmdmC81sr5mtN7M/mlmHxo5ZRESkKmb2I+C3wM+BHkB/4I9ATh3Pk1abtqYQ1XVFEoESV5GGlQrcVN+TWKDJ/n+a2WBgBrAQGAj0BiYCr5vZqBqO/V/gQeBmoAMwGhgAvGZm6Y0XtYiISOXCL0/vBb7n7i+6+x53L3H3l9z9ZjPLNLPfmtna8PZbM8sMjx1jZmvM7BYzWw/81czuNrMXzOxpM9sJXGdmHczs8bAnt8DM7jOz1CriOcHMZodfDs82sxPitg00s+nhl8ZvmNmjZvZ0uG2AmbmZXW9mq4A3w/Z/hl8U7wiPHR53vifDL5BfDXuaZ5hZz/A5bjOzxWZ2VKO9+CKNRImrSMN6CPixmXWsbGMNb1y5Zna/mc0A9gKDwjer75rZJ+Eb2s/MbLCZvWtmO83sH2aWER7fycxeNrNN4RvTy2bWt5Zx3w285+63u/tWd9/l7r8HniZISitlZu2Be4Dvu/t/wg8FK4DLgUHA1bW8voiISEM6HmgF/LuK7bcTfNE6AjgSGAXcEbe9J9AZOAi4IWzLAV4AOgITgCeBUuBg4CjgbOALU3LMrDPwCvB7oAvwMPCKmXUJd3kGeD/cdjfwlUriPRUYBpwTPn4VGAJ0Bz4I44l3efh8ugJFwHvhfl3D5/BwJdcQSWhJkbia2e6oYxAJzQFygR9X3FCLNy4I3qxuANoBK8O2c4BjCN5gfwKMB74M9AMOA64K90sB/krwJtsfKAQeqWXcZwH/rKT9H8DJZtaqiuNOIPhg8GJ8o7vvBqYQvImLiIg0tS7AZncvrWL7NcC97r7R3TcRfAkbnzDGgLvcvcjdC8O299x9orvHgPbAecAPw97cjcBvgCsrudb5wCfu/nd3L3X3Z4HFwIVm1h84FrjT3Yvd/R1gciXnuDu8TiGAuz8RfslcRJDsHllhis6/3X2uu+8jSN73ufvf3L0MeJ4g0RZpVpIicRVJMHcC3zezbhXaq3zjitvnSXfPC7eXhG2/dPed7p4HfAS85u7L3X0HwTeuRwG4+xZ3/5e773X3XcD9BN/Q1kZXYF0l7esIhj93rua4qj4YrAMqvgYiIiJNYQvQtZo5ob35/Atiwvu94x5vCpO+eKvj7h8EpAPrzGy7mW0HHiPoAa3pWuXX6xNu2+rue6u4zhfazCzVzB4ws2XhsOUV4aaucftviLtfWMnjtpVcQyShJU3iamZtzey/ZvZBWCQmJ2wfYGaLzOzPZpZnZq+ZWVbU8UrycvePgJeBWytsqu6Nq1xlb1a1evMxs9Zm9piZrQzfyKYDHauab1PBZqBXJe29AAe2mNnJ4VyZ3WaWF3dcVR8MeoXbRUREmtp7BENkx1WxfS1B8lmuf9hWzis5Jr5tdXj+ru7eMby1d/fhlRxX8Vrl1ysg+JK3s5m1jtvWr4ZrX00wbPlMgtoSA8J2q+Q4kaSRNIkrsA+42N2PBk4Dfm1m5f+BhwCPhn9MtgNfiiZEaUHuAr7J/klpdW9c5Sp7o6yt/wWGAse5e3vglLC9Nm9kbwCXVdJ+OTAzHCr1tru3DW/lb8zlHwwuiT/IzNoC5xIMmxYREWlS4aikO4FHzWxc+OVuupmda2a/BJ4F7jCzbmbWNdz36Tqcfx3wGsHnzfZmlhLWoKhspNMU4BALluZJM7MrgGzgZXdfSTDN6G4zyzCz49l/JFZl2hG8924BWhNUTRZJesmUuBrwczNbQPAhvA9B6XOAT919fnh/Lp9/MyXSKNx9KcEckh/ENVf5xtVAl21H0AO7PZxPe1cdjr0HOCEsDtXZzNqZ2feBrxG8mVcq/GBwD/AHMxsbfigYQDA3djNfLBYhIiLSJNz918CPCIoUbSLoJb2RoGr+fQQJ4wKCivofhG118VUgA8gHthEUPfrC6CV33wJcQPAF8xaCehUXuHv5qKRrCIpJbQljeJ4gMa3K3whGbBWE155Zx7hFmqVkWgvqGoL5dMe4e4mZrSAoGgP7/+cvAzRUWJrCvcQVenD3LWZ2AfA74P+Apez/xlVfvyWoTLiZoHf311Q9RGo/7v6JBQuyP0AwV6YNsItgFMMbNRz7SzPbAvyKoLJiJjANONPd9xzIExEREWkI7j6Bqr9E/QH7f8Fcfkwu0LdC292V7LcD+E54q7jtSYKqw+WP3yEotFhZjMuAk8sfm9nzBDUwCCv1W4X9d/PFtWj/Frf9ugr7/wX4S9zjpSRXDiAthLnXZ2RiYgirCt8OHOzu3zez0wjWuRoY7vKyux8W7vtjoG1lf4BEJBAuozOToKLi43U89msESfuJ7r6qMeITERFJFmZ2LLAV+JSgGv9E4Hh3nxdlXCKJptkPFQ6LwhQRfJs20swWEgzdWBxpYCLNmLuvIZij2iucr1qXY/8K/JRgqRwRaWJm9oSZbTSzj6rYbmb2ezNbamYLzOzouG3XhutGf2Jm1zZd1CItWk+CmhC7CZbM+46SVpEvavY9rmZ2JPBndx8VdSwiIiJRM7NTCD4A/618tFGF7ecB3ydYg/I44Hfuflw4N34OMJKgUNxcguk325oseBERkSo06x5XM/s2YVW4qGMRERFJBO4+nWDYYVVyCJJad/eZBMtm9QLOAV53961hsvo6MLbxIxYREalZs56Y7e5/Av4UdRwiIiLNSB/2XzN6TdhWVbuIiEjkIk9czSyVYGhSgbtfUN2+Xbt29QEDBjRJXCIikvzmzp272d27RR1Hc2NmNwA3ALRp0+aYQw899IDOs3FXERt27vtCe4/2rejeLrNeMYqISPNU1Xtz5IkrcBOwCGhf044DBgxgzpw5jR+RiIi0CGa2MuoYIlAA9It73DdsKwDGVGjPrewE7j4eGA8wcuRIP9D35v8u2sD3n53H3uKyz9paZ6Tyh6uO4oxhPao5UkREklVV782RznENl9w4n7i1pURERKRRTQa+GlYXHg3scPd1wFTgbDPrZGadCJblmNqYgYwZ2p0R/TqSEq5S2TojlRH9OjJmaPfGvKyIiDRDUfe4/hb4CdCuqh3ihyP179+/aaISERFppszsWYKe065mtga4C0iHz2pDTCGoKLwU2At8Ldy21cx+BswOT3Wvu1dX5KneUlOMv19/HOf+bjp7i8q4J2c4Y4Z2J7U8kxUREQlFlria2QXARnefa2Zjqtqv4nCkpolORESkeXL3q2rY7sD3qtj2BPBEY8RVldQUo1PrDDq1RsODRUSkSlEOFT4RuMjMVgDPAaeb2dMRxiMiIiIiIiIJKLIeV3e/DbgNIOxx/bG7fzmqeEREJHlMnFfAQ1OXsHZ7Ib07ZnHzOUMZd5RWdhEREWmuop7jKiIi0qAmzivgthcXUlgSVKot2F7IbS8uBFDyKiIi0kxFWlW4nLvn1rSGq4iISG08NHXJZ0lrucKSMh6auiSiiERERKS+EiJxFRERaShrtxfWqV1EREQSnxJXERFJKr07ZtWpXURERBKfElcREUkqN58zlKz01P3astJTufmcoRFFJCIiIvWl4kwiIpJUygswqaqwiIhI8lDiKiIiCetAl7UZd1QfJaoiIiJJRImriIgkJC1rIyIiIuU0x1VERBKSlrURERGRckpcRUQkIWlZGxERESmnxFVERBKSlrURERGRckpcRUQkIWlZGxERESmn4kwiIpKQtKyNiIiIlFPiKiIiCUvL2oiIiAgocRURkUZW1VqsB7pGq1TPzMYCvwNSgb+4+wMVtv8GOC182Bro7u4dw21lwMJw2yp3v6hJghYREalBZImrmbUCpgOZYRwvuPtdUcUjIiL1VzEZPe3QbvxrbsEX1mKds3Jrpe2gNVrrw8xSgUeBs4A1wGwzm+zu+eX7uPv/xO3/feCouFMUuvuIJgpXRESk1qIszlQEnO7uRwIjgLFmNjrCeEREpB4mzivgthcXUrC9ECdIRifMXFXpWqzPzlrd+Gu0lpTAhg0Nd77mYRSw1N2Xu3sx8ByQU83+VwHPNklkIiIi9RBZ4uqB3eHD9PDmUcUjIiL189DUJV9IRqv6o17mlW+p9xqt7vDee3DjjdCnD3zrW/U7X/PTB1gd93hN2PYFZnYQMBB4M665lZnNMbOZZjau0aIUERGpo0jnuIZDmuYCBwOPuvusKOMREZHaqzgsuKAOSWeqWaXJ6wGv0bp4MUyYAM88A8uXQ6tWcOGFcO21B3a+luFKgmk68d82HOTuBWY2CHjTzBa6+7KKB5rZDcANAP3792+aaEVEpEWLdB1Xdy8L59L0BUaZ2WEV9zGzG8Jvf+ds2rSpyWMUEZEvqmxYsFWxb8X2rPRUrjquX/3XaF27Fh5+GI45BoYNg5//HAYNgr/+NRgi/I9/wPnn1+VpJYMCoF/c475hW2WupMIwYXcvCH8uB3LZf/5r/H7j3X2ku4/s1q1bfWMWERGpUUJUFXb37Wb2FjAW+KjCtvHAeICRI0dqKLGISBOqrNjSW4s3Vdq76gRJavwf6qz0VL50TB/eWrzpC9WDRx7Uue5VhXfsgBdfDHpX33wzGBp8zDFBAnvlldCrV0M+/eZoNjDEzAYSJKxXAldX3MnMDgU6Ae/FtXUC9rp7kZl1BU4EftkkUYuIiNQgyqrC3YCSMGnNIqiA+GBU8YiIyP7Ke1XjK/8+PXNVtcc40KdjVq2S0Vqv0VpUBK++GiSrL70UPB48GO64A665BobWoZc2ybl7qZndCEwlWA7nCXfPM7N7gTnuPjnc9UrgOff9xmsPAx4zsxjBiKwH4qsRi4iIRCnKHtdewFPhPNcU4B/u/nKE8YiItGjlvasF2wurnINakz4ds5hx6+n1DyYWg+nTg2T1hRdg+3bo1g1uuCFIVkeNAqtqcHLL5u5TgCkV2u6s8PjuSo57Fzi8UYMTERE5QJElru6+gCrmzoiISNOq2Lt6IElrneeoVuQOCxYEyeqzz8KaNdCmDVx8cZCsnnkmpCXEDBcRERFpYvoEICLSgsX3stZHn9rOUa3MypVBNeAJEyAvL0hOzzkHfvlLuOiiIHkVERGRFk2Jq4hIC1Wxl/VAZKWn8otLDq97wrplC/zzn0Gy+s47QdsJJ8Cjj8Lll0PXrgcck4iIiCQfJa4iIi3QxHkF/O8/PqzTkOA+cVWF61QJuNzevTB5ctC7+uqrUFoK2dlw//1w1VUwcOABPhsRERFJdkpcRURagPghwRWXrKnJAfeqQpCc/ve/Qc/qv/8Nu3dDnz7wwx8G81aPPFJFlkRERKRGSlxFRJJQdYlqbZLW8qrCBzR31R1mzw6S1eefhw0boEMHuOKKIFk95RRITa3jMxIREZGWTImriEiSqTh3tcl6Vz/5JEhWn3kmuJ+RARdcECSr550HrVrV/ZwiIiIiKHEVEUk697yUd0AFl1LN6p60rl8f9KpOmBD0sprBmDFwyy3wpS9Bx451jkNERESkIiWuIiJJZOK8ArbtLanzcXXqad21K5ivOmECvPEGxGIwYgQ89BBceSX07Vv3wEVERESqocRVRCRJlFcKrqtOrdO568Lh1SetxcXwn/8EyerkybBvHwwYALfdBldfHVQHFhEREWkkSlxFRJqx+CJMtZViEHNqLrwUi8GMGUGy+s9/wtat0KULfP3rwbzV449XRWARERFpEkpcRUSaqTsmLmTCzFW1Lr5U6wrBH330eZGlVasgKwvGjQuS1bPPhvT0+oYuIiIiUidKXEVEmqE7Ji7k6ZmrarVvreavrl4Nzz4bJKwLFgTL1Zx1Ftx/f5C0tm3bMIGLiIiIHAAlriIizcjEeQXcPTmP7YW1K8BUbaXgbdvghReCZHX69GD91dGj4fe/D9Zc7d69gaMXEREROTBKXEVEmoFgbdYFFJbEan2MAb++/Mj9k9bCQnj55SBZnTIFSkrgkEPg7ruDIksHH9zgsYuIiIjUV2SJq5n1A/4G9AAcGO/uv4sqHhGRRDVxXgE3//NDSmK1nc0aJK3XjO4fJK1lZfDWW0Gy+uKLsHMn9OwJN94YzFs9+mgVWRIREZGElhLhtUuB/3X3bGA08D0z03oKIiIV3PNSXp2S1j4ds/jN5UdyX79i+NGPoF+/YL7qv/4Fl1wCr78Oa9bAww/DMccoaU0yZjbWzJaY2VIzu7WS7deZ2SYzmx/evhG37Voz+yS8Xdu0kYuIiFQtsh5Xd18HrAvv7zKzRUAfID+qmEREEkVdl7kp72G97/DWQTXgq78LS5YEFYDPOy/oWb3ggqBCsCQtM0sFHgXOAtYAs81ssrtXfG993t1vrHBsZ+AuYCTBSKi54bHbmiB0ERGRaiXEHFczGwAcBcyKOBQRkcjVdZmbQbE9/MY+5sgH74OZM4PGU04JelsvvRQ6d260WCXhjAKWuvtyADN7Dsihdl8KnwO87u5bw2NfB8YCzzZSrCIiIrUWeeJqZm2BfwE/dPedlWy/AbgBoH///k0cnYhI06lLAabWxYWc9clMvrt2FkM/fC+Yx3rEEfDAA3DVVaC/ly1VH2B13OM1wHGV7PclMzsF+Bj4H3dfXcWxNSz6KyIi0jQiTVzNLJ0gaZ3g7i9Wto+7jwfGA4wcObL2k7xERJqRa/78HjOWba12n7SyUk5eMY9xebmctXQmrUuKggT15puDocCHHdZE0Uoz9xLwrLsXmdm3gKeA0+tyAn2pLCIiTS3KqsIGPA4scveHo4pDRCRq1Sat7hxdsJhx+bmcv/htuhTuZHurtmy46DIG3nQDnHgipERZZ08STAHQL+5x37DtM+6+Je7hX4Bfxh07psKxuZVdRF8qi4hIU4uyx/VE4CvAQjObH7b91N2nRBeSiEjTumPiwkqT1sGbVzMuP5ec/Fz679jAvrQM3jj4OCZlj6H3leO457KjI4hWmoHZwBAzG0iQiF4JXB2/g5n1CgskAlwELArvTwV+bmadwsdnA7c1fsgiIiI1i7Kq8DsEhTBFRFqEifMKuHtyHtsLSyrd3mPXZi5cNJ1x+dM4bMMyyiyFGQcdye9OvJqphxxPhx5duPmcocHarCKVcPdSM7uRIAlNBZ5w9zwzuxeY4+6TgR+Y2UUEy9JtBa4Lj91qZj8jSH4B7i0v1CQiIhK1yIsziYgku+qKLrXft5uxS94lZ1Eux69cSArO/F5DuOeMb/LyoaewqW0nvjy6Px+NOzyCyKU5CkcuTanQdmfc/duooifV3Z8AnmjUAEVERA6AElcRkUZU2fzVjNISTls2m3H5uZy+bDaZZSV82qkXvz/xSiZlj+HTzkGPamZaCr/90hHqYRUREZEWr8bE1cwGA2vC6oNjgCOAv7n79sYNTUSk+alqOLB5jNGrPiInP5fzlsygfdEeNrXuyDMjxjIxewwf9joE7PPZEycO7syEbx7f1OGLiIiIJKTa9Lj+CxhpZgcTVBCcBDwDnNeYgYmINAd3TFzIhJmrqLSsqjvZGz8lJz+Xi/Kn0Wv3FnZnZDF1yGgmZY9hxoARlKWkfuGwL4/uz30aGiwiIiLymdokrrGw2MPFwB/c/Q9mNq+xAxMRSXRVLWPTd8cGLsqfxri8XA7ZsoqSlFSmDTyan5/2dV4fchz70ltVeU4lrSIiIiJfVJvEtcTMrgKuBS4M29IbLyQRkcR2x8SFPD1z1X5tnfbu4PwlM8jJy+XYgnwAZvfJ5o6zv8srQ09kW+sO1Z6zU+t07rpwuOazioiIiFSiNonr14BvA/e7+6fh2nB/b9ywREQSR1XzVluV7OPsT2aRk5/LKZ9+QHqsjCVd+/PLU77K5OxTWdOhR5XnVKIqIiIiUns1Jq7unm9mtwD9w8efAg82dmAiIlGrrGc1NVbGSSvmk5Ofyzkfv0ebkn2sbdeVx0fmMGn4GBZ1G7hfkaWKVHRJREREpO5qU1X4QuBXQAYw0MxGECxKflEjxyYiEomJ8wr40fPz+WzVVXdGrPuYnPxcLlj0Nt32bmdHZhsmDzuFScPHMKvfYbilVHvONhmp3H/x4ephFRERETkAtRkqfDcwCsgFcPf5ZjaoEWMSEWlyE+cVcPM/51MS+7xt4NYCxuXlctGiXAZuW0dRajr/HXwsk4aP4a1Bx1KcVv10fw0HFhEREWkYtSrO5O47bP+hb7GqdhYRaS4mzivgthcXUBiXrXbbvZULF71NTn4uR67/hBjGuwcdwR9HX8Z/hp7Irsw2VZ4vxeDhy0coURURERFpYLVJXPPM7Gog1cyGAD8A3m3csEREGlf8UjZti/Yy9uN3ycnL5YRVC0j1GAt7DOZnp13PS8NOYWO7LjWeT72rIiIiIo2nNonr94HbgSLgWWAq8LPGDEpEpDGd9XAuK9Zt56zlc8nJy+XMZe/TqrSYVR168Ojoy5iUPYZlXfvVeB4DrtG6qyIiIiKNrjZVhfcSJK63N344IiKN45o/v8e7Szdz7Jp8vpaXy3lL3qHjvt1syWrP80ecxaTsMXzQ+9BqKwKDiiyJiIiIRKHKxNXMXgK8qu0NUVXYzJ4ALgA2uvth9T2fiEi5+KVshm5awbi8XB5cNI2+OzexNz2T14aMZmL2GN4ZcBSlqTUPPtEyNiIiIiLRqe7T2q+a4PpPAo8Af2uCa4lIC1CesPbeuZFv508nJz+XYZtWUGopvD3wKB465au8PmQ0ezOyanU+9bCKiIiIRK/KxNXdpzX2xd19upkNaOzriEjymzivgHuefJuxS2bwfH4ux63+CIC5vQ/lzjO/xSuHnsyWNh1rdS4lqyIiIiKJpbqhwv9w98vNbCGVDBl29yMaNTIRkRpMnFfAHc/M4tSP32dcfi6zls8lI1bK0s59+dXJX2ZS9hhWd+xZ6/N9WYWWJAmY2Vjgd0Aq8Bd3f6DC9h8B3wBKgU3A1919ZbitDFgY7rqqIaYFiYiINITqhgrfFP68oCkCqYqZ3QDcANC/f/8oQxGRBHDNn9/jvU82ccLKBYzLz+W9j9+lXXEhG9p25qljLmBi9hjyegyuschSPK2/KsnCzFKBR4GzgDXAbDOb7O75cbvNA0a6+14z+w7wS+CKcFuhu49oyphFRERqo7qhwuvCu99191vit5nZg8AtXzyq4bn7eGA8wMiRI6ssFiUiySe+wBLuHL5+KePyc/nNoul037ONnRmteXXoiUzMHsPM/ocTS0mt8zVUdEmSzChgqbsvBzCz54Ac4LPE1d3fitt/JvDlJo1QRETkANRmHdez+GKSem4lbSIi9TJxXgE/en4+sbi2g7atJSd/Gjn5uQzeWkBRahq5g0YyMXsMbw4+lqL0zDpfR0OCJYn1AVbHPV4DHFfN/tcDr8Y9bmVmcwiGET/g7hMrO0ijoUREpKlVN8f1O8B3gUFmtiBuUztgRkNc3MyeBcYAXc1sDXCXuz/eEOcWkebhmj+/x4xlW/dr67pnGxcsepuc/GkctW4JMYxZ/Q9j/KhLeHXoiexs1bZO10hLMX512ZEaCiwSx8y+DIwETo1rPsjdC8xsEPCmmS1092UVj9VoKBERaWrV9bg+Q/At7C+AW+Pad7n71soPqRt3v6ohziMizc9ZD+fyycY9nz1uXVzIOR+/x7j8XE5cMZ80j5HffSA/H/M1Xhp2Cuvad6vzNZSwSgtUAPSLe9w3bNuPmZ0J3A6c6u5F5e3uXhD+XG5mucBRwBcSVxERkaZW3RzXHcAO4Kqw2EOPcP+2ZtbW3Vc1UYwikiQmzivg5n/OpyQcC5xWVsopn37AuPxczvpkFlmlRaxp353HjvsSE7PH8Em3gw74WhoOLC3UbGCImQ0kSFivBK6O38HMjgIeA8a6+8a49k7AXncvMrOuwIkEhZtEREQiV+McVzO7Ebgb2ACfTT1zQMvhiEitVCyydEzBIsbl53L+4nfoXLiTba3a8a/DTmfi8DHM7TMMt5QDuo6SVWnp3L00fN+eSrAczhPunmdm9wJz3H0y8BDQFvinBdW3y5e9GQY8ZmYxIIVgjmt+pRcSERFpYrUpzvRDYKi7b2nkWEQkycQPBz548yrG5eeSkz+Nfjs2UJiWyRsHj2Li8DFMH3g0JanpdT6/KgKLfJG7TwGmVGi7M+7+mVUc9y6gb35ERCQh1SZxXU0wZFhEpFbKCy712LWZb+ZPZ1x+LsM3LqfMUphx0JH85qSrmTrkePZktq71OTVfVURERKTlqk3iuhzINbNXgPgCDg83WlQi0qzEVwZuv2835y6ZwbP5uRy36iNScOb3OoS7z7iBl4edzOY2nWp9Xg39FRERERGoXeK6KrxlhDcRkf3WXM0sLWbsstmMy8/ltGWzySwrZXmn3vzuxKuYlH0qKzrXrpc0My2FB790hHpVRURERGQ/NSau7n5PUwQiIs1D+bzVlFgZx63+iHF5uZz78bu0L9rDpjYdmTDiPCYOH8OCnkMgKPxSoyHd2/D6j8Y0buAiIiIi0mzVpqpwN+AnwHCgVXm7u5/eiHGJSAL5rHfVneEbl/PTvFwuWjSNnru3sjsji6mHHM/E7DG8e9CRlKWk1vq8Kq4kIiIiIrVRm6HCE4DngQuAbwPXApsaMygRSQzlvav9tq/nO/nTGJefy5AtqylOSWPaoGO4L/tU3jh4FPvSW9V8sjiauyoiIiIidVGbxLWLuz9uZje5+zRgmpnNbuzARCQ61/z5PRYt/JTzF7/NA3m5HLN2MQCz+g7np+d8jylDT2R7Vvs6nVPDgUVERETkQNUmcS0Jf64zs/OBtUDnxgtJRJpaeVXgrOJ9nLV0Jtfn5XLyinmkx8pY3PUgHjz1WiYPO5WCDt3rfG4lrCIiIiJSX7VJXO8zsw7A/wJ/ANoD/9OoUYlIo7tj4kKenrmK1FgZJ386j9/k53L2JzNpU7KPte268vix45iYPYbF3QfW6bxab1VEREREGlptqgq/HN7dAZzWuOGISGOKL7J01Nol3J2fywWL36br3h3syGzDpOxTmZQ9hvf7DcctpU7nVqElEREREWkstakq/FfAK7a7+9cbJSIRaXDH3f86G3YVM2jLGm7KzyUnfxoDtq9jX1oGbwwexaThY5g28BiK09LrdF71ropIsimLOblLNpK3difDe7dnzNDupKbUbmkvERFpPLUZKvxy3P1WwMUE81zrzczGAr8DUoG/uPsDDXFekZasfAhwue67tnDhounkLJrGEeuXUmYpvNv/CB454Qr+c8gJ7M5sXedrqHdVRJJRWcz5yuOzmL96O4XFZWRlpDKiX0f+fv1xkSSvSqJFRD5Xm6HC/4p/bGbPAu/U98Jmlgo8CpwFrAFmm9lkd8+v77lFWqLyXlWAdkV7GLvkXXLyczl+1UJSPcaCngfzs9O/weRhp7Cpbd3rq7XPTGXBPWMbOmwRkQb13rItB3zsByu3MXflNopKYwDsLS5j7spt/Cl3GUcf1KmhQqyVWMz5+auLWLpxN8WlMTLSUji4e1t+eu4wUpS8SoKLxZz5q7ezYsseBnRpw4h+HfV7m+SOH9yl0a9Rmx7XioYAdS8t+kWjgKXuvhzAzJ4DcgAlriJ1UN7DmlFawtnL55CTn8uZS98ns6yElR178sjxlzM5+1SWdel3QOfXcGARaSlWbNlDcZi0lisujbFiy54mT1znr97O0o27P0uii0pjLN24m/mrtzd5LCJ1oS9dpLHUZo7rLoI5rhb+XA/c0gDX7gOsjnu8BjiukuvfANwA0L9//wa4rEjzV56smscYtTqPn+fnct6SGXTct5vNrTvw7JHnMCl7DPN6DwWr+5vEl0f3575xhzdC5CIiiWtAlzZkpKV8liwCZKSlMKBLmyaPJZGSaJG60Jcu0lhqM1S4XVMEUs31xwPjAUaOHPmFIlEiLUn5cOBDN37Krfm5XJg/nT67NrEnvRWvDRnNpOwxvDNgBKWpdR9MoWRVJHnUVEPCzDKBvwHHAFuAK9x9RbjtNuB6oAz4gbtPbcLQIzWiX0cO7t6W/HU7cYfMsKdoRL+OTR5LIiXR0jwkyvBcfekijaXaT7dmlgVcA2SHTXOAF9y9uAGuXQDEj13sG7aJSOiz5WuAPjs2csmiaeTk5XLo5pWUpKQyfeDRPDjmOl4/+DgKM1rV+fxDurfh9R+NafC4RSQ6tawhcT2wzd0PNrMrgQeBK8wsG7gSGA70Bt4ws0Pcvaxpn0U0UlKMn547jFteXEBRSRnXnTAwsg//iZRES+JLpOG5+tJFGkuViauZHQ5MBqYDc8Pmc4D/MbOzgB+7+x31uPZsYIiZDSRIWK8Erq7H+USatfgktVzHwp1ctfgdLsqfxnFr8gCY02cYd5z1HaYcehJbW3eo83WUrIokvdrUkMgB7g7vvwA8YmYWtj/n7kXAp2a2NDzfe00Ue+RSUox2rdJo1yot0t6hREqiJfEl0vBcfekijaW6HtffAze4++vxjWZ2JvARkFefC7t7qZndCEwlGMr0hLvX65wizdE1f36PGcu2fva4Vck+zlz6Pjn5uZy6/AMyYqV80qUfD538FSZln8qajj3rdH4tXSPS4tSmhsRn+4TvxzuALmH7zArHVluZbfmmPVzxWP3y2vx1OwHqfR6AnftK6n2OlVv2AnDvy9F/LNm6Jxjk9vLCtby8sEFWI5QktGlX0X49nBAkr0+++2kkvzfuTkZqCjF3urXLpCwW474pqr+azNq3Sm/0a1SXuPaqmLQCuPsbZlZCsJ5rvbj7FGBKfc8j0pxUTFQBUmNlnLDyQ8bl53LOx+/RtriQ9W078+QxFzJp+Bjyug+qU5GlVqnG4vvPa+jQRUSA/Qsntu01uN7ny+7Vvt7naEgHdan7+taNJZFiKU/oo47J3fl0815i7vRo34q2manYARQibCiJ8Lq0Sk/FDDyuGowZZKanRhKPmTGoW2IMDU603xdIjN+ZcokUS02qS1xTzCwzHC70GTNrBZS4+97GDU0keZRXAd6PO0es/4RxeblcuHg63fZsZ2dmG14ZehITh49hVr/DiKXU/Q1HPawiLV5takiU77PGzNKADgRFmmpVf6Ji4cTnv5U4f3Pqs46rVK+8B/rOC4ZHFkP5XM7ishjuQU9jh6zollqJxZxbXlzAvpIyLji8d2TDuRNpjmsiSbTfl/KYEuF3plxD/b9uyHVc//HtyturS1z/BvzLzL7n7isBzGwAwRDivzdYZCJJ7KyHc/lk45792gZsLSAnfxo5+bkM2raWotQ03hp8LP/OPo3cwSMpSsuo83VUEVhE4tSmhsRk4FqCuauXAm+6u5vZZOAZM3uYoDjTEOD9JotcpAblcznLexajnMtZnhQVbC/EHX7/5ieRJYvlc6IToapwIkmk3xdIrN+Z5qjKxNXd7wvnoL5tZuV9x3uAX7n7H5okOpFmprJEFaDrnm1cuGg6Ofm5jFj3CTGMmf0P50/HXcp/hp7AzlZt63wtFVkSkcpUVUPCzO4F5rj7ZOBx4O9h8aWtBMkt4X7/ICjkVAp8r6VUFJbqxWLOrn2l7Csp44OV27TUComXFKWkGEcf1ElLzsRJpN8XSLzfmeam2uVw3P0RgkqD7cLHu5okKpFmpLI5qwBtivZyzifvMS4vlxNXfkiqx8jrPoj7x3ydl4adwvr2Xet8LSWrIlIbldWQcPc74+7vAy6r4tj7gfsbNUBpVhKplyiRllpJtKRIviiRfl9AvzP1VW3iWk4Jq8jnKlu2plx6WQmnfPoB4/JyOXPp+2SVFrG6Qw/+b/SlTMwew9Ku/Wt9HSWpIiKSCBKpl6h8qZWKczmjWGol0ZIi+aJE+n0B/c7UV60SVxGpumfVPMYxBYsYl5fL+YvfodO+XWzNas8Lh5/BxOwxzO0zrE4VgTVfVUREEkki9RIl0lzOREuK5IsS6fcF9DtTX0pcRSpRXa9quUM2rQiLLE2j786NFKZl8tqQ0UzKPpXpA4+mNLXm/15pKcavLjuScUdVu0yiiIjUUkNWtpTA3uJSXlm4jr3Fn093zspIZexhPSN7vU8cUvfpNo1h8uCTyF2ykfy1O8nu3Z4xQ7uTqiI7CSdRfl8g8X5nytdfbQ5/O2v8ZB0WZvpfoL+7f9PMhgBD3f3lRo9OpIlVVVypXK+dm7ho0TTG5eUybNMKSi2FdwYcxa9O+QqvDRnN3oysWl1HS9aIiEhzMWZod0b068j81dspLC4jKyOVEf06MmZo96hDi1xqinHGsB6cMaxH1KFIM6HfmQNXmx7XvwJzgfJP2QXAPwElrpIUakpW2+/bzXmL32Fcfi6jVueRgjOv11DuOvNbvHLoSWxuU7thUpqzKiIizVFqivH3649LqF4iEWl5apO4Dnb3K8zsKgB332tWhwl7IgmopmQ1s7SY05e+z7j8XMYsn0NmWSnLOvfhtyddzaTsU1nZqXeN11CiKiIiyUK9RCIStdokrsVmlgU4gJkNBooaNSqRRnDHxIU8PXNVldtTYmWMXrWQcfm5jF3yLu2L97KxTSeePup8JmaPYWHPg2sssqQ5qyIiIiIiDa82ietdwH+AfmY2ATgRuK4xgxJpKBPnFXDzP+dTUlWVJXeGb1jGuPxcLlw0nZ67t7IrI4v/HHIiE4eP4b3+hxNLSa32GpqvKiIiIiLSuGpMXN39dTP7ABgNGHCTu29u9MhE6qGmqsD9tq9nXN5b5ORP4+CtayhOSSN38EjuzR7DfwcfS1F6ZrXn1zBgEREREZGmU2XiamZHV2haF/7sb2b93f2DA72omV0G3A0MA0a5+5wDPZdIuZp6Vzvv3cEFi6YzLj+Xo9cuAWBWv8N4/NhxTBl6Ijuy2lV5bvWqioiIiIhEp7oe119Xs82B0+tx3Y+AS4DH6nEOEQCu+fN7zFi2tdJtWcX7OPuT9xiXn8vJn84jzWMs6jaAB069jsnZp7C2fdWl/JWsioiIiIgkhioTV3c/rbEu6u6LAFScWOqixvmqobSyUk5aMY9x+bmc/clMWpcUUdCuG38edQkTh49hSbcBVR6rZFVEREREWoKymLNtbzF7i8r476INCb/MVY1zXM2sFfBd4CSCnta3gT+5+75Gjk2EifMKuO3FBRTWlK26c/TaxeTk53LBorfpUriT7a3aMjH7NCYOH8Psvtm4pVR6qJJVEREREWlJymLOVx6fxdKNu4k5fP/ZeYzo15G/X39cwiavtakq/DdgF/CH8PHVwN+By6o7yMzeAHpWsul2d59U2wDN7AbgBoD+/fvX9jBpxmpatibe4C2rycnLJWfRNA7avp59aRm8cfBxTMwew7RBR1OSml7pcZlpKTz4pSO0bI2IiIiItDi5SzYyf/V2Yh483ltcxvzV28ldsjFh12uuTeJ6mLtnxz1+y8zyazrI3c888LD2O894YDzAyJEjvSHOKYmnLslq911buGjRNHLyp3H4hmWUWQozDjqS359wFVMPOZ7dma2rPPbLo/tz37jDGypsEREREZFmJ2/tTgqLy/ZrKywuI3/tzmaduH5gZqPdfSaAmR0HqAqw1EuthwCH2hXtYeySGYzLz+X4lQtJwfmw5xDuPf2bvDTsZDa17Vzt8UpYRUREREQCw3u3Jysjlb1xyWtWRirZvdtHGFX1apO4HgO8a2bl3WH9gSVmthBwdz+irhc1s4sJhh53A14xs/nufk5dzyPNS116VQEySks4bflscvJyOWPZbDLLSljRsRd/OOFKJmWfyvIufas8VkOBRaSlMbPOwPPAAGAFcLm7b6uwzwjg/4D2QBlwv7s/H257EjgV2BHufp27z2/8yEVEpKmNGdqdEf06Mn/1dgqLy8jKSGVEv46MGVr1ihtRq03iOrahL+ru/wb+3dDnlcRxx8SFTJi5irqO7TaPcdzqj8jJy+W8JTPoULSHTa078syIsUzKHsP8XodANdWoVWhJRFqwW4H/uvsDZnZr+PiWCvvsBb7q7p+YWW9grplNdfft4fab3f2FpgtZRESikJpi/P3648hdspH8tTvJ7t2++VcVdveVZtYJ6Be/v7t/0JiBSfMzcV4Bd0/OY3thSd0OdGfYpk/JycvlokXT6b1rM7szspg6ZDSTsscwY8AIylJS9ztEPaoiIl+QA4wJ7z8F5FIhcXX3j+PurzWzjQSjn7Y3SYQiIpIwUlOMM4b1SNg5rRXVZjmcnwHXAcvgsw40B05vvLCkOanrfNVyfXds4KL8aYzLy+WQLasoSUll2sCj+cWYr/H6kOPYl95qv/3bZKRy/8WHK1kVEalcD3dfF95fD1T7ScTMRgEZBO/v5e43szuB/wK3untRo0QqIiJSR7UZKnw5MNjdixs7GGleJs4r4OZ/zqcu+WrHwp1csPgdcvJyObYgKE49u082d5z9XV4ZeiLbWnf4bF8DrlFRJRGRz1S31Fz8A3d3M6tytoaZ9SJY2u5ady//K34bQcKbQVDN/xbg3iqO11J1IiLSpGqTuH4EdAQ2Nm4o0lzUNWFtVbKPsz6ZRU5+Lqd++gHpsTI+7tKfX57yVSZnn8qaDp93CihZFRGpWnVLzZnZBjPr5e7rwsS00vdtM2sPvEKwrvrMuHOX99YWmdlfgR9XE4eWqhMRkSZVm8T1F8A8M/sI+GzIkLtf1GhRScKp6/zV1FgZJ66YT05+Lud8MpO2xYWsa9uFJ0bmMCl7DPndB35WZElDgEVEGsRk4FrggfDnpIo7mFkGQXHEv1UswhSX9BowjuCLaxERkYRQm8T1KeBBYCFQt0mMkhQmzivgR/+YT6ym79TdGbHuY3Lyc7lg0dt027udnZlteOnQk5mcPYZZ/YYTS0mlTUYqv1WiKiLS0B4A/mFm1wMrCab6YGYjgW+7+zfCtlOALmZ2XXhc+bI3E8ysG8Hgl/nAt5s0ehERkWrUJnHd6+6/b/RIJGHUtXd14NYCxuXlctGiXAZuW0dRajr/HXwsk4aPIXfQsVx20mCe1dBfEZFG5e5bgDMqaZ8DfCO8/zTwdBXHq+iiiIgkrNokrm+b2S8IhiDFDxXWcjhJpK7Jarfd27hw0XRy8nM5cv0nxDDeO+hw/jj6MqYecgKpnTtx14XDeUy9qiIiIiIiUk+1SVyPCn+OjmvTcjjN2IGut9q2aC/nfPweOfm5nLjyQ1I9xkc9BnPfaV/npWGnsKFdV748uj8L1LsqIiIiIiINqMbE1d1Pa4pApGFNnFfAQ1OXULC9EOPzBXjrKr2shFOXf8C4/FzOXDqLVqXFrOrQgz+OvoyJ2WNY1rWfKgGLiIiIiEijqk2PK2Z2PjAcaFXe5u6Vru0m0Zo4r4DbXlxAYdxaNXVNWs1jjFyTz7j8XM5bPINO+3axJas9zx9xFpOyx/BB70PBTEWWRERERESkSdSYuJrZn4DWwGnAX4BLgfcbOS6ppYbqWQUYumkF4/JyuXDRNPru3MTe9ExeGzKaidljeGfAUZSmfv7r8mX1sIqIiIiISBOpTY/rCe5+hJktcPd7zOzXwKuNHZjU7I6JC5kwc9VnyeqBJK29d27kovygyNKwTSsotRTeHngUD53yVV4fMpq9GVn77d+pdTp3XThcvawiIiIiItJkapO4FoY/95pZb2AL0KvxQpKqNFTvaofCXZy3ZAbj8nM5bnWwvvwHvYdy55nf4pVDT2ZLm45AkKT+XEmqiIiIiIhErDaJ68tm1hF4CPiAIF/6c30uamYPARcCxcAy4Gvuvr0+50xmlVUBrmvSmllSxBnLZjMuP5cxy+aQEStlWee+/Pqka5iUPYZVnYLvIjq1Tue3SlZFRERERCSB1Kaq8M/Cu/8ys5eBVu6+o57XfR24zd1LzexB4Dbglnqes9kq70ldu72QDlnpmMG2vSWkmlHmfsC9qymxMo5ftZBxebmM/XgGdTKuqgAAFvpJREFU7YoL2dC2M38/5nxezD6N7UMP4+axhzJdSaqIiIiIiCSwKhNXMzsWWO3u68PHXwW+BKw0s7vdfeuBXtTdX4t7OJOg4FOLFFQBXkhhSRnAfr2qZR6kq3VKWt05bMMyxuW9xUWLptN9zzZK2rYj/Zor4Zpr6DFmDNenpnJ9Az4HERERERGRxlRdj+tjwJkAZnYK8ADwfWAEMJ6GSza/DjzfQOdqdh6auuSzpLU++m9bx7j8XHLypzF46xrK0jNIPf88uOYa0s8/H7Kyaj6JiIiIiIhIAqoucU2N61W9Ahjv7v8iGDI8v6YTm9kbQM9KNt3u7pPCfW4HSoEJ1ZznBuAGgP79+9d02WYjvtDSgeqyZzsXLH6bcXm5HLVuSdB46qlwzZ2kXnopdOrUQNGKiIiIiIhEp9rE1czS3L0UOIMweazFcQC4+5nVbTez64ALgDPcvcrRsO4+nqCHl5EjR9ZnmdLINURV4NbFhZz9yUzG5edy0qfzSPMYO4YMgwcfhKuugn79GjpsERERERGRSFWXgD4LTDOzzQRL4rwNYGYHA/UqzmRmY4GfAKe6+976nKu5qDiXtS5Ja1pZKaesmEdOXi5nL51FVsk+6N8fbvkJXHMNHQ47rHGCFhERERERSQBVJq7ufr+Z/ZdgzdbX4npFUwjmutbHI0Am8LqZAcx092/X85wJrbZzWTuWVxXeU8yxaxdzYV4uF378Dp327IDOneH66+Caa+CEEyAlpfEDFxERERERiVi1Q37dfWYlbR/X96LufnB9z9HcrK3FXNY+HbOYcVFPmDAB/vEMrFgBrVpBTk6QrJ5zDmRkNH6wIiIiIiIiCaTGuapy4OLXZ00J12StTI9dm/nSkre5Yc1MuC0v6Ek980y45x64+GJo166JIxcRkebIzDoTVOofAKwALnf3bZXsVwYsDB+ucveLwvaBwHNAF2Au8BV3L278yEVERKqnxLWRVJzTWjFpbb9vN+cueZec/FxGr15Iijsceyz89rdwxRXQs7KCzCIiItW6Ffivuz9gZreGj2+pZL9Cdx9RSfuDwG/c/Tkz+xNwPfB/jRatiIhILSlxbUA19bBmlhZz+vI5XJSXy+nLZ5NZWgJDhsBdd8HVVwf3RUREDlwOMCa8/xSQS+WJ6xdYUHTidODquOPvRomriIgkACWuDaSqHtaUWBnHrf6InPxpnLdkBu2L9kCPHvC97wbzVkeOhKBAlYiISH31cPd14f31QI8q9mtlZnMI1lJ/wN0nEgwP3h4ugwewBuhT2cHJusa6iIgkLiWuDWS/qsHuDN+4nJy8XC5cNJ1eu7ewOyOLqYcczzvHnsNvxv8I0vTSi4hI3ZnZG0Bl80luj3/g7m5mVa2+dpC7F5jZIOBNM1tIHZa6S6Y11kVEpHlQ9tRA1m4vpO/29eTkT2Ncfi5DtqymJCWV3EHHcH/29bxx8CisdRt+ccnhSlpFROSAufuZVW0zsw1m1svd15lZL2BjFecoCH8uN7Nc4CjgX0BHM0sLe137AgUN/gREREQOgDKo+tq8Gf7xDyY990eOWJkHwPt9s7n97O/yyqEnsat1B2Lu9O6Yxc3nDGXcUZWOuhIREWkIk4FrgQfCn5Mq7mBmnYC97l5kZl2BE4Ffhj20bwGXElQWrvR4ERGRKChxPRB79sDkycF6q1OnQmkpAwYP5eHTruPFoSezpkMwpSgrPZVfX3K4klUREWkqDwD/MLPrgZXA5QBmNhL4trt/AxgGPGZmMSCFYI5rfnj8LcBzZnYfMA94vKmfgIiISGWUuNZWaSm88UaQrP7730Hy2rcv/OhHcM01tD/8cAbNX4tPXYJtL1QPq4iINDl33wKcUUn7HOAb4f13gcOrOH45MKoxYxQRETkQSlyr4w6zZgXJ6vPPw6ZN0LFjsHTNNdfAySdDSspnu487qo8SVRERERERkQamxLUyS5YEyeozz8CyZZCZCRdeGCSr554LmZnBmq2/zGWteldFREREREQalRLXcuvWwXPPBQnr3LnB2qqnnw633w6XXAIdOny2a8U1Wwu2F3LbiwsBlLyKiIiIiIg0sJaduO7cCS++GCSrb74JsRgccwz8+tdw5ZXQu3elh+23ZmuosKSMh6YuUeIqIiIiIiLSwFpe4lpUBP/5T5CsvvQS7NsHgwYFPatXXw2HHlrjKdZuL6xTu4iIiIiIiBy4SBJXM/sZkAPECBZHv87d1zbaBWMxeOcdePppeOEF2LYNunWDb3wjmLd63HHB0OBa6t0xi4JKktTeHbMaMmoREREREREhuh7Xh9z9/wGY2Q+AO4FvN/hVFiwIelaffRZWr4Y2bWDcuCBZPfNMSE+v8RQT5xXw0NQl+xVhuvmcofvNcYVgzdabzxna4E9BRERERESkpUupeZeG5+474x62AbzBTr5qFTzwABx+OBx5ZDBf9fDDgwR2w4ag1/Xcc2udtN724kIKthfi7F+E6ReXHE6fjlkY0KdjFr+45HDNbxUREREREWkEkc1xNbP7ga8CO4DT6nWywkL429+C5PTtt4O244+HRx6Byy8PhgVXorLe1Pjks7oiTDNuPV2JqoiIiIiISBNotMTVzN4Aelay6XZ3n+TutwO3m9ltwI3AXVWc5wbgBoD+/ftXfcGbb4Y+feBnPwuKLA0aVG18tVnSRkWYREREREREotdoiau7n1nLXScAU6gicXX38cB4gJEjR1Y+pDgrC/LyoG/fWhdZqs2SNirCJCIiIiIiEr1I5ria2ZC4hznA4nqftF+/OlUGrk1v6s3nDCUrPXW/7SrCJCIiIiIi0rSimuP6gJkNJVgOZyWNUVG4BrXpTS3vea1uHqyIiIiIiIg0rkgSV3f/UhTXjVfbJW3GHdVHiaqIiIiIiEiEIqsqHDX1poqIiIiIiDQPLTZxBfWmiohI8jCzzsDzwABgBXC5u2+rsM9pwG/img4FrnT3iWb2JHAqwTJ1ANe5+/zGjVpERKR2IinOJCIiIg3uVuC/7j4E+G/4eD/u/pa7j3D3EcDpwF7gtbhdbi7frqRVREQSiRJXERGR5JADPBXefwoYV8P+lwKvuvvexgxKRESkIShxFRERSQ493H1deH890KOG/a8Enq3Qdr+ZLTCz35hZZoNHKCIicoBa9BxXERGR5sTM3gB6VrLp9vgH7u5m5tWcpxdwODA1rvk2goQ3AxgP3ALcW8XxNwA3APTv378Oz0BEROTAKHEVERFpJtz9zKq2mdkGM+vl7uvCxHRjNae6HPi3u5fEnbu8t7bIzP4K/LiaOMYTJLeMHDmyygRZRESkoWiosIiISHKYDFwb3r8WmFTNvldRYZhwmOxiZkYwP/ajhg9RRETkwChxFRERSQ4PAGeZ2SfAmeFjzGykmf2lfCczGwD0A6ZVOH6CmS0EFgJdgfuaImgREZHa0FBhERGRJODuW4AzKmmfA3wj7vEK4AuLmLv76Y0Zn4iISH2ox1VEREREREQSmhJXERERERERSWhKXEVERERERCShKXEVERERERGRhBZp4mpm/2tmbmZdo4xDREREREREEldkiauZ9QPOBlZFFYOIiIiIiIgkvih7XH8D/ATwCGMQERERERGRBBdJ4mpmOUCBu39Yi31vMLM5ZjZn06ZNTRCdiIiIiIiIJJK0xjqxmb0B9Kxk0+3ATwmGCdfI3ccD4wFGjhxZae/sxHkFPDR1CWu3F9K7YxY3nzOUcUd9YW11ERERERERaYYaLXF19zMrazezw4GBwIdmBtAX+MDMRrn7+rpeZ+K8Am57cSGFJWUAFGwv5LYXFwIoeRUREREREUkCTT5U2N0Xunt3dx/g7gOANcDRB5K0Ajw0dclnSWu5wpIyHpq6pP7BioiIiIiISOSa/Tqua7cX1qldREREREREmpfIE9ew53XzgR7fu2NWndpFRERERESkeYk8ca2vm88ZSlZ66n5tWemp3HzO0IgiEhERERERkYbUaMWZmkp5ASZVFRYREREREUlOzT5xhSB5VaIqIiIiIiKSnJr9UGEREREJmNllZpZnZjEzG1nNfmPNbImZLTWzW+PaB5rZrLD9eTPLaJrIRUREqqfEVUREJHl8BFwCTK9qBzNLBR4FzgWygavMLDvc/CDwG3c/GNgGXN+44YqIiNSOElcREZEk4e6L3L2mhcxHAUvdfbm7FwPPATlmZsDpwAvhfk8B4xotWBERkTpQ4ioiItKy9AFWxz1eE7Z1Aba7e2mFdhERkcg1q+JMc+fO3WxmK6vZpStwwGvCJgm9BnoNQK8B6DUAvQZQ82twUFMF0lDM7A2gZyWbbnf3SU0Uww3ADeHD3WZWUy9vbej3tWp6bSqn16Vyel0qp9elaon22lT63tysEld371bddjOb4+5VFqNoCfQa6DUAvQag1wD0GkByvgbufmY9T1EA9It73Dds2wJ0NLO0sNe1vL2yGMYD4+sZx36S8d+qoei1qZxel8rpdamcXpeqNZfXRkOFRUREWpbZwJCwgnAGcCUw2d0deAu4NNzvWqBJenBFRERqosRVREQkSZjZxWa2BjgeeMXMpobtvc1sCkDYm3ojMBVYBPzD3fPCU9wC/MjMlhLMeX28qZ+DiIhIZZrVUOFaaNBhS82UXgO9BqDXAPQagF4DaGGvgbv/G/h3Je1rgfPiHk8BplSy33KCqsNRaFH/VnWk16Zyel0qp9elcnpdqtYsXhsLRgaJiIiIiIiIJCYNFRYREREREZGElnSJq5n9zMwWmNl8M3vNzHpHHVNTM7OHzGxx+Dr828w6Rh1TUzOzy8wsz8xiZpbwVdIaipmNNbMlZrbUzG6NOp4omNkTZrbRzD6KOpYomFk/M3vLzPLD/wM3RR1TUzOzVmb2vpl9GL4G90Qdk1RPf7u+SP+Xq2dmqWY2z8xejjqWRGJmHc3shfBz4CIzOz7qmBKBmf1P+P/oIzN71sxaRR1TVCr7nGRmnc3sdTP7JPzZKcoYq5J0iSvwkLsf4e4jgJeBOyOOJwqvA4e5+xHAx8BtEccThY+AS4DpUQfSVMwsFXgUOBfIBq4ys+xoo4rEk8DYqIOIUCnwv+6eDYwGvtcCfw+KgNPd/UhgBDDWzEZHG5JURX+7qqT/y9W7iaC4mOzvd8B/3P1Q4Ej0GmFmfYAfACPd/TAglaCaekv1JF/8nHQr8F93HwL8N3yccJIucXX3nXEP2wAtbhKvu78WVo0EmEmwFl+L4u6L3H1J1HE0sVHAUndf7u7FwHNATsQxNTl3nw5sjTqOqLj7Onf/ILy/i+BDS59oo2paHtgdPkwPby3uvaAZ0d+uSuj/ctXMrC9wPvCXqGNJJGbWATiFsBq4uxe7+/ZIg0ocaUCWmaUBrYG1EccTmSo+J+UAT4X3nwLGNWVMtZV0iSuAmd1vZquBa2iZPa7xvg68GnUQ0iT6AKvjHq9BH3JaNDMbABwFzIo4lCYXDiOcD2wEXnf3FvcaNCP621WDlvx/uQq/BX4CxCKOI9EMBDYBfw2HUf/FzNpEHVTU3L0A+BWwClgH7HD316KNKuH0cPd14f31QI8og6lKs0xczeyNcIx6xVsOgLvf7u79gAkEa9UlnZpeg3Cf2wmGGk2ILtLGU5vXQKSlMrO2wL+AH1YYidIiuHtZOGWkLzDKzA6LOCSRA9LS/y9XZGYXABvdfW7UsSSgNOBo4P/c/ShgDwk65LMphfM1cwgS+95AGzP7crRRJS4PlpxJyFFKzXIdV3c/s5a7TiBYp+6uRgwnEjW9BmZ2HXABcIYn6ZpHdfg9aCkKgH5xj/uGbdLCmFk6wQfdCe7+YtTxRMndt5vZWwTzeVpkwa5mQH+7qqD/y5U6EbjIzM4DWgHtzexpd1ciEoxWWBM3wuQFlLgCnAl86u6bAMzsReAE4OlIo0osG8ysl7uvM7NeBKOVEk6z7HGtjpkNiXuYAyyOKpaomNlYgiE0F7n73qjjkSYzGxhiZgPNLIOg8MDkiGOSJmZmRjC/aZG7Pxx1PFEws27l1dTNLAs4ixb4XtCM6G9XJfR/uXLufpu793X3AQS/K28qaQ24+3pgtZkNDZvOAPIjDClRrAJGm1nr8P/VGahoVUWTgWvD+9cCkyKMpUpJl7gCD4TDRRcAZxNUnWtpHgHaAa9bsCzQn6IOqKmZ2cVmtgY4HnjFzKZGHVNjCwty3QhMJfiD/A93z4s2qqZnZs8C7wFDzWyNmV0fdUxN7ETgK8Dp4f//+WHPREvSC3grfB+YTTDHVUtmJCj97aqS/i/Lgfg+MCH8+zcC+Hm04UQv7IF+AfgAWEiQ/4yPNKgIVfE56QHgLDP7hKCH+oEoY6yKJekoUhEREREREUkSydjjKiIiIiIiIklEiauIiIiIiIgkNCWuIiIiIiIiktCUuIqIiIiIiEhCU+IqIiIiIiIiCU2Jq7R4ZtYlbqmB9WZWEN7fbmZNuv6ZmY0zs+y4x/ea2ZkHcJ4BZvZRFduGm9mbZrbEzJaZ2T1m1uB/C6p7LmaWa2YjG/qaIiIiIpKclLhKi+fuW9x9hLuPAP4E/Ca8PwKINfT1zCytms3jgM+SPXe/093faMBrZxEsMv2Auw8FDgdG0TjrHY+jEZ+LiIiIiLQcSlxFqpdqZn82szwzey1M/DCzwWb2HzOba2Zvm9mhYfuAsDdzgZn918z6h+1PmtmfzGwW8MvKjjezE4CLgIfCHt/B4XGXhuc41szeNbMPzex9M2sXXu9tM/sgvJ1Qw/O5Gpjh7q8BuPte4Ebg5vAad5vZj8t3NrOPzGxAeH9iGG+emd0Qt89uM7s/jGummfWo6bnEM7Ozzey9MP5/mlnbsP0BM8sPX8tf1f2fTkRERESShRJXkeoNAR519+HAduBLYft44PvufgzwY+CPYfsfgKfc/QhgAvD7uHP1BU5w9x9Vdry7v0vQG3pz2AO8rPxAM8sAngducvcjgTOBQmAjcJa7Hw1cUeF6lRkOzI1vCK+TZWYdazj262G8I4EfmFmXsL0NMDOMazrwzeqeSzwz6wrcAZwZPoc5wI/Cc18MDA9fy/tqiE1EREREklh1QxZFBD519/nh/bnAgLBH8ATgn2ZWvl9m+PN44JLw/t+BX8ad65/uXlbD8VUZCqxz99kA7r4TwMzaAI+Y2QigDDikrk+wDn5gZheH9/sRJPVbgGLg5bB9LnBWHc45mmA48YzwtcgA3gN2APuAx83s5bjzi4iIiEgLpMRVpHpFcffLgCyCkQrbw3mwdbEn/Hmgx1fmf4ANwJHheffVsH8+cEp8g5kNAra4+3YzK2X/kRitwn3GEPTyHu/ue80st3wbUOLuHt4vo25/Vwx43d2v+sIGs1HAGcClBMOZT6/DeUVEREQkiWiosEgdhb2dn5rZZQAWODLc/C5wZXj/GuDtOh6/C2hXyWWXAL3M7NjwmHZhkacOBD2xMeArQGoN4U8AToqr7ptFMLz4rnD7CuDocNvRwMCwvQOwLUxaDyXoKa1JVc8l3kzgRDM7OLxmGzM7JOyV7uDuUwiS8yOrO4mIiIiIJDclriIH5hrgejP7EMgDcsL27wNfM7MFBIlkVdV6qzr+OeBmM5tnZoPLd3b3YoI5rH8Ij3mdoMfzj8C1YduhfN6rWyl3LyQomnS7mX0MbCYo1jQh3OVfQGczyyPo5fw4bP8PkGZmi4AHCBLOmlT6XCrEswm4Dng2fM3eC59HO+DlsO0d4Ee1uJ6IiIiIJCn7fISfiLQ0ZjYOeBg4zd1XRhyOiIiIiEillLiKiIiIiIhIQtNQYREREREREUloSlxFREREREQkoSlxFRERERERkYSmxFVEREREREQSmhJXERERERERSWhKXEVERERERCShKXEVERERERGRhPb/AevqV17y0EThAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "model_fit.plot_diagnostics(figsize=(16,8));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Hbn9UK_vDQJ0",
        "outputId": "b6497cf7-8ef8-472d-ba4d-c33f31a2467e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f6170a16430>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "fitted = pd.Series(model_fit.predict()).reset_index()\n",
        "df = geracaoNE.reset_index()\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(df['val_geracao'].iloc[1:], label='Observado')\n",
        "ax.plot(fitted['predicted_mean'].iloc[1:], label='Previsão')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aplicação de Machine Learning a Séries temporais"
      ],
      "metadata": {
        "id": "lS98xBelMbr7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Os modelos de ML aplicados foram: SVR (Support Vector Regression), MLP (Multi-Layer Perceptron), LGBM (LightGBM) e LSTM (Long Short-Term Memory). Como  métricas de avaliação foram utilizados o MSE (Mean Squared Error), o MAE (Mean Absolute Error) e o MAPE (Mean Absolute Percentage Error). O MSE mede a média do quadrado das diferenças entre os valores previstos e os valores reais da série temporal, enquanto o MAE mede a média das diferenças absolutas entre os valores previstos e os valores reais. Já o MAPE mede a porcentagem média de diferença absoluta entre os valores previstos e os valores reais."
      ],
      "metadata": {
        "id": "8xfFQ-Awm89y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pM35EhiqETiF"
      },
      "outputs": [],
      "source": [
        "def windonXy(dat,n_lags):\n",
        "  X = pd.DataFrame()\n",
        "  y = list()\n",
        "  for i in range(len(dat)):\n",
        "    end_ix = i + n_lags\n",
        "    if end_ix > len(dat)-1:\n",
        "      break\n",
        "    n = np.array(dat[i:end_ix])\n",
        "    df = (pd.DataFrame(n)).T\n",
        "    X= pd.concat([X,df],axis=0)\n",
        "    y.append(dat[end_ix])\n",
        "  y= pd.DataFrame(y)\n",
        "  return(X,y)\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "st_train, st_test = train_test_split(geracaoNE['val_geracao'],shuffle=False, test_size=0.25)\n",
        "st_train = np.array(st_train)\n",
        "st_test = np.array(st_test)\n",
        "min = np.min(st_train)\n",
        "max = np.max(st_train)\n",
        "st_train = (st_train - min) / (max - min)\n",
        "st_test = (st_test - min) / (max - min)"
      ],
      "metadata": {
        "id": "ZJ_TRLjjnRwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qwgs1NZwCpqT"
      },
      "outputs": [],
      "source": [
        "X_train,y_train = windonXy(st_train,24)\n",
        "X_test,y_test = windonXy(st_test,24)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "8VBFPsSPZs9U",
        "outputId": "040d95bd-e98d-4c1a-8f53-2fcf9ed4acf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(534, 24)\n",
            "(534, 1)\n",
            "(162, 24)\n",
            "(162, 1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         0         1         2         3         4         5         6   \\\n",
              "0  0.731627  0.659203  0.577821  0.549911  0.540754  0.493904  0.489982   \n",
              "0  0.659203  0.577821  0.549911  0.540754  0.493904  0.489982  0.648703   \n",
              "0  0.577821  0.549911  0.540754  0.493904  0.489982  0.648703  0.641119   \n",
              "0  0.549911  0.540754  0.493904  0.489982  0.648703  0.641119  0.550780   \n",
              "0  0.540754  0.493904  0.489982  0.648703  0.641119  0.550780  0.455516   \n",
              "\n",
              "         7         8         9   ...        14        15        16        17  \\\n",
              "0  0.648703  0.641119  0.550780  ...  0.474623  0.492530  0.449158  0.339306   \n",
              "0  0.641119  0.550780  0.455516  ...  0.492530  0.449158  0.339306  0.380870   \n",
              "0  0.550780  0.455516  0.439209  ...  0.449158  0.339306  0.380870  0.539708   \n",
              "0  0.455516  0.439209  0.410856  ...  0.339306  0.380870  0.539708  0.582440   \n",
              "0  0.439209  0.410856  0.419064  ...  0.380870  0.539708  0.582440  0.605207   \n",
              "\n",
              "         18        19        20        21        22        23  \n",
              "0  0.380870  0.539708  0.582440  0.605207  0.662901  0.689669  \n",
              "0  0.539708  0.582440  0.605207  0.662901  0.689669  0.619117  \n",
              "0  0.582440  0.605207  0.662901  0.689669  0.619117  0.515847  \n",
              "0  0.605207  0.662901  0.689669  0.619117  0.515847  0.440871  \n",
              "0  0.662901  0.689669  0.619117  0.515847  0.440871  0.410557  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-61cad0ad-7fda-482c-8c2b-637b07ce91fd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.731627</td>\n",
              "      <td>0.659203</td>\n",
              "      <td>0.577821</td>\n",
              "      <td>0.549911</td>\n",
              "      <td>0.540754</td>\n",
              "      <td>0.493904</td>\n",
              "      <td>0.489982</td>\n",
              "      <td>0.648703</td>\n",
              "      <td>0.641119</td>\n",
              "      <td>0.550780</td>\n",
              "      <td>...</td>\n",
              "      <td>0.474623</td>\n",
              "      <td>0.492530</td>\n",
              "      <td>0.449158</td>\n",
              "      <td>0.339306</td>\n",
              "      <td>0.380870</td>\n",
              "      <td>0.539708</td>\n",
              "      <td>0.582440</td>\n",
              "      <td>0.605207</td>\n",
              "      <td>0.662901</td>\n",
              "      <td>0.689669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.659203</td>\n",
              "      <td>0.577821</td>\n",
              "      <td>0.549911</td>\n",
              "      <td>0.540754</td>\n",
              "      <td>0.493904</td>\n",
              "      <td>0.489982</td>\n",
              "      <td>0.648703</td>\n",
              "      <td>0.641119</td>\n",
              "      <td>0.550780</td>\n",
              "      <td>0.455516</td>\n",
              "      <td>...</td>\n",
              "      <td>0.492530</td>\n",
              "      <td>0.449158</td>\n",
              "      <td>0.339306</td>\n",
              "      <td>0.380870</td>\n",
              "      <td>0.539708</td>\n",
              "      <td>0.582440</td>\n",
              "      <td>0.605207</td>\n",
              "      <td>0.662901</td>\n",
              "      <td>0.689669</td>\n",
              "      <td>0.619117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.577821</td>\n",
              "      <td>0.549911</td>\n",
              "      <td>0.540754</td>\n",
              "      <td>0.493904</td>\n",
              "      <td>0.489982</td>\n",
              "      <td>0.648703</td>\n",
              "      <td>0.641119</td>\n",
              "      <td>0.550780</td>\n",
              "      <td>0.455516</td>\n",
              "      <td>0.439209</td>\n",
              "      <td>...</td>\n",
              "      <td>0.449158</td>\n",
              "      <td>0.339306</td>\n",
              "      <td>0.380870</td>\n",
              "      <td>0.539708</td>\n",
              "      <td>0.582440</td>\n",
              "      <td>0.605207</td>\n",
              "      <td>0.662901</td>\n",
              "      <td>0.689669</td>\n",
              "      <td>0.619117</td>\n",
              "      <td>0.515847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.549911</td>\n",
              "      <td>0.540754</td>\n",
              "      <td>0.493904</td>\n",
              "      <td>0.489982</td>\n",
              "      <td>0.648703</td>\n",
              "      <td>0.641119</td>\n",
              "      <td>0.550780</td>\n",
              "      <td>0.455516</td>\n",
              "      <td>0.439209</td>\n",
              "      <td>0.410856</td>\n",
              "      <td>...</td>\n",
              "      <td>0.339306</td>\n",
              "      <td>0.380870</td>\n",
              "      <td>0.539708</td>\n",
              "      <td>0.582440</td>\n",
              "      <td>0.605207</td>\n",
              "      <td>0.662901</td>\n",
              "      <td>0.689669</td>\n",
              "      <td>0.619117</td>\n",
              "      <td>0.515847</td>\n",
              "      <td>0.440871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.540754</td>\n",
              "      <td>0.493904</td>\n",
              "      <td>0.489982</td>\n",
              "      <td>0.648703</td>\n",
              "      <td>0.641119</td>\n",
              "      <td>0.550780</td>\n",
              "      <td>0.455516</td>\n",
              "      <td>0.439209</td>\n",
              "      <td>0.410856</td>\n",
              "      <td>0.419064</td>\n",
              "      <td>...</td>\n",
              "      <td>0.380870</td>\n",
              "      <td>0.539708</td>\n",
              "      <td>0.582440</td>\n",
              "      <td>0.605207</td>\n",
              "      <td>0.662901</td>\n",
              "      <td>0.689669</td>\n",
              "      <td>0.619117</td>\n",
              "      <td>0.515847</td>\n",
              "      <td>0.440871</td>\n",
              "      <td>0.410557</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61cad0ad-7fda-482c-8c2b-637b07ce91fd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-61cad0ad-7fda-482c-8c2b-637b07ce91fd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-61cad0ad-7fda-482c-8c2b-637b07ce91fd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "X_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP regressor"
      ],
      "metadata": {
        "id": "5tk0Yk70Mjz9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lzcRi3uXDRb",
        "outputId": "d9700a1f-1206-4634-e160-0c5c9505d546"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mA saída de streaming foi truncada nas últimas 5000 linhas.\u001b[0m\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "310/400 [======================>.......] - ETA: 0s - loss: 0.0389 - mean_squared_error: 0.0025\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "320/400 [=======================>......] - ETA: 0s - loss: 0.0386 - mean_squared_error: 0.0025\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "331/400 [=======================>......] - ETA: 0s - loss: 0.0385 - mean_squared_error: 0.0024\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "341/400 [========================>.....] - ETA: 0s - loss: 0.0383 - mean_squared_error: 0.0024\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "352/400 [=========================>....] - ETA: 0s - loss: 0.0386 - mean_squared_error: 0.0025\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "363/400 [==========================>...] - ETA: 0s - loss: 0.0391 - mean_squared_error: 0.0025\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "373/400 [==========================>...] - ETA: 0s - loss: 0.0392 - mean_squared_error: 0.0025\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "383/400 [===========================>..] - ETA: 0s - loss: 0.0388 - mean_squared_error: 0.0025\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "394/400 [============================>.] - ETA: 0s - loss: 0.0389 - mean_squared_error: 0.0025\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00067\n",
            "400/400 [==============================] - 2s 6ms/step - loss: 0.0394 - mean_squared_error: 0.0026 - val_loss: 0.0411 - val_mean_squared_error: 0.0026 - lr: 5.0000e-04\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "  1/400 [..............................] - ETA: 3s - loss: 0.0605 - mean_squared_error: 0.0037\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            " 11/400 [..............................] - ETA: 2s - loss: 0.0301 - mean_squared_error: 0.0015\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            " 22/400 [>.............................] - ETA: 1s - loss: 0.0278 - mean_squared_error: 0.0014\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            " 33/400 [=>............................] - ETA: 1s - loss: 0.0278 - mean_squared_error: 0.0013\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            " 44/400 [==>...........................] - ETA: 1s - loss: 0.0282 - mean_squared_error: 0.0013\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            " 55/400 [===>..........................] - ETA: 1s - loss: 0.0293 - mean_squared_error: 0.0014\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            " 66/400 [===>..........................] - ETA: 1s - loss: 0.0324 - mean_squared_error: 0.0016\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            " 76/400 [====>.........................] - ETA: 1s - loss: 0.0330 - mean_squared_error: 0.0017\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            " 87/400 [=====>........................] - ETA: 1s - loss: 0.0319 - mean_squared_error: 0.0016\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            " 98/400 [======>.......................] - ETA: 1s - loss: 0.0322 - mean_squared_error: 0.0016\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "109/400 [=======>......................] - ETA: 1s - loss: 0.0317 - mean_squared_error: 0.0015\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "120/400 [========>.....................] - ETA: 1s - loss: 0.0327 - mean_squared_error: 0.0017\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "131/400 [========>.....................] - ETA: 1s - loss: 0.0341 - mean_squared_error: 0.0019\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "141/400 [=========>....................] - ETA: 1s - loss: 0.0339 - mean_squared_error: 0.0020\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "151/400 [==========>...................] - ETA: 1s - loss: 0.0343 - mean_squared_error: 0.0020\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "163/400 [===========>..................] - ETA: 1s - loss: 0.0347 - mean_squared_error: 0.0021\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "174/400 [============>.................] - ETA: 1s - loss: 0.0356 - mean_squared_error: 0.0022\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "185/400 [============>.................] - ETA: 1s - loss: 0.0359 - mean_squared_error: 0.0022\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "197/400 [=============>................] - ETA: 0s - loss: 0.0356 - mean_squared_error: 0.0021\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "208/400 [==============>...............] - ETA: 0s - loss: 0.0357 - mean_squared_error: 0.0021\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "219/400 [===============>..............] - ETA: 0s - loss: 0.0359 - mean_squared_error: 0.0021\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "229/400 [================>.............] - ETA: 0s - loss: 0.0361 - mean_squared_error: 0.0022\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "240/400 [=================>............] - ETA: 0s - loss: 0.0363 - mean_squared_error: 0.0022\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "252/400 [=================>............] - ETA: 0s - loss: 0.0366 - mean_squared_error: 0.0022\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "263/400 [==================>...........] - ETA: 0s - loss: 0.0366 - mean_squared_error: 0.0023\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "274/400 [===================>..........] - ETA: 0s - loss: 0.0366 - mean_squared_error: 0.0023\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "284/400 [====================>.........] - ETA: 0s - loss: 0.0368 - mean_squared_error: 0.0023\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "295/400 [=====================>........] - ETA: 0s - loss: 0.0366 - mean_squared_error: 0.0023\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "306/400 [=====================>........] - ETA: 0s - loss: 0.0372 - mean_squared_error: 0.0024\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "317/400 [======================>.......] - ETA: 0s - loss: 0.0375 - mean_squared_error: 0.0024\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "327/400 [=======================>......] - ETA: 0s - loss: 0.0372 - mean_squared_error: 0.0024\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "338/400 [========================>.....] - ETA: 0s - loss: 0.0381 - mean_squared_error: 0.0025\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "349/400 [=========================>....] - ETA: 0s - loss: 0.0381 - mean_squared_error: 0.0025\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "360/400 [==========================>...] - ETA: 0s - loss: 0.0378 - mean_squared_error: 0.0025\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "371/400 [==========================>...] - ETA: 0s - loss: 0.0373 - mean_squared_error: 0.0024\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "383/400 [===========================>..] - ETA: 0s - loss: 0.0368 - mean_squared_error: 0.0024\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "394/400 [============================>.] - ETA: 0s - loss: 0.0369 - mean_squared_error: 0.0024\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00067\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.0367 - mean_squared_error: 0.0024 - val_loss: 0.0439 - val_mean_squared_error: 0.0028 - lr: 5.0000e-04\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "  1/400 [..............................] - ETA: 3s - loss: 0.0155 - mean_squared_error: 2.4126e-04\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            " 12/400 [..............................] - ETA: 1s - loss: 0.0410 - mean_squared_error: 0.0019    \n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            " 24/400 [>.............................] - ETA: 1s - loss: 0.0385 - mean_squared_error: 0.0020\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            " 35/400 [=>............................] - ETA: 1s - loss: 0.0413 - mean_squared_error: 0.0024\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            " 47/400 [==>...........................] - ETA: 1s - loss: 0.0435 - mean_squared_error: 0.0027\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            " 58/400 [===>..........................] - ETA: 1s - loss: 0.0469 - mean_squared_error: 0.0037\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            " 69/400 [====>.........................] - ETA: 1s - loss: 0.0446 - mean_squared_error: 0.0035\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            " 79/400 [====>.........................] - ETA: 1s - loss: 0.0435 - mean_squared_error: 0.0033\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            " 91/400 [=====>........................] - ETA: 1s - loss: 0.0402 - mean_squared_error: 0.0030\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "102/400 [======>.......................] - ETA: 1s - loss: 0.0399 - mean_squared_error: 0.0029\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "113/400 [=======>......................] - ETA: 1s - loss: 0.0419 - mean_squared_error: 0.0031\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "124/400 [========>.....................] - ETA: 1s - loss: 0.0412 - mean_squared_error: 0.0030\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "136/400 [=========>....................] - ETA: 1s - loss: 0.0409 - mean_squared_error: 0.0030\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "148/400 [==========>...................] - ETA: 1s - loss: 0.0396 - mean_squared_error: 0.0028\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "159/400 [==========>...................] - ETA: 1s - loss: 0.0394 - mean_squared_error: 0.0028\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "170/400 [===========>..................] - ETA: 1s - loss: 0.0388 - mean_squared_error: 0.0027\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "180/400 [============>.................] - ETA: 1s - loss: 0.0380 - mean_squared_error: 0.0026\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "191/400 [=============>................] - ETA: 0s - loss: 0.0375 - mean_squared_error: 0.0025\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "202/400 [==============>...............] - ETA: 0s - loss: 0.0377 - mean_squared_error: 0.0025\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "213/400 [==============>...............] - ETA: 0s - loss: 0.0370 - mean_squared_error: 0.0025\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "223/400 [===============>..............] - ETA: 0s - loss: 0.0370 - mean_squared_error: 0.0024\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "232/400 [================>.............] - ETA: 0s - loss: 0.0371 - mean_squared_error: 0.0024\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "241/400 [=================>............] - ETA: 0s - loss: 0.0369 - mean_squared_error: 0.0024\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "251/400 [=================>............] - ETA: 0s - loss: 0.0375 - mean_squared_error: 0.0025\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "259/400 [==================>...........] - ETA: 0s - loss: 0.0381 - mean_squared_error: 0.0026\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "270/400 [===================>..........] - ETA: 0s - loss: 0.0376 - mean_squared_error: 0.0025\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "277/400 [===================>..........] - ETA: 0s - loss: 0.0375 - mean_squared_error: 0.0025\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "285/400 [====================>.........] - ETA: 0s - loss: 0.0377 - mean_squared_error: 0.0025\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "292/400 [====================>.........] - ETA: 0s - loss: 0.0382 - mean_squared_error: 0.0026\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "298/400 [=====================>........] - ETA: 0s - loss: 0.0380 - mean_squared_error: 0.0026\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "305/400 [=====================>........] - ETA: 0s - loss: 0.0383 - mean_squared_error: 0.0026\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "312/400 [======================>.......] - ETA: 0s - loss: 0.0380 - mean_squared_error: 0.0026\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "321/400 [=======================>......] - ETA: 0s - loss: 0.0383 - mean_squared_error: 0.0026\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "331/400 [=======================>......] - ETA: 0s - loss: 0.0380 - mean_squared_error: 0.0026\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "342/400 [========================>.....] - ETA: 0s - loss: 0.0389 - mean_squared_error: 0.0027\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "353/400 [=========================>....] - ETA: 0s - loss: 0.0393 - mean_squared_error: 0.0027\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "364/400 [==========================>...] - ETA: 0s - loss: 0.0390 - mean_squared_error: 0.0027\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "375/400 [===========================>..] - ETA: 0s - loss: 0.0392 - mean_squared_error: 0.0027\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "387/400 [============================>.] - ETA: 0s - loss: 0.0396 - mean_squared_error: 0.0028\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "398/400 [============================>.] - ETA: 0s - loss: 0.0397 - mean_squared_error: 0.0027\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 46: loss did not improve from 0.00067\n",
            "400/400 [==============================] - 2s 6ms/step - loss: 0.0398 - mean_squared_error: 0.0028 - val_loss: 0.0608 - val_mean_squared_error: 0.0056 - lr: 5.0000e-04\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "  1/400 [..............................] - ETA: 2s - loss: 0.0399 - mean_squared_error: 0.0016\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            " 12/400 [..............................] - ETA: 1s - loss: 0.0449 - mean_squared_error: 0.0033\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            " 25/400 [>.............................] - ETA: 1s - loss: 0.0446 - mean_squared_error: 0.0038\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            " 35/400 [=>............................] - ETA: 1s - loss: 0.0466 - mean_squared_error: 0.0037\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            " 46/400 [==>...........................] - ETA: 1s - loss: 0.0412 - mean_squared_error: 0.0031\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            " 57/400 [===>..........................] - ETA: 1s - loss: 0.0410 - mean_squared_error: 0.0030\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            " 68/400 [====>.........................] - ETA: 1s - loss: 0.0411 - mean_squared_error: 0.0030\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            " 79/400 [====>.........................] - ETA: 1s - loss: 0.0397 - mean_squared_error: 0.0028\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            " 91/400 [=====>........................] - ETA: 1s - loss: 0.0384 - mean_squared_error: 0.0027\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "103/400 [======>.......................] - ETA: 1s - loss: 0.0375 - mean_squared_error: 0.0025\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "114/400 [=======>......................] - ETA: 1s - loss: 0.0381 - mean_squared_error: 0.0026\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "125/400 [========>.....................] - ETA: 1s - loss: 0.0380 - mean_squared_error: 0.0025\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "136/400 [=========>....................] - ETA: 1s - loss: 0.0393 - mean_squared_error: 0.0028\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "147/400 [==========>...................] - ETA: 1s - loss: 0.0388 - mean_squared_error: 0.0027\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "159/400 [==========>...................] - ETA: 1s - loss: 0.0397 - mean_squared_error: 0.0027\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "170/400 [===========>..................] - ETA: 1s - loss: 0.0398 - mean_squared_error: 0.0027\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "182/400 [============>.................] - ETA: 1s - loss: 0.0397 - mean_squared_error: 0.0027\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "193/400 [=============>................] - ETA: 0s - loss: 0.0394 - mean_squared_error: 0.0027\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "203/400 [==============>...............] - ETA: 0s - loss: 0.0390 - mean_squared_error: 0.0026\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "213/400 [==============>...............] - ETA: 0s - loss: 0.0389 - mean_squared_error: 0.0026\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "222/400 [===============>..............] - ETA: 0s - loss: 0.0385 - mean_squared_error: 0.0026\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "233/400 [================>.............] - ETA: 0s - loss: 0.0392 - mean_squared_error: 0.0026\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "244/400 [=================>............] - ETA: 0s - loss: 0.0399 - mean_squared_error: 0.0027\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "255/400 [==================>...........] - ETA: 0s - loss: 0.0403 - mean_squared_error: 0.0028\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "267/400 [===================>..........] - ETA: 0s - loss: 0.0401 - mean_squared_error: 0.0027\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "276/400 [===================>..........] - ETA: 0s - loss: 0.0405 - mean_squared_error: 0.0028\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "287/400 [====================>.........] - ETA: 0s - loss: 0.0405 - mean_squared_error: 0.0028\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "298/400 [=====================>........] - ETA: 0s - loss: 0.0400 - mean_squared_error: 0.0027\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "309/400 [======================>.......] - ETA: 0s - loss: 0.0401 - mean_squared_error: 0.0027\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "320/400 [=======================>......] - ETA: 0s - loss: 0.0401 - mean_squared_error: 0.0027\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "332/400 [=======================>......] - ETA: 0s - loss: 0.0403 - mean_squared_error: 0.0027\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "342/400 [========================>.....] - ETA: 0s - loss: 0.0400 - mean_squared_error: 0.0027\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "353/400 [=========================>....] - ETA: 0s - loss: 0.0397 - mean_squared_error: 0.0026\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "364/400 [==========================>...] - ETA: 0s - loss: 0.0393 - mean_squared_error: 0.0026\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "375/400 [===========================>..] - ETA: 0s - loss: 0.0394 - mean_squared_error: 0.0026\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "385/400 [===========================>..] - ETA: 0s - loss: 0.0394 - mean_squared_error: 0.0026\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "395/400 [============================>.] - ETA: 0s - loss: 0.0393 - mean_squared_error: 0.0026\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00067\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.0395 - mean_squared_error: 0.0026 - val_loss: 0.0577 - val_mean_squared_error: 0.0049 - lr: 5.0000e-04\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "  1/400 [..............................] - ETA: 2s - loss: 0.1027 - mean_squared_error: 0.0106\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            " 11/400 [..............................] - ETA: 2s - loss: 0.0484 - mean_squared_error: 0.0038\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            " 21/400 [>.............................] - ETA: 2s - loss: 0.0483 - mean_squared_error: 0.0035\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            " 32/400 [=>............................] - ETA: 1s - loss: 0.0443 - mean_squared_error: 0.0032\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            " 44/400 [==>...........................] - ETA: 1s - loss: 0.0445 - mean_squared_error: 0.0030\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            " 54/400 [===>..........................] - ETA: 1s - loss: 0.0413 - mean_squared_error: 0.0027\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            " 65/400 [===>..........................] - ETA: 1s - loss: 0.0401 - mean_squared_error: 0.0027\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            " 76/400 [====>.........................] - ETA: 1s - loss: 0.0392 - mean_squared_error: 0.0026\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            " 87/400 [=====>........................] - ETA: 1s - loss: 0.0424 - mean_squared_error: 0.0032\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            " 98/400 [======>.......................] - ETA: 1s - loss: 0.0413 - mean_squared_error: 0.0030\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "109/400 [=======>......................] - ETA: 1s - loss: 0.0419 - mean_squared_error: 0.0031\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "120/400 [========>.....................] - ETA: 1s - loss: 0.0418 - mean_squared_error: 0.0030\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "132/400 [========>.....................] - ETA: 1s - loss: 0.0409 - mean_squared_error: 0.0029\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "143/400 [=========>....................] - ETA: 1s - loss: 0.0406 - mean_squared_error: 0.0028\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "155/400 [==========>...................] - ETA: 1s - loss: 0.0405 - mean_squared_error: 0.0028\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "166/400 [===========>..................] - ETA: 1s - loss: 0.0401 - mean_squared_error: 0.0028\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "176/400 [============>.................] - ETA: 1s - loss: 0.0399 - mean_squared_error: 0.0027\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "187/400 [=============>................] - ETA: 1s - loss: 0.0395 - mean_squared_error: 0.0027\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "198/400 [=============>................] - ETA: 0s - loss: 0.0394 - mean_squared_error: 0.0027\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "209/400 [==============>...............] - ETA: 0s - loss: 0.0391 - mean_squared_error: 0.0026\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "219/400 [===============>..............] - ETA: 0s - loss: 0.0390 - mean_squared_error: 0.0026\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "230/400 [================>.............] - ETA: 0s - loss: 0.0394 - mean_squared_error: 0.0027\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "241/400 [=================>............] - ETA: 0s - loss: 0.0394 - mean_squared_error: 0.0026\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "252/400 [=================>............] - ETA: 0s - loss: 0.0399 - mean_squared_error: 0.0028\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "263/400 [==================>...........] - ETA: 0s - loss: 0.0393 - mean_squared_error: 0.0027\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "274/400 [===================>..........] - ETA: 0s - loss: 0.0410 - mean_squared_error: 0.0030\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "285/400 [====================>.........] - ETA: 0s - loss: 0.0407 - mean_squared_error: 0.0029\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "296/400 [=====================>........] - ETA: 0s - loss: 0.0403 - mean_squared_error: 0.0029\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "307/400 [======================>.......] - ETA: 0s - loss: 0.0403 - mean_squared_error: 0.0028\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "318/400 [======================>.......] - ETA: 0s - loss: 0.0404 - mean_squared_error: 0.0028\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "329/400 [=======================>......] - ETA: 0s - loss: 0.0406 - mean_squared_error: 0.0029\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "341/400 [========================>.....] - ETA: 0s - loss: 0.0399 - mean_squared_error: 0.0028\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "352/400 [=========================>....] - ETA: 0s - loss: 0.0400 - mean_squared_error: 0.0028\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "363/400 [==========================>...] - ETA: 0s - loss: 0.0397 - mean_squared_error: 0.0028\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "373/400 [==========================>...] - ETA: 0s - loss: 0.0395 - mean_squared_error: 0.0028\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "383/400 [===========================>..] - ETA: 0s - loss: 0.0393 - mean_squared_error: 0.0027\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "393/400 [============================>.] - ETA: 0s - loss: 0.0393 - mean_squared_error: 0.0027\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00067\n",
            "400/400 [==============================] - 2s 5ms/step - loss: 0.0396 - mean_squared_error: 0.0028 - val_loss: 0.0418 - val_mean_squared_error: 0.0026 - lr: 5.0000e-04\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "  1/400 [..............................] - ETA: 2s - loss: 0.0073 - mean_squared_error: 5.3807e-05\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            " 11/400 [..............................] - ETA: 2s - loss: 0.0454 - mean_squared_error: 0.0030    \n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            " 23/400 [>.............................] - ETA: 1s - loss: 0.0517 - mean_squared_error: 0.0039\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            " 33/400 [=>............................] - ETA: 1s - loss: 0.0450 - mean_squared_error: 0.0031\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            " 44/400 [==>...........................] - ETA: 1s - loss: 0.0462 - mean_squared_error: 0.0033\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            " 55/400 [===>..........................] - ETA: 1s - loss: 0.0422 - mean_squared_error: 0.0029\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            " 65/400 [===>..........................] - ETA: 1s - loss: 0.0408 - mean_squared_error: 0.0029\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            " 76/400 [====>.........................] - ETA: 1s - loss: 0.0419 - mean_squared_error: 0.0030\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            " 87/400 [=====>........................] - ETA: 1s - loss: 0.0401 - mean_squared_error: 0.0028\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            " 98/400 [======>.......................] - ETA: 1s - loss: 0.0403 - mean_squared_error: 0.0028\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "108/400 [=======>......................] - ETA: 1s - loss: 0.0400 - mean_squared_error: 0.0027\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "119/400 [=======>......................] - ETA: 1s - loss: 0.0396 - mean_squared_error: 0.0027\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "130/400 [========>.....................] - ETA: 1s - loss: 0.0400 - mean_squared_error: 0.0027\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "141/400 [=========>....................] - ETA: 1s - loss: 0.0403 - mean_squared_error: 0.0027\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "152/400 [==========>...................] - ETA: 1s - loss: 0.0411 - mean_squared_error: 0.0029\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "162/400 [===========>..................] - ETA: 1s - loss: 0.0406 - mean_squared_error: 0.0028\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "173/400 [===========>..................] - ETA: 1s - loss: 0.0397 - mean_squared_error: 0.0028\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "183/400 [============>.................] - ETA: 1s - loss: 0.0394 - mean_squared_error: 0.0027\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "194/400 [=============>................] - ETA: 0s - loss: 0.0395 - mean_squared_error: 0.0027\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "204/400 [==============>...............] - ETA: 0s - loss: 0.0393 - mean_squared_error: 0.0027\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "215/400 [===============>..............] - ETA: 0s - loss: 0.0391 - mean_squared_error: 0.0027\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "226/400 [===============>..............] - ETA: 0s - loss: 0.0388 - mean_squared_error: 0.0026\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "237/400 [================>.............] - ETA: 0s - loss: 0.0387 - mean_squared_error: 0.0026\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "248/400 [=================>............] - ETA: 0s - loss: 0.0393 - mean_squared_error: 0.0027\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "259/400 [==================>...........] - ETA: 0s - loss: 0.0388 - mean_squared_error: 0.0026\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "269/400 [===================>..........] - ETA: 0s - loss: 0.0388 - mean_squared_error: 0.0026\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "279/400 [===================>..........] - ETA: 0s - loss: 0.0387 - mean_squared_error: 0.0026\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "288/400 [====================>.........] - ETA: 0s - loss: 0.0390 - mean_squared_error: 0.0026\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "298/400 [=====================>........] - ETA: 0s - loss: 0.0389 - mean_squared_error: 0.0026\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "309/400 [======================>.......] - ETA: 0s - loss: 0.0390 - mean_squared_error: 0.0026\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "319/400 [======================>.......] - ETA: 0s - loss: 0.0392 - mean_squared_error: 0.0026\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "329/400 [=======================>......] - ETA: 0s - loss: 0.0388 - mean_squared_error: 0.0026\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "340/400 [========================>.....] - ETA: 0s - loss: 0.0389 - mean_squared_error: 0.0026\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "350/400 [=========================>....] - ETA: 0s - loss: 0.0394 - mean_squared_error: 0.0026\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "361/400 [==========================>...] - ETA: 0s - loss: 0.0390 - mean_squared_error: 0.0026\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "370/400 [==========================>...] - ETA: 0s - loss: 0.0389 - mean_squared_error: 0.0026\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "381/400 [===========================>..] - ETA: 0s - loss: 0.0388 - mean_squared_error: 0.0025\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "391/400 [============================>.] - ETA: 0s - loss: 0.0387 - mean_squared_error: 0.0025\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "400/400 [==============================] - 2s 6ms/step - loss: 0.0383 - mean_squared_error: 0.0025 - val_loss: 0.0423 - val_mean_squared_error: 0.0027 - lr: 5.0000e-04\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "  1/400 [..............................] - ETA: 3s - loss: 0.0346 - mean_squared_error: 0.0012\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            " 11/400 [..............................] - ETA: 2s - loss: 0.0609 - mean_squared_error: 0.0046\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            " 22/400 [>.............................] - ETA: 1s - loss: 0.0435 - mean_squared_error: 0.0028\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            " 33/400 [=>............................] - ETA: 1s - loss: 0.0415 - mean_squared_error: 0.0026\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            " 44/400 [==>...........................] - ETA: 1s - loss: 0.0408 - mean_squared_error: 0.0024\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            " 54/400 [===>..........................] - ETA: 1s - loss: 0.0373 - mean_squared_error: 0.0021\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            " 64/400 [===>..........................] - ETA: 1s - loss: 0.0380 - mean_squared_error: 0.0022\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            " 74/400 [====>.........................] - ETA: 1s - loss: 0.0361 - mean_squared_error: 0.0020\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            " 85/400 [=====>........................] - ETA: 1s - loss: 0.0348 - mean_squared_error: 0.0019\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            " 96/400 [======>.......................] - ETA: 1s - loss: 0.0337 - mean_squared_error: 0.0018\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "106/400 [======>.......................] - ETA: 1s - loss: 0.0336 - mean_squared_error: 0.0018\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "117/400 [=======>......................] - ETA: 1s - loss: 0.0332 - mean_squared_error: 0.0018\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "127/400 [========>.....................] - ETA: 1s - loss: 0.0344 - mean_squared_error: 0.0021\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "138/400 [=========>....................] - ETA: 1s - loss: 0.0335 - mean_squared_error: 0.0020\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "149/400 [==========>...................] - ETA: 1s - loss: 0.0332 - mean_squared_error: 0.0020\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "159/400 [==========>...................] - ETA: 1s - loss: 0.0353 - mean_squared_error: 0.0023\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "169/400 [===========>..................] - ETA: 1s - loss: 0.0352 - mean_squared_error: 0.0022\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "179/400 [============>.................] - ETA: 1s - loss: 0.0348 - mean_squared_error: 0.0022\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "190/400 [=============>................] - ETA: 1s - loss: 0.0348 - mean_squared_error: 0.0022\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "200/400 [==============>...............] - ETA: 1s - loss: 0.0340 - mean_squared_error: 0.0022\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "211/400 [==============>...............] - ETA: 0s - loss: 0.0343 - mean_squared_error: 0.0022\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "222/400 [===============>..............] - ETA: 0s - loss: 0.0349 - mean_squared_error: 0.0023\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "232/400 [================>.............] - ETA: 0s - loss: 0.0346 - mean_squared_error: 0.0022\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "243/400 [=================>............] - ETA: 0s - loss: 0.0341 - mean_squared_error: 0.0021\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "253/400 [=================>............] - ETA: 0s - loss: 0.0338 - mean_squared_error: 0.0021\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "262/400 [==================>...........] - ETA: 0s - loss: 0.0335 - mean_squared_error: 0.0021\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "271/400 [===================>..........] - ETA: 0s - loss: 0.0338 - mean_squared_error: 0.0021\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "281/400 [====================>.........] - ETA: 0s - loss: 0.0335 - mean_squared_error: 0.0020\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "292/400 [====================>.........] - ETA: 0s - loss: 0.0334 - mean_squared_error: 0.0020\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "303/400 [=====================>........] - ETA: 0s - loss: 0.0330 - mean_squared_error: 0.0020\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "314/400 [======================>.......] - ETA: 0s - loss: 0.0332 - mean_squared_error: 0.0020\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "325/400 [=======================>......] - ETA: 0s - loss: 0.0330 - mean_squared_error: 0.0020\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "336/400 [========================>.....] - ETA: 0s - loss: 0.0333 - mean_squared_error: 0.0020\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "347/400 [=========================>....] - ETA: 0s - loss: 0.0334 - mean_squared_error: 0.0020\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "358/400 [=========================>....] - ETA: 0s - loss: 0.0335 - mean_squared_error: 0.0020\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "369/400 [==========================>...] - ETA: 0s - loss: 0.0342 - mean_squared_error: 0.0021\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "380/400 [===========================>..] - ETA: 0s - loss: 0.0344 - mean_squared_error: 0.0021\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "391/400 [============================>.] - ETA: 0s - loss: 0.0347 - mean_squared_error: 0.0021\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00067\n",
            "400/400 [==============================] - 2s 6ms/step - loss: 0.0350 - mean_squared_error: 0.0021 - val_loss: 0.0462 - val_mean_squared_error: 0.0031 - lr: 2.5000e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6164047550>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "model_mlp = Sequential()\n",
        "model_mlp.add(Dense(50, input_shape=(24,), activation='relu'))\n",
        "model_mlp.add(Dense(50, activation='relu'))\n",
        "model_mlp.add(Dense(50, activation='relu'))\n",
        "model_mlp.add(Dense(1, activation='linear'))\n",
        "callbacks = [\n",
        "    ReduceLROnPlateau(patience=10, factor=0.5, verbose=True),\n",
        "    ModelCheckpoint(\"best_model_mlp.hdf5\", monitor='loss', verbose=1,\n",
        "    save_best_only=True, mode='auto', save_freq=1)]\n",
        "# Configurando e treiando o modelo\n",
        "model_mlp.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_squared_error'])\n",
        "model_mlp.fit(X_train, y_train, epochs=50, batch_size=1, verbose=True, validation_split=0.25,callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0EHT-h4XwaT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbe30432-d92c-48e3-cc69-2c381ab0dbef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "model_mlp.load_weights('best_model_mlp.hdf5')\n",
        "pred_mlp = model_mlp.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMsGbTJHXybD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7914c434-b295-45b5-e5bc-3e68d230f316"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP model Results\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MLP': {'mse': 0.003234977257735753,\n",
              "  'mae': 0.04369475587181178,\n",
              "  'mape': 0.0766240223561974}}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "results = {}\n",
        "\n",
        "print('MLP model Results')\n",
        "results['MLP'] = {'mse': mean_squared_error(pred_mlp, y_test),\n",
        "                  'mae': mean_absolute_error(pred_mlp, y_test),\n",
        "                  'mape':mean_absolute_percentage_error(pred_mlp, y_test)}\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaVLc85XXyWl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "361e20c1-cf2b-474d-c783-600a312ce261"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f6170a3e9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(pred_mlp, label='pred')\n",
        "ax.plot(y_test.reset_index(drop=True), label='true')\n",
        "plt.title('MLP MODEL')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM regressor"
      ],
      "metadata": {
        "id": "6xYv6wO9MpVb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EHMhseSWRP5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0b3b7b6-e311-48b7-e619-fdf33c97a6ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (534, 24, 1)\n",
            "X_test:   (162, 24, 1)\n"
          ]
        }
      ],
      "source": [
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "print('X_train: ', X_train.shape)\n",
        "print('X_test:  ', X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKZSQWoGQO9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a73fb7b0-d622-4c5b-ca70-53bce830bfca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ],
      "source": [
        "model_lstm = Sequential()\n",
        "model_lstm.add(LSTM(120, activation='relu', return_sequences=True, input_shape=(24,1)))\n",
        "model_lstm.add(tf.keras.layers.Dropout(0.3))\n",
        "model_lstm.add(LSTM(50, activation='relu'))\n",
        "model_lstm.add(tf.keras.layers.Dropout(0.3))\n",
        "model_lstm.add(Dense(1))\n",
        "model_lstm.compile(optimizer='adam', loss='mse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhjfLXfYE3tM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83118f55-f90e-4d61-b8f0-baba69f2573f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 24, 120)           58560     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 24, 120)           0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 50)                34200     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 92,811\n",
            "Trainable params: 92,811\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_lstm.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCqh2JBlhSHn"
      },
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "    ReduceLROnPlateau(patience=10, factor=0.5, verbose=True),\n",
        "    ModelCheckpoint(\"best_model_lstm.hdf5\", monitor='loss', verbose=1,\n",
        "    save_best_only=True, mode='auto', save_freq=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxVgfZcghc4s",
        "outputId": "54b14087-2389-400e-b54b-6a7427fcb1b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\n",
            "Epoch 1: loss improved from inf to 0.25417, saving model to best_model_lstm.hdf5\n",
            " 1/17 [>.............................] - ETA: 48s - loss: 0.2542\n",
            "Epoch 1: loss improved from 0.25417 to 0.21073, saving model to best_model_lstm.hdf5\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.2107 \n",
            "Epoch 1: loss improved from 0.21073 to 0.20697, saving model to best_model_lstm.hdf5\n",
            " 3/17 [====>.........................] - ETA: 1s - loss: 0.2070\n",
            "Epoch 1: loss did not improve from 0.20697\n",
            " 4/17 [======>.......................] - ETA: 1s - loss: 0.2074\n",
            "Epoch 1: loss improved from 0.20697 to 0.19489, saving model to best_model_lstm.hdf5\n",
            " 5/17 [=======>......................] - ETA: 1s - loss: 0.1949\n",
            "Epoch 1: loss improved from 0.19489 to 0.17785, saving model to best_model_lstm.hdf5\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.1778\n",
            "Epoch 1: loss improved from 0.17785 to 0.16436, saving model to best_model_lstm.hdf5\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.1644\n",
            "Epoch 1: loss improved from 0.16436 to 0.14970, saving model to best_model_lstm.hdf5\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.1497\n",
            "Epoch 1: loss improved from 0.14970 to 0.13562, saving model to best_model_lstm.hdf5\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.1356\n",
            "Epoch 1: loss improved from 0.13562 to 0.12496, saving model to best_model_lstm.hdf5\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.1250\n",
            "Epoch 1: loss improved from 0.12496 to 0.11675, saving model to best_model_lstm.hdf5\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.1168\n",
            "Epoch 1: loss improved from 0.11675 to 0.11016, saving model to best_model_lstm.hdf5\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.1102\n",
            "Epoch 1: loss improved from 0.11016 to 0.10521, saving model to best_model_lstm.hdf5\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.1052\n",
            "Epoch 1: loss improved from 0.10521 to 0.10055, saving model to best_model_lstm.hdf5\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.1006\n",
            "Epoch 1: loss improved from 0.10055 to 0.09523, saving model to best_model_lstm.hdf5\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0952\n",
            "Epoch 1: loss improved from 0.09523 to 0.09153, saving model to best_model_lstm.hdf5\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0915\n",
            "Epoch 1: loss improved from 0.09153 to 0.08959, saving model to best_model_lstm.hdf5\n",
            "17/17 [==============================] - 5s 112ms/step - loss: 0.0896 - val_loss: 0.0280 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 2: loss improved from 0.08959 to 0.03365, saving model to best_model_lstm.hdf5\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0336\n",
            "Epoch 2: loss improved from 0.03365 to 0.03279, saving model to best_model_lstm.hdf5\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0328\n",
            "Epoch 2: loss improved from 0.03279 to 0.02847, saving model to best_model_lstm.hdf5\n",
            " 3/17 [====>.........................] - ETA: 1s - loss: 0.0285\n",
            "Epoch 2: loss improved from 0.02847 to 0.02726, saving model to best_model_lstm.hdf5\n",
            " 4/17 [======>.......................] - ETA: 1s - loss: 0.0273\n",
            "Epoch 2: loss did not improve from 0.02726\n",
            " 5/17 [=======>......................] - ETA: 1s - loss: 0.0280\n",
            "Epoch 2: loss did not improve from 0.02726\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0279\n",
            "Epoch 2: loss improved from 0.02726 to 0.02692, saving model to best_model_lstm.hdf5\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0269\n",
            "Epoch 2: loss did not improve from 0.02692\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0270\n",
            "Epoch 2: loss improved from 0.02692 to 0.02634, saving model to best_model_lstm.hdf5\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0263\n",
            "Epoch 2: loss did not improve from 0.02634\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0270\n",
            "Epoch 2: loss improved from 0.02634 to 0.02616, saving model to best_model_lstm.hdf5\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0262\n",
            "Epoch 2: loss improved from 0.02616 to 0.02534, saving model to best_model_lstm.hdf5\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0253\n",
            "Epoch 2: loss did not improve from 0.02534\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0257\n",
            "Epoch 2: loss did not improve from 0.02534\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0257\n",
            "Epoch 2: loss did not improve from 0.02534\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0257\n",
            "Epoch 2: loss did not improve from 0.02534\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0257\n",
            "Epoch 2: loss did not improve from 0.02534\n",
            "17/17 [==============================] - 1s 83ms/step - loss: 0.0259 - val_loss: 0.0219 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 3: loss improved from 0.02534 to 0.01824, saving model to best_model_lstm.hdf5\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0182\n",
            "Epoch 3: loss did not improve from 0.01824\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0205\n",
            "Epoch 3: loss did not improve from 0.01824\n",
            " 3/17 [====>.........................] - ETA: 0s - loss: 0.0232\n",
            "Epoch 3: loss did not improve from 0.01824\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0248\n",
            "Epoch 3: loss did not improve from 0.01824\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0238\n",
            "Epoch 3: loss did not improve from 0.01824\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0247\n",
            "Epoch 3: loss did not improve from 0.01824\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0245\n",
            "Epoch 3: loss did not improve from 0.01824\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0267\n",
            "Epoch 3: loss did not improve from 0.01824\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0279\n",
            "Epoch 3: loss did not improve from 0.01824\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0270\n",
            "Epoch 3: loss did not improve from 0.01824\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0266\n",
            "Epoch 3: loss did not improve from 0.01824\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0262\n",
            "Epoch 3: loss did not improve from 0.01824\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0264\n",
            "Epoch 3: loss did not improve from 0.01824\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0259\n",
            "Epoch 3: loss did not improve from 0.01824\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0256\n",
            "Epoch 3: loss did not improve from 0.01824\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0255\n",
            "Epoch 3: loss did not improve from 0.01824\n",
            "17/17 [==============================] - 1s 81ms/step - loss: 0.0255 - val_loss: 0.0233 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 4: loss did not improve from 0.01824\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0203\n",
            "Epoch 4: loss did not improve from 0.01824\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0275\n",
            "Epoch 4: loss did not improve from 0.01824\n",
            " 3/17 [====>.........................] - ETA: 1s - loss: 0.0263\n",
            "Epoch 4: loss did not improve from 0.01824\n",
            " 4/17 [======>.......................] - ETA: 1s - loss: 0.0280\n",
            "Epoch 4: loss did not improve from 0.01824\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0271\n",
            "Epoch 4: loss did not improve from 0.01824\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0278\n",
            "Epoch 4: loss did not improve from 0.01824\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0291\n",
            "Epoch 4: loss did not improve from 0.01824\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0281\n",
            "Epoch 4: loss did not improve from 0.01824\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0274\n",
            "Epoch 4: loss did not improve from 0.01824\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0282\n",
            "Epoch 4: loss did not improve from 0.01824\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0271\n",
            "Epoch 4: loss did not improve from 0.01824\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0273\n",
            "Epoch 4: loss did not improve from 0.01824\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0266\n",
            "Epoch 4: loss did not improve from 0.01824\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0267\n",
            "Epoch 4: loss did not improve from 0.01824\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0263\n",
            "Epoch 4: loss did not improve from 0.01824\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0257\n",
            "Epoch 4: loss did not improve from 0.01824\n",
            "17/17 [==============================] - 1s 82ms/step - loss: 0.0256 - val_loss: 0.0181 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 5: loss did not improve from 0.01824\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0304\n",
            "Epoch 5: loss did not improve from 0.01824\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0305\n",
            "Epoch 5: loss did not improve from 0.01824\n",
            " 3/17 [====>.........................] - ETA: 0s - loss: 0.0278\n",
            "Epoch 5: loss did not improve from 0.01824\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0268\n",
            "Epoch 5: loss did not improve from 0.01824\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0250\n",
            "Epoch 5: loss did not improve from 0.01824\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0238\n",
            "Epoch 5: loss did not improve from 0.01824\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0235\n",
            "Epoch 5: loss did not improve from 0.01824\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0237\n",
            "Epoch 5: loss did not improve from 0.01824\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0238\n",
            "Epoch 5: loss did not improve from 0.01824\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0236\n",
            "Epoch 5: loss did not improve from 0.01824\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0248\n",
            "Epoch 5: loss did not improve from 0.01824\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0250\n",
            "Epoch 5: loss did not improve from 0.01824\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0254\n",
            "Epoch 5: loss did not improve from 0.01824\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0252\n",
            "Epoch 5: loss did not improve from 0.01824\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0252\n",
            "Epoch 5: loss did not improve from 0.01824\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0251\n",
            "Epoch 5: loss did not improve from 0.01824\n",
            "17/17 [==============================] - 1s 76ms/step - loss: 0.0252 - val_loss: 0.0197 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 6: loss did not improve from 0.01824\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0307\n",
            "Epoch 6: loss did not improve from 0.01824\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0242\n",
            "Epoch 6: loss did not improve from 0.01824\n",
            " 3/17 [====>.........................] - ETA: 0s - loss: 0.0240\n",
            "Epoch 6: loss did not improve from 0.01824\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0216\n",
            "Epoch 6: loss did not improve from 0.01824\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0214\n",
            "Epoch 6: loss did not improve from 0.01824\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0209\n",
            "Epoch 6: loss did not improve from 0.01824\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0200\n",
            "Epoch 6: loss did not improve from 0.01824\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0213\n",
            "Epoch 6: loss did not improve from 0.01824\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0206\n",
            "Epoch 6: loss did not improve from 0.01824\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0205\n",
            "Epoch 6: loss did not improve from 0.01824\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0208\n",
            "Epoch 6: loss did not improve from 0.01824\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0226\n",
            "Epoch 6: loss did not improve from 0.01824\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0232\n",
            "Epoch 6: loss did not improve from 0.01824\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0241\n",
            "Epoch 6: loss did not improve from 0.01824\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0243\n",
            "Epoch 6: loss did not improve from 0.01824\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0239\n",
            "Epoch 6: loss did not improve from 0.01824\n",
            "17/17 [==============================] - 1s 74ms/step - loss: 0.0242 - val_loss: 0.0394 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 7: loss did not improve from 0.01824\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0302\n",
            "Epoch 7: loss did not improve from 0.01824\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0319\n",
            "Epoch 7: loss did not improve from 0.01824\n",
            " 3/17 [====>.........................] - ETA: 0s - loss: 0.0276\n",
            "Epoch 7: loss did not improve from 0.01824\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0248\n",
            "Epoch 7: loss did not improve from 0.01824\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0243\n",
            "Epoch 7: loss did not improve from 0.01824\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0237\n",
            "Epoch 7: loss did not improve from 0.01824\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0234\n",
            "Epoch 7: loss did not improve from 0.01824\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0240\n",
            "Epoch 7: loss did not improve from 0.01824\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0246\n",
            "Epoch 7: loss did not improve from 0.01824\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0241\n",
            "Epoch 7: loss did not improve from 0.01824\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0245\n",
            "Epoch 7: loss did not improve from 0.01824\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0252\n",
            "Epoch 7: loss did not improve from 0.01824\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0248\n",
            "Epoch 7: loss did not improve from 0.01824\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0247\n",
            "Epoch 7: loss did not improve from 0.01824\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0244\n",
            "Epoch 7: loss did not improve from 0.01824\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0241\n",
            "Epoch 7: loss did not improve from 0.01824\n",
            "17/17 [==============================] - 1s 73ms/step - loss: 0.0239 - val_loss: 0.0206 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 8: loss did not improve from 0.01824\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0241\n",
            "Epoch 8: loss did not improve from 0.01824\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0221\n",
            "Epoch 8: loss did not improve from 0.01824\n",
            " 3/17 [====>.........................] - ETA: 0s - loss: 0.0209\n",
            "Epoch 8: loss did not improve from 0.01824\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0204\n",
            "Epoch 8: loss did not improve from 0.01824\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0221\n",
            "Epoch 8: loss did not improve from 0.01824\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0215\n",
            "Epoch 8: loss did not improve from 0.01824\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0206\n",
            "Epoch 8: loss did not improve from 0.01824\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0216\n",
            "Epoch 8: loss did not improve from 0.01824\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0227\n",
            "Epoch 8: loss did not improve from 0.01824\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0219\n",
            "Epoch 8: loss did not improve from 0.01824\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0216\n",
            "Epoch 8: loss did not improve from 0.01824\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0216\n",
            "Epoch 8: loss did not improve from 0.01824\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0211\n",
            "Epoch 8: loss did not improve from 0.01824\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0218\n",
            "Epoch 8: loss did not improve from 0.01824\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0219\n",
            "Epoch 8: loss did not improve from 0.01824\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0220\n",
            "Epoch 8: loss did not improve from 0.01824\n",
            "17/17 [==============================] - 1s 73ms/step - loss: 0.0224 - val_loss: 0.0178 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 9: loss did not improve from 0.01824\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0224\n",
            "Epoch 9: loss did not improve from 0.01824\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0233\n",
            "Epoch 9: loss did not improve from 0.01824\n",
            " 3/17 [====>.........................] - ETA: 0s - loss: 0.0223\n",
            "Epoch 9: loss did not improve from 0.01824\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0214\n",
            "Epoch 9: loss did not improve from 0.01824\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0195\n",
            "Epoch 9: loss did not improve from 0.01824\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0192\n",
            "Epoch 9: loss did not improve from 0.01824\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0203\n",
            "Epoch 9: loss did not improve from 0.01824\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0210\n",
            "Epoch 9: loss did not improve from 0.01824\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0205\n",
            "Epoch 9: loss did not improve from 0.01824\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0211\n",
            "Epoch 9: loss did not improve from 0.01824\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0216\n",
            "Epoch 9: loss did not improve from 0.01824\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0222\n",
            "Epoch 9: loss did not improve from 0.01824\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0214\n",
            "Epoch 9: loss did not improve from 0.01824\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0219\n",
            "Epoch 9: loss did not improve from 0.01824\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0218\n",
            "Epoch 9: loss did not improve from 0.01824\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0209\n",
            "Epoch 9: loss did not improve from 0.01824\n",
            "17/17 [==============================] - 1s 74ms/step - loss: 0.0208 - val_loss: 0.0175 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 10: loss improved from 0.01824 to 0.01817, saving model to best_model_lstm.hdf5\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0182\n",
            "Epoch 10: loss did not improve from 0.01817\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0217\n",
            "Epoch 10: loss did not improve from 0.01817\n",
            " 3/17 [====>.........................] - ETA: 1s - loss: 0.0232\n",
            "Epoch 10: loss did not improve from 0.01817\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0222\n",
            "Epoch 10: loss did not improve from 0.01817\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0224\n",
            "Epoch 10: loss did not improve from 0.01817\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0210\n",
            "Epoch 10: loss did not improve from 0.01817\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0215\n",
            "Epoch 10: loss did not improve from 0.01817\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0219\n",
            "Epoch 10: loss did not improve from 0.01817\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0219\n",
            "Epoch 10: loss did not improve from 0.01817\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0215\n",
            "Epoch 10: loss did not improve from 0.01817\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0212\n",
            "Epoch 10: loss did not improve from 0.01817\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0214\n",
            "Epoch 10: loss did not improve from 0.01817\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0213\n",
            "Epoch 10: loss did not improve from 0.01817\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0211\n",
            "Epoch 10: loss did not improve from 0.01817\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0208\n",
            "Epoch 10: loss did not improve from 0.01817\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0214\n",
            "Epoch 10: loss did not improve from 0.01817\n",
            "17/17 [==============================] - 1s 75ms/step - loss: 0.0214 - val_loss: 0.0278 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 11: loss did not improve from 0.01817\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0296\n",
            "Epoch 11: loss did not improve from 0.01817\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0254\n",
            "Epoch 11: loss did not improve from 0.01817\n",
            " 3/17 [====>.........................] - ETA: 0s - loss: 0.0251\n",
            "Epoch 11: loss did not improve from 0.01817\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0233\n",
            "Epoch 11: loss did not improve from 0.01817\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0266\n",
            "Epoch 11: loss did not improve from 0.01817\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0263\n",
            "Epoch 11: loss did not improve from 0.01817\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0239\n",
            "Epoch 11: loss did not improve from 0.01817\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0231\n",
            "Epoch 11: loss did not improve from 0.01817\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0231\n",
            "Epoch 11: loss did not improve from 0.01817\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0230\n",
            "Epoch 11: loss did not improve from 0.01817\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0224\n",
            "Epoch 11: loss did not improve from 0.01817\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0226\n",
            "Epoch 11: loss did not improve from 0.01817\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0224\n",
            "Epoch 11: loss did not improve from 0.01817\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0221\n",
            "Epoch 11: loss did not improve from 0.01817\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0221\n",
            "Epoch 11: loss did not improve from 0.01817\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0219\n",
            "Epoch 11: loss did not improve from 0.01817\n",
            "17/17 [==============================] - 1s 73ms/step - loss: 0.0218 - val_loss: 0.0184 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 12: loss improved from 0.01817 to 0.01491, saving model to best_model_lstm.hdf5\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0149\n",
            "Epoch 12: loss did not improve from 0.01491\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0199\n",
            "Epoch 12: loss did not improve from 0.01491\n",
            " 3/17 [====>.........................] - ETA: 0s - loss: 0.0205\n",
            "Epoch 12: loss did not improve from 0.01491\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0201\n",
            "Epoch 12: loss did not improve from 0.01491\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0181\n",
            "Epoch 12: loss did not improve from 0.01491\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0186\n",
            "Epoch 12: loss did not improve from 0.01491\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0201\n",
            "Epoch 12: loss did not improve from 0.01491\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0199\n",
            "Epoch 12: loss did not improve from 0.01491\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0198\n",
            "Epoch 12: loss did not improve from 0.01491\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0197\n",
            "Epoch 12: loss did not improve from 0.01491\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0202\n",
            "Epoch 12: loss did not improve from 0.01491\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0200\n",
            "Epoch 12: loss did not improve from 0.01491\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0197\n",
            "Epoch 12: loss did not improve from 0.01491\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0193\n",
            "Epoch 12: loss did not improve from 0.01491\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0192\n",
            "Epoch 12: loss did not improve from 0.01491\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0196\n",
            "Epoch 12: loss did not improve from 0.01491\n",
            "17/17 [==============================] - 1s 78ms/step - loss: 0.0197 - val_loss: 0.0162 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 13: loss did not improve from 0.01491\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0222\n",
            "Epoch 13: loss did not improve from 0.01491\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0199\n",
            "Epoch 13: loss did not improve from 0.01491\n",
            " 3/17 [====>.........................] - ETA: 1s - loss: 0.0174\n",
            "Epoch 13: loss did not improve from 0.01491\n",
            " 4/17 [======>.......................] - ETA: 1s - loss: 0.0213\n",
            "Epoch 13: loss did not improve from 0.01491\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0211\n",
            "Epoch 13: loss did not improve from 0.01491\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0201\n",
            "Epoch 13: loss did not improve from 0.01491\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0209\n",
            "Epoch 13: loss did not improve from 0.01491\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0212\n",
            "Epoch 13: loss did not improve from 0.01491\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0224\n",
            "Epoch 13: loss did not improve from 0.01491\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0219\n",
            "Epoch 13: loss did not improve from 0.01491\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0217\n",
            "Epoch 13: loss did not improve from 0.01491\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0218\n",
            "Epoch 13: loss did not improve from 0.01491\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0222\n",
            "Epoch 13: loss did not improve from 0.01491\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0221\n",
            "Epoch 13: loss did not improve from 0.01491\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0220\n",
            "Epoch 13: loss did not improve from 0.01491\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0217\n",
            "Epoch 13: loss did not improve from 0.01491\n",
            "17/17 [==============================] - 1s 85ms/step - loss: 0.0219 - val_loss: 0.0149 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 14: loss did not improve from 0.01491\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0205\n",
            "Epoch 14: loss did not improve from 0.01491\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0164\n",
            "Epoch 14: loss did not improve from 0.01491\n",
            " 3/17 [====>.........................] - ETA: 1s - loss: 0.0163\n",
            "Epoch 14: loss did not improve from 0.01491\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0151\n",
            "Epoch 14: loss did not improve from 0.01491\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0190\n",
            "Epoch 14: loss did not improve from 0.01491\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0194\n",
            "Epoch 14: loss did not improve from 0.01491\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0193\n",
            "Epoch 14: loss did not improve from 0.01491\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0195\n",
            "Epoch 14: loss did not improve from 0.01491\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0188\n",
            "Epoch 14: loss did not improve from 0.01491\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0186\n",
            "Epoch 14: loss did not improve from 0.01491\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0181\n",
            "Epoch 14: loss did not improve from 0.01491\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0183\n",
            "Epoch 14: loss did not improve from 0.01491\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0189\n",
            "Epoch 14: loss did not improve from 0.01491\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0186\n",
            "Epoch 14: loss did not improve from 0.01491\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0189\n",
            "Epoch 14: loss did not improve from 0.01491\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0191\n",
            "Epoch 14: loss did not improve from 0.01491\n",
            "17/17 [==============================] - 1s 74ms/step - loss: 0.0193 - val_loss: 0.0192 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 15: loss did not improve from 0.01491\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0242\n",
            "Epoch 15: loss did not improve from 0.01491\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0225\n",
            "Epoch 15: loss did not improve from 0.01491\n",
            " 3/17 [====>.........................] - ETA: 0s - loss: 0.0225\n",
            "Epoch 15: loss did not improve from 0.01491\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0227\n",
            "Epoch 15: loss did not improve from 0.01491\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0214\n",
            "Epoch 15: loss did not improve from 0.01491\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0207\n",
            "Epoch 15: loss did not improve from 0.01491\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0207\n",
            "Epoch 15: loss did not improve from 0.01491\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0204\n",
            "Epoch 15: loss did not improve from 0.01491\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0202\n",
            "Epoch 15: loss did not improve from 0.01491\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0209\n",
            "Epoch 15: loss did not improve from 0.01491\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0206\n",
            "Epoch 15: loss did not improve from 0.01491\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0207\n",
            "Epoch 15: loss did not improve from 0.01491\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0207\n",
            "Epoch 15: loss did not improve from 0.01491\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0205\n",
            "Epoch 15: loss did not improve from 0.01491\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0209\n",
            "Epoch 15: loss did not improve from 0.01491\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0206\n",
            "Epoch 15: loss did not improve from 0.01491\n",
            "17/17 [==============================] - 1s 75ms/step - loss: 0.0206 - val_loss: 0.0144 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 16: loss did not improve from 0.01491\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0241\n",
            "Epoch 16: loss did not improve from 0.01491\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0230\n",
            "Epoch 16: loss did not improve from 0.01491\n",
            " 3/17 [====>.........................] - ETA: 0s - loss: 0.0229\n",
            "Epoch 16: loss did not improve from 0.01491\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0208\n",
            "Epoch 16: loss did not improve from 0.01491\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0198\n",
            "Epoch 16: loss did not improve from 0.01491\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0198\n",
            "Epoch 16: loss did not improve from 0.01491\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0197\n",
            "Epoch 16: loss did not improve from 0.01491\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0190\n",
            "Epoch 16: loss did not improve from 0.01491\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0192\n",
            "Epoch 16: loss did not improve from 0.01491\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0185\n",
            "Epoch 16: loss did not improve from 0.01491\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0184\n",
            "Epoch 16: loss did not improve from 0.01491\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0191\n",
            "Epoch 16: loss did not improve from 0.01491\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0188\n",
            "Epoch 16: loss did not improve from 0.01491\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0189\n",
            "Epoch 16: loss did not improve from 0.01491\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0192\n",
            "Epoch 16: loss did not improve from 0.01491\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0188\n",
            "Epoch 16: loss did not improve from 0.01491\n",
            "17/17 [==============================] - 1s 75ms/step - loss: 0.0186 - val_loss: 0.0143 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 17: loss did not improve from 0.01491\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0174\n",
            "Epoch 17: loss did not improve from 0.01491\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0169\n",
            "Epoch 17: loss did not improve from 0.01491\n",
            " 3/17 [====>.........................] - ETA: 0s - loss: 0.0167\n",
            "Epoch 17: loss improved from 0.01491 to 0.01439, saving model to best_model_lstm.hdf5\n",
            " 4/17 [======>.......................] - ETA: 1s - loss: 0.0144\n",
            "Epoch 17: loss did not improve from 0.01439\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0173\n",
            "Epoch 17: loss did not improve from 0.01439\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0177\n",
            "Epoch 17: loss did not improve from 0.01439\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0183\n",
            "Epoch 17: loss did not improve from 0.01439\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0186\n",
            "Epoch 17: loss did not improve from 0.01439\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0179\n",
            "Epoch 17: loss did not improve from 0.01439\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0181\n",
            "Epoch 17: loss did not improve from 0.01439\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0177\n",
            "Epoch 17: loss did not improve from 0.01439\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0182\n",
            "Epoch 17: loss did not improve from 0.01439\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0183\n",
            "Epoch 17: loss did not improve from 0.01439\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0184\n",
            "Epoch 17: loss did not improve from 0.01439\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0189\n",
            "Epoch 17: loss did not improve from 0.01439\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0188\n",
            "Epoch 17: loss did not improve from 0.01439\n",
            "17/17 [==============================] - 1s 76ms/step - loss: 0.0186 - val_loss: 0.0200 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 18: loss did not improve from 0.01439\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0155\n",
            "Epoch 18: loss did not improve from 0.01439\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0187\n",
            "Epoch 18: loss did not improve from 0.01439\n",
            " 3/17 [====>.........................] - ETA: 0s - loss: 0.0181\n",
            "Epoch 18: loss did not improve from 0.01439\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0172\n",
            "Epoch 18: loss did not improve from 0.01439\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0171\n",
            "Epoch 18: loss did not improve from 0.01439\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0180\n",
            "Epoch 18: loss did not improve from 0.01439\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0182\n",
            "Epoch 18: loss did not improve from 0.01439\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0182\n",
            "Epoch 18: loss did not improve from 0.01439\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0179\n",
            "Epoch 18: loss did not improve from 0.01439\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0183\n",
            "Epoch 18: loss did not improve from 0.01439\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0191\n",
            "Epoch 18: loss did not improve from 0.01439\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0190\n",
            "Epoch 18: loss did not improve from 0.01439\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0198\n",
            "Epoch 18: loss did not improve from 0.01439\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0197\n",
            "Epoch 18: loss did not improve from 0.01439\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0195\n",
            "Epoch 18: loss did not improve from 0.01439\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0193\n",
            "Epoch 18: loss did not improve from 0.01439\n",
            "17/17 [==============================] - 1s 75ms/step - loss: 0.0189 - val_loss: 0.0183 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 19: loss did not improve from 0.01439\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0205\n",
            "Epoch 19: loss did not improve from 0.01439\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0248\n",
            "Epoch 19: loss did not improve from 0.01439\n",
            " 3/17 [====>.........................] - ETA: 0s - loss: 0.0239\n",
            "Epoch 19: loss did not improve from 0.01439\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0226\n",
            "Epoch 19: loss did not improve from 0.01439\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0221\n",
            "Epoch 19: loss did not improve from 0.01439\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0201\n",
            "Epoch 19: loss did not improve from 0.01439\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0192\n",
            "Epoch 19: loss did not improve from 0.01439\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0200\n",
            "Epoch 19: loss did not improve from 0.01439\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0198\n",
            "Epoch 19: loss did not improve from 0.01439\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0197\n",
            "Epoch 19: loss did not improve from 0.01439\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0195\n",
            "Epoch 19: loss did not improve from 0.01439\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0200\n",
            "Epoch 19: loss did not improve from 0.01439\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0198\n",
            "Epoch 19: loss did not improve from 0.01439\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0195\n",
            "Epoch 19: loss did not improve from 0.01439\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0191\n",
            "Epoch 19: loss did not improve from 0.01439\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0190\n",
            "Epoch 19: loss did not improve from 0.01439\n",
            "17/17 [==============================] - 1s 75ms/step - loss: 0.0188 - val_loss: 0.0179 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 20: loss did not improve from 0.01439\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0185\n",
            "Epoch 20: loss did not improve from 0.01439\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0193\n",
            "Epoch 20: loss did not improve from 0.01439\n",
            " 3/17 [====>.........................] - ETA: 1s - loss: 0.0179\n",
            "Epoch 20: loss did not improve from 0.01439\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0170\n",
            "Epoch 20: loss did not improve from 0.01439\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0173\n",
            "Epoch 20: loss did not improve from 0.01439\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0172\n",
            "Epoch 20: loss did not improve from 0.01439\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0164\n",
            "Epoch 20: loss did not improve from 0.01439\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0161\n",
            "Epoch 20: loss did not improve from 0.01439\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0166\n",
            "Epoch 20: loss did not improve from 0.01439\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0181\n",
            "Epoch 20: loss did not improve from 0.01439\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0177\n",
            "Epoch 20: loss did not improve from 0.01439\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0183\n",
            "Epoch 20: loss did not improve from 0.01439\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0183\n",
            "Epoch 20: loss did not improve from 0.01439\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0181\n",
            "Epoch 20: loss did not improve from 0.01439\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0185\n",
            "Epoch 20: loss did not improve from 0.01439\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0183\n",
            "Epoch 20: loss did not improve from 0.01439\n",
            "17/17 [==============================] - 1s 77ms/step - loss: 0.0183 - val_loss: 0.0147 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 21: loss did not improve from 0.01439\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0203\n",
            "Epoch 21: loss did not improve from 0.01439\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0208\n",
            "Epoch 21: loss did not improve from 0.01439\n",
            " 3/17 [====>.........................] - ETA: 1s - loss: 0.0187\n",
            "Epoch 21: loss did not improve from 0.01439\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0178\n",
            "Epoch 21: loss did not improve from 0.01439\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0171\n",
            "Epoch 21: loss did not improve from 0.01439\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0171\n",
            "Epoch 21: loss did not improve from 0.01439\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0174\n",
            "Epoch 21: loss did not improve from 0.01439\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0183\n",
            "Epoch 21: loss did not improve from 0.01439\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0187\n",
            "Epoch 21: loss did not improve from 0.01439\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0184\n",
            "Epoch 21: loss did not improve from 0.01439\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0184\n",
            "Epoch 21: loss did not improve from 0.01439\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0185\n",
            "Epoch 21: loss did not improve from 0.01439\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0182\n",
            "Epoch 21: loss did not improve from 0.01439\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0184\n",
            "Epoch 21: loss did not improve from 0.01439\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0193\n",
            "Epoch 21: loss did not improve from 0.01439\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0196\n",
            "Epoch 21: loss did not improve from 0.01439\n",
            "17/17 [==============================] - 1s 81ms/step - loss: 0.0195 - val_loss: 0.0132 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 22: loss did not improve from 0.01439\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0146\n",
            "Epoch 22: loss improved from 0.01439 to 0.01245, saving model to best_model_lstm.hdf5\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0124\n",
            "Epoch 22: loss did not improve from 0.01245\n",
            " 3/17 [====>.........................] - ETA: 1s - loss: 0.0136\n",
            "Epoch 22: loss did not improve from 0.01245\n",
            " 4/17 [======>.......................] - ETA: 1s - loss: 0.0160\n",
            "Epoch 22: loss did not improve from 0.01245\n",
            " 5/17 [=======>......................] - ETA: 1s - loss: 0.0167\n",
            "Epoch 22: loss did not improve from 0.01245\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0170\n",
            "Epoch 22: loss did not improve from 0.01245\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0165\n",
            "Epoch 22: loss did not improve from 0.01245\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0169\n",
            "Epoch 22: loss did not improve from 0.01245\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0164\n",
            "Epoch 22: loss did not improve from 0.01245\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0164\n",
            "Epoch 22: loss did not improve from 0.01245\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0159\n",
            "Epoch 22: loss did not improve from 0.01245\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0159\n",
            "Epoch 22: loss did not improve from 0.01245\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0156\n",
            "Epoch 22: loss did not improve from 0.01245\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0153\n",
            "Epoch 22: loss did not improve from 0.01245\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0151\n",
            "Epoch 22: loss did not improve from 0.01245\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0158\n",
            "Epoch 22: loss did not improve from 0.01245\n",
            "17/17 [==============================] - 2s 91ms/step - loss: 0.0160 - val_loss: 0.0139 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 23: loss did not improve from 0.01245\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0131\n",
            "Epoch 23: loss did not improve from 0.01245\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0185\n",
            "Epoch 23: loss did not improve from 0.01245\n",
            " 3/17 [====>.........................] - ETA: 1s - loss: 0.0198\n",
            "Epoch 23: loss did not improve from 0.01245\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0173\n",
            "Epoch 23: loss did not improve from 0.01245\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0164\n",
            "Epoch 23: loss did not improve from 0.01245\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0160\n",
            "Epoch 23: loss did not improve from 0.01245\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0155\n",
            "Epoch 23: loss did not improve from 0.01245\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0155\n",
            "Epoch 23: loss did not improve from 0.01245\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0157\n",
            "Epoch 23: loss did not improve from 0.01245\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0156\n",
            "Epoch 23: loss did not improve from 0.01245\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0155\n",
            "Epoch 23: loss did not improve from 0.01245\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0156\n",
            "Epoch 23: loss did not improve from 0.01245\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0162\n",
            "Epoch 23: loss did not improve from 0.01245\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0165\n",
            "Epoch 23: loss did not improve from 0.01245\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0161\n",
            "Epoch 23: loss did not improve from 0.01245\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0163\n",
            "Epoch 23: loss did not improve from 0.01245\n",
            "17/17 [==============================] - 1s 76ms/step - loss: 0.0165 - val_loss: 0.0102 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 24: loss did not improve from 0.01245\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0164\n",
            "Epoch 24: loss did not improve from 0.01245\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0138\n",
            "Epoch 24: loss did not improve from 0.01245\n",
            " 3/17 [====>.........................] - ETA: 0s - loss: 0.0147\n",
            "Epoch 24: loss did not improve from 0.01245\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0145\n",
            "Epoch 24: loss did not improve from 0.01245\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0154\n",
            "Epoch 24: loss did not improve from 0.01245\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0175\n",
            "Epoch 24: loss did not improve from 0.01245\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0172\n",
            "Epoch 24: loss did not improve from 0.01245\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0178\n",
            "Epoch 24: loss did not improve from 0.01245\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0175\n",
            "Epoch 24: loss did not improve from 0.01245\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0172\n",
            "Epoch 24: loss did not improve from 0.01245\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0173\n",
            "Epoch 24: loss did not improve from 0.01245\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0176\n",
            "Epoch 24: loss did not improve from 0.01245\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0177\n",
            "Epoch 24: loss did not improve from 0.01245\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0180\n",
            "Epoch 24: loss did not improve from 0.01245\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0181\n",
            "Epoch 24: loss did not improve from 0.01245\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0179\n",
            "Epoch 24: loss did not improve from 0.01245\n",
            "17/17 [==============================] - 1s 73ms/step - loss: 0.0175 - val_loss: 0.0106 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 25: loss improved from 0.01245 to 0.01060, saving model to best_model_lstm.hdf5\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0106\n",
            "Epoch 25: loss did not improve from 0.01060\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0137\n",
            "Epoch 25: loss did not improve from 0.01060\n",
            " 3/17 [====>.........................] - ETA: 0s - loss: 0.0159\n",
            "Epoch 25: loss did not improve from 0.01060\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0157\n",
            "Epoch 25: loss did not improve from 0.01060\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0160\n",
            "Epoch 25: loss did not improve from 0.01060\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0154\n",
            "Epoch 25: loss did not improve from 0.01060\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0155\n",
            "Epoch 25: loss did not improve from 0.01060\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0148\n",
            "Epoch 25: loss did not improve from 0.01060\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0147\n",
            "Epoch 25: loss did not improve from 0.01060\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0143\n",
            "Epoch 25: loss did not improve from 0.01060\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0144\n",
            "Epoch 25: loss did not improve from 0.01060\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0146\n",
            "Epoch 25: loss did not improve from 0.01060\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0144\n",
            "Epoch 25: loss did not improve from 0.01060\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0144\n",
            "Epoch 25: loss did not improve from 0.01060\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0154\n",
            "Epoch 25: loss did not improve from 0.01060\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0156\n",
            "Epoch 25: loss did not improve from 0.01060\n",
            "17/17 [==============================] - 1s 74ms/step - loss: 0.0156 - val_loss: 0.0098 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 26: loss improved from 0.01060 to 0.01015, saving model to best_model_lstm.hdf5\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0101\n",
            "Epoch 26: loss did not improve from 0.01015\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0113\n",
            "Epoch 26: loss did not improve from 0.01015\n",
            " 3/17 [====>.........................] - ETA: 0s - loss: 0.0119\n",
            "Epoch 26: loss did not improve from 0.01015\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0127\n",
            "Epoch 26: loss did not improve from 0.01015\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0124\n",
            "Epoch 26: loss did not improve from 0.01015\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0129\n",
            "Epoch 26: loss did not improve from 0.01015\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0131\n",
            "Epoch 26: loss did not improve from 0.01015\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0143\n",
            "Epoch 26: loss did not improve from 0.01015\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0138\n",
            "Epoch 26: loss did not improve from 0.01015\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0137\n",
            "Epoch 26: loss did not improve from 0.01015\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0135\n",
            "Epoch 26: loss did not improve from 0.01015\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0139\n",
            "Epoch 26: loss did not improve from 0.01015\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0141\n",
            "Epoch 26: loss did not improve from 0.01015\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0140\n",
            "Epoch 26: loss did not improve from 0.01015\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0144\n",
            "Epoch 26: loss did not improve from 0.01015\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0149\n",
            "Epoch 26: loss did not improve from 0.01015\n",
            "17/17 [==============================] - 1s 74ms/step - loss: 0.0152 - val_loss: 0.0096 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 27: loss did not improve from 0.01015\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0115\n",
            "Epoch 27: loss did not improve from 0.01015\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0111\n",
            "Epoch 27: loss did not improve from 0.01015\n",
            " 3/17 [====>.........................] - ETA: 0s - loss: 0.0114\n",
            "Epoch 27: loss did not improve from 0.01015\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0155\n",
            "Epoch 27: loss did not improve from 0.01015\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0163\n",
            "Epoch 27: loss did not improve from 0.01015\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0170\n",
            "Epoch 27: loss did not improve from 0.01015\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0175\n",
            "Epoch 27: loss did not improve from 0.01015\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0172\n",
            "Epoch 27: loss did not improve from 0.01015\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0170\n",
            "Epoch 27: loss did not improve from 0.01015\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0167\n",
            "Epoch 27: loss did not improve from 0.01015\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0165\n",
            "Epoch 27: loss did not improve from 0.01015\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0167\n",
            "Epoch 27: loss did not improve from 0.01015\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0177\n",
            "Epoch 27: loss did not improve from 0.01015\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0173\n",
            "Epoch 27: loss did not improve from 0.01015\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0170\n",
            "Epoch 27: loss did not improve from 0.01015\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0172\n",
            "Epoch 27: loss did not improve from 0.01015\n",
            "17/17 [==============================] - 1s 75ms/step - loss: 0.0172 - val_loss: 0.0095 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 28: loss did not improve from 0.01015\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0163\n",
            "Epoch 28: loss did not improve from 0.01015\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0159\n",
            "Epoch 28: loss did not improve from 0.01015\n",
            " 3/17 [====>.........................] - ETA: 0s - loss: 0.0171\n",
            "Epoch 28: loss did not improve from 0.01015\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0177\n",
            "Epoch 28: loss did not improve from 0.01015\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0165\n",
            "Epoch 28: loss did not improve from 0.01015\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0158\n",
            "Epoch 28: loss did not improve from 0.01015\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0155\n",
            "Epoch 28: loss did not improve from 0.01015\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0152\n",
            "Epoch 28: loss did not improve from 0.01015\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0151\n",
            "Epoch 28: loss did not improve from 0.01015\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0155\n",
            "Epoch 28: loss did not improve from 0.01015\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0157\n",
            "Epoch 28: loss did not improve from 0.01015\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0157\n",
            "Epoch 28: loss did not improve from 0.01015\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0163\n",
            "Epoch 28: loss did not improve from 0.01015\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0164\n",
            "Epoch 28: loss did not improve from 0.01015\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0165\n",
            "Epoch 28: loss did not improve from 0.01015\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0164\n",
            "Epoch 28: loss did not improve from 0.01015\n",
            "17/17 [==============================] - 1s 76ms/step - loss: 0.0163 - val_loss: 0.0095 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 29: loss did not improve from 0.01015\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0112\n",
            "Epoch 29: loss did not improve from 0.01015\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0131\n",
            "Epoch 29: loss did not improve from 0.01015\n",
            " 3/17 [====>.........................] - ETA: 0s - loss: 0.0152\n",
            "Epoch 29: loss did not improve from 0.01015\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0163\n",
            "Epoch 29: loss did not improve from 0.01015\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0162\n",
            "Epoch 29: loss did not improve from 0.01015\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0161\n",
            "Epoch 29: loss did not improve from 0.01015\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0163\n",
            "Epoch 29: loss did not improve from 0.01015\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0162\n",
            "Epoch 29: loss did not improve from 0.01015\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0160\n",
            "Epoch 29: loss did not improve from 0.01015\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0161\n",
            "Epoch 29: loss did not improve from 0.01015\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0161\n",
            "Epoch 29: loss did not improve from 0.01015\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0156\n",
            "Epoch 29: loss did not improve from 0.01015\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0153\n",
            "Epoch 29: loss did not improve from 0.01015\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0156\n",
            "Epoch 29: loss did not improve from 0.01015\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0155\n",
            "Epoch 29: loss did not improve from 0.01015\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0155\n",
            "Epoch 29: loss did not improve from 0.01015\n",
            "17/17 [==============================] - 1s 77ms/step - loss: 0.0153 - val_loss: 0.0130 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 30: loss did not improve from 0.01015\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0229\n",
            "Epoch 30: loss did not improve from 0.01015\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0243\n",
            "Epoch 30: loss did not improve from 0.01015\n",
            " 3/17 [====>.........................] - ETA: 0s - loss: 0.0192\n",
            "Epoch 30: loss did not improve from 0.01015\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0181\n",
            "Epoch 30: loss did not improve from 0.01015\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0178\n",
            "Epoch 30: loss did not improve from 0.01015\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0170\n",
            "Epoch 30: loss did not improve from 0.01015\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0168\n",
            "Epoch 30: loss did not improve from 0.01015\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0167\n",
            "Epoch 30: loss did not improve from 0.01015\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0168\n",
            "Epoch 30: loss did not improve from 0.01015\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0161\n",
            "Epoch 30: loss did not improve from 0.01015\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0162\n",
            "Epoch 30: loss did not improve from 0.01015\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0158\n",
            "Epoch 30: loss did not improve from 0.01015\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0157\n",
            "Epoch 30: loss did not improve from 0.01015\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0155\n",
            "Epoch 30: loss did not improve from 0.01015\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0158\n",
            "Epoch 30: loss did not improve from 0.01015\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0157\n",
            "Epoch 30: loss did not improve from 0.01015\n",
            "17/17 [==============================] - 1s 78ms/step - loss: 0.0155 - val_loss: 0.0150 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 31: loss did not improve from 0.01015\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0205\n",
            "Epoch 31: loss did not improve from 0.01015\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0221\n",
            "Epoch 31: loss did not improve from 0.01015\n",
            " 3/17 [====>.........................] - ETA: 1s - loss: 0.0182\n",
            "Epoch 31: loss did not improve from 0.01015\n",
            " 4/17 [======>.......................] - ETA: 1s - loss: 0.0164\n",
            "Epoch 31: loss did not improve from 0.01015\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0169\n",
            "Epoch 31: loss did not improve from 0.01015\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0164\n",
            "Epoch 31: loss did not improve from 0.01015\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0173\n",
            "Epoch 31: loss did not improve from 0.01015\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0189\n",
            "Epoch 31: loss did not improve from 0.01015\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0183\n",
            "Epoch 31: loss did not improve from 0.01015\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0178\n",
            "Epoch 31: loss did not improve from 0.01015\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0179\n",
            "Epoch 31: loss did not improve from 0.01015\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0173\n",
            "Epoch 31: loss did not improve from 0.01015\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0181\n",
            "Epoch 31: loss did not improve from 0.01015\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0183\n",
            "Epoch 31: loss did not improve from 0.01015\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0184\n",
            "Epoch 31: loss did not improve from 0.01015\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0181\n",
            "Epoch 31: loss did not improve from 0.01015\n",
            "17/17 [==============================] - 1s 87ms/step - loss: 0.0181 - val_loss: 0.0129 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 32: loss did not improve from 0.01015\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0157\n",
            "Epoch 32: loss did not improve from 0.01015\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0165\n",
            "Epoch 32: loss did not improve from 0.01015\n",
            " 3/17 [====>.........................] - ETA: 1s - loss: 0.0155\n",
            "Epoch 32: loss did not improve from 0.01015\n",
            " 4/17 [======>.......................] - ETA: 1s - loss: 0.0144\n",
            "Epoch 32: loss did not improve from 0.01015\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0145\n",
            "Epoch 32: loss did not improve from 0.01015\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0150\n",
            "Epoch 32: loss did not improve from 0.01015\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0161\n",
            "Epoch 32: loss did not improve from 0.01015\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0161\n",
            "Epoch 32: loss did not improve from 0.01015\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0158\n",
            "Epoch 32: loss did not improve from 0.01015\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0154\n",
            "Epoch 32: loss did not improve from 0.01015\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0157\n",
            "Epoch 32: loss did not improve from 0.01015\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0158\n",
            "Epoch 32: loss did not improve from 0.01015\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0161\n",
            "Epoch 32: loss did not improve from 0.01015\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0155\n",
            "Epoch 32: loss did not improve from 0.01015\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0159\n",
            "Epoch 32: loss did not improve from 0.01015\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0158\n",
            "Epoch 32: loss did not improve from 0.01015\n",
            "17/17 [==============================] - 1s 79ms/step - loss: 0.0158 - val_loss: 0.0127 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 33: loss did not improve from 0.01015\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0116\n",
            "Epoch 33: loss did not improve from 0.01015\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0127\n",
            "Epoch 33: loss did not improve from 0.01015\n",
            " 3/17 [====>.........................] - ETA: 0s - loss: 0.0150\n",
            "Epoch 33: loss did not improve from 0.01015\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0154\n",
            "Epoch 33: loss did not improve from 0.01015\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0154\n",
            "Epoch 33: loss did not improve from 0.01015\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0157\n",
            "Epoch 33: loss did not improve from 0.01015\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0150\n",
            "Epoch 33: loss did not improve from 0.01015\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0152\n",
            "Epoch 33: loss did not improve from 0.01015\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0152\n",
            "Epoch 33: loss did not improve from 0.01015\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0150\n",
            "Epoch 33: loss did not improve from 0.01015\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0151\n",
            "Epoch 33: loss did not improve from 0.01015\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0150\n",
            "Epoch 33: loss did not improve from 0.01015\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0147\n",
            "Epoch 33: loss did not improve from 0.01015\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0146\n",
            "Epoch 33: loss did not improve from 0.01015\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0143\n",
            "Epoch 33: loss did not improve from 0.01015\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0146\n",
            "Epoch 33: loss did not improve from 0.01015\n",
            "17/17 [==============================] - 1s 75ms/step - loss: 0.0145 - val_loss: 0.0109 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 34: loss improved from 0.01015 to 0.00985, saving model to best_model_lstm.hdf5\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0099\n",
            "Epoch 34: loss did not improve from 0.00985\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0110\n",
            "Epoch 34: loss did not improve from 0.00985\n",
            " 3/17 [====>.........................] - ETA: 0s - loss: 0.0124\n",
            "Epoch 34: loss did not improve from 0.00985\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0125\n",
            "Epoch 34: loss did not improve from 0.00985\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0132\n",
            "Epoch 34: loss did not improve from 0.00985\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0146\n",
            "Epoch 34: loss did not improve from 0.00985\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0145\n",
            "Epoch 34: loss did not improve from 0.00985\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0145\n",
            "Epoch 34: loss did not improve from 0.00985\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0151\n",
            "Epoch 34: loss did not improve from 0.00985\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0147\n",
            "Epoch 34: loss did not improve from 0.00985\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0148\n",
            "Epoch 34: loss did not improve from 0.00985\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0148\n",
            "Epoch 34: loss did not improve from 0.00985\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0147\n",
            "Epoch 34: loss did not improve from 0.00985\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0146\n",
            "Epoch 34: loss did not improve from 0.00985\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0150\n",
            "Epoch 34: loss did not improve from 0.00985\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0148\n",
            "Epoch 34: loss did not improve from 0.00985\n",
            "17/17 [==============================] - 1s 78ms/step - loss: 0.0146 - val_loss: 0.0112 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 35: loss did not improve from 0.00985\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0125\n",
            "Epoch 35: loss did not improve from 0.00985\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0132\n",
            "Epoch 35: loss did not improve from 0.00985\n",
            " 3/17 [====>.........................] - ETA: 1s - loss: 0.0131\n",
            "Epoch 35: loss did not improve from 0.00985\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0126\n",
            "Epoch 35: loss did not improve from 0.00985\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0125\n",
            "Epoch 35: loss did not improve from 0.00985\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0126\n",
            "Epoch 35: loss did not improve from 0.00985\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0127\n",
            "Epoch 35: loss did not improve from 0.00985\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0128\n",
            "Epoch 35: loss did not improve from 0.00985\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0120\n",
            "Epoch 35: loss did not improve from 0.00985\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0124\n",
            "Epoch 35: loss did not improve from 0.00985\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0129\n",
            "Epoch 35: loss did not improve from 0.00985\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0131\n",
            "Epoch 35: loss did not improve from 0.00985\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0134\n",
            "Epoch 35: loss did not improve from 0.00985\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0131\n",
            "Epoch 35: loss did not improve from 0.00985\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0137\n",
            "Epoch 35: loss did not improve from 0.00985\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0143\n",
            "Epoch 35: loss did not improve from 0.00985\n",
            "17/17 [==============================] - 1s 75ms/step - loss: 0.0144 - val_loss: 0.0086 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 36: loss improved from 0.00985 to 0.00872, saving model to best_model_lstm.hdf5\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0087\n",
            "Epoch 36: loss did not improve from 0.00872\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0112\n",
            "Epoch 36: loss did not improve from 0.00872\n",
            " 3/17 [====>.........................] - ETA: 0s - loss: 0.0121\n",
            "Epoch 36: loss did not improve from 0.00872\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0124\n",
            "Epoch 36: loss did not improve from 0.00872\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0122\n",
            "Epoch 36: loss did not improve from 0.00872\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0122\n",
            "Epoch 36: loss did not improve from 0.00872\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0122\n",
            "Epoch 36: loss did not improve from 0.00872\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0126\n",
            "Epoch 36: loss did not improve from 0.00872\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0128\n",
            "Epoch 36: loss did not improve from 0.00872\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0126\n",
            "Epoch 36: loss did not improve from 0.00872\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0126\n",
            "Epoch 36: loss did not improve from 0.00872\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0123\n",
            "Epoch 36: loss did not improve from 0.00872\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0129\n",
            "Epoch 36: loss did not improve from 0.00872\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0127\n",
            "Epoch 36: loss did not improve from 0.00872\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0124\n",
            "Epoch 36: loss did not improve from 0.00872\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0122\n",
            "Epoch 36: loss did not improve from 0.00872\n",
            "17/17 [==============================] - 1s 76ms/step - loss: 0.0122 - val_loss: 0.0103 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 37: loss did not improve from 0.00872\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0187\n",
            "Epoch 37: loss did not improve from 0.00872\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0136\n",
            "Epoch 37: loss did not improve from 0.00872\n",
            " 3/17 [====>.........................] - ETA: 0s - loss: 0.0139\n",
            "Epoch 37: loss did not improve from 0.00872\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0140\n",
            "Epoch 37: loss did not improve from 0.00872\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0147\n",
            "Epoch 37: loss did not improve from 0.00872\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0150\n",
            "Epoch 37: loss did not improve from 0.00872\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0156\n",
            "Epoch 37: loss did not improve from 0.00872\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0152\n",
            "Epoch 37: loss did not improve from 0.00872\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0147\n",
            "Epoch 37: loss did not improve from 0.00872\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0142\n",
            "Epoch 37: loss did not improve from 0.00872\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0139\n",
            "Epoch 37: loss did not improve from 0.00872\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0134\n",
            "Epoch 37: loss did not improve from 0.00872\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0136\n",
            "Epoch 37: loss did not improve from 0.00872\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0142\n",
            "Epoch 37: loss did not improve from 0.00872\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0141\n",
            "Epoch 37: loss did not improve from 0.00872\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0138\n",
            "Epoch 37: loss did not improve from 0.00872\n",
            "17/17 [==============================] - 1s 77ms/step - loss: 0.0139 - val_loss: 0.0106 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 38: loss did not improve from 0.00872\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0179\n",
            "Epoch 38: loss did not improve from 0.00872\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0153\n",
            "Epoch 38: loss did not improve from 0.00872\n",
            " 3/17 [====>.........................] - ETA: 0s - loss: 0.0152\n",
            "Epoch 38: loss did not improve from 0.00872\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0146\n",
            "Epoch 38: loss did not improve from 0.00872\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0146\n",
            "Epoch 38: loss did not improve from 0.00872\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0141\n",
            "Epoch 38: loss did not improve from 0.00872\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0134\n",
            "Epoch 38: loss did not improve from 0.00872\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0143\n",
            "Epoch 38: loss did not improve from 0.00872\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0136\n",
            "Epoch 38: loss did not improve from 0.00872\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0132\n",
            "Epoch 38: loss did not improve from 0.00872\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0132\n",
            "Epoch 38: loss did not improve from 0.00872\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0131\n",
            "Epoch 38: loss did not improve from 0.00872\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0134\n",
            "Epoch 38: loss did not improve from 0.00872\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0135\n",
            "Epoch 38: loss did not improve from 0.00872\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0131\n",
            "Epoch 38: loss did not improve from 0.00872\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0137\n",
            "Epoch 38: loss did not improve from 0.00872\n",
            "17/17 [==============================] - 1s 76ms/step - loss: 0.0137 - val_loss: 0.0092 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 39: loss did not improve from 0.00872\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0148\n",
            "Epoch 39: loss did not improve from 0.00872\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0116\n",
            "Epoch 39: loss did not improve from 0.00872\n",
            " 3/17 [====>.........................] - ETA: 1s - loss: 0.0117\n",
            "Epoch 39: loss did not improve from 0.00872\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0112\n",
            "Epoch 39: loss did not improve from 0.00872\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0107\n",
            "Epoch 39: loss did not improve from 0.00872\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0106\n",
            "Epoch 39: loss did not improve from 0.00872\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0112\n",
            "Epoch 39: loss did not improve from 0.00872\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0112\n",
            "Epoch 39: loss did not improve from 0.00872\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0114\n",
            "Epoch 39: loss did not improve from 0.00872\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0117\n",
            "Epoch 39: loss did not improve from 0.00872\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0117\n",
            "Epoch 39: loss did not improve from 0.00872\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0117\n",
            "Epoch 39: loss did not improve from 0.00872\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0123\n",
            "Epoch 39: loss did not improve from 0.00872\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0123\n",
            "Epoch 39: loss did not improve from 0.00872\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0122\n",
            "Epoch 39: loss did not improve from 0.00872\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0127\n",
            "Epoch 39: loss did not improve from 0.00872\n",
            "17/17 [==============================] - 1s 77ms/step - loss: 0.0127 - val_loss: 0.0086 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 40: loss did not improve from 0.00872\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0149\n",
            "Epoch 40: loss did not improve from 0.00872\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0103\n",
            "Epoch 40: loss did not improve from 0.00872\n",
            " 3/17 [====>.........................] - ETA: 1s - loss: 0.0130\n",
            "Epoch 40: loss did not improve from 0.00872\n",
            " 4/17 [======>.......................] - ETA: 1s - loss: 0.0125\n",
            "Epoch 40: loss did not improve from 0.00872\n",
            " 5/17 [=======>......................] - ETA: 1s - loss: 0.0135\n",
            "Epoch 40: loss did not improve from 0.00872\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0138\n",
            "Epoch 40: loss did not improve from 0.00872\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0147\n",
            "Epoch 40: loss did not improve from 0.00872\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0144\n",
            "Epoch 40: loss did not improve from 0.00872\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0138\n",
            "Epoch 40: loss did not improve from 0.00872\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0137\n",
            "Epoch 40: loss did not improve from 0.00872\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0134\n",
            "Epoch 40: loss did not improve from 0.00872\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0134\n",
            "Epoch 40: loss did not improve from 0.00872\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0131\n",
            "Epoch 40: loss did not improve from 0.00872\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0131\n",
            "Epoch 40: loss did not improve from 0.00872\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0129\n",
            "Epoch 40: loss did not improve from 0.00872\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0126\n",
            "Epoch 40: loss did not improve from 0.00872\n",
            "17/17 [==============================] - 2s 88ms/step - loss: 0.0124 - val_loss: 0.0086 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 41: loss did not improve from 0.00872\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0091\n",
            "Epoch 41: loss did not improve from 0.00872\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0090\n",
            "Epoch 41: loss did not improve from 0.00872\n",
            " 3/17 [====>.........................] - ETA: 1s - loss: 0.0092\n",
            "Epoch 41: loss did not improve from 0.00872\n",
            " 4/17 [======>.......................] - ETA: 1s - loss: 0.0096\n",
            "Epoch 41: loss did not improve from 0.00872\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0103\n",
            "Epoch 41: loss did not improve from 0.00872\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0109\n",
            "Epoch 41: loss did not improve from 0.00872\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0108\n",
            "Epoch 41: loss did not improve from 0.00872\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0115\n",
            "Epoch 41: loss did not improve from 0.00872\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0115\n",
            "Epoch 41: loss did not improve from 0.00872\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0123\n",
            "Epoch 41: loss did not improve from 0.00872\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0122\n",
            "Epoch 41: loss did not improve from 0.00872\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0124\n",
            "Epoch 41: loss did not improve from 0.00872\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0124\n",
            "Epoch 41: loss did not improve from 0.00872\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0124\n",
            "Epoch 41: loss did not improve from 0.00872\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0123\n",
            "Epoch 41: loss did not improve from 0.00872\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0123\n",
            "Epoch 41: loss did not improve from 0.00872\n",
            "17/17 [==============================] - 1s 78ms/step - loss: 0.0124 - val_loss: 0.0087 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 42: loss did not improve from 0.00872\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0106\n",
            "Epoch 42: loss did not improve from 0.00872\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0098\n",
            "Epoch 42: loss did not improve from 0.00872\n",
            " 3/17 [====>.........................] - ETA: 0s - loss: 0.0104\n",
            "Epoch 42: loss did not improve from 0.00872\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0103\n",
            "Epoch 42: loss did not improve from 0.00872\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0101\n",
            "Epoch 42: loss did not improve from 0.00872\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0101\n",
            "Epoch 42: loss did not improve from 0.00872\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0110\n",
            "Epoch 42: loss did not improve from 0.00872\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0114\n",
            "Epoch 42: loss did not improve from 0.00872\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0113\n",
            "Epoch 42: loss did not improve from 0.00872\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0119\n",
            "Epoch 42: loss did not improve from 0.00872\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0121\n",
            "Epoch 42: loss did not improve from 0.00872\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0122\n",
            "Epoch 42: loss did not improve from 0.00872\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0122\n",
            "Epoch 42: loss did not improve from 0.00872\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0125\n",
            "Epoch 42: loss did not improve from 0.00872\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0123\n",
            "Epoch 42: loss did not improve from 0.00872\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0122\n",
            "Epoch 42: loss did not improve from 0.00872\n",
            "17/17 [==============================] - 1s 76ms/step - loss: 0.0124 - val_loss: 0.0078 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 43: loss did not improve from 0.00872\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0100\n",
            "Epoch 43: loss did not improve from 0.00872\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0088\n",
            "Epoch 43: loss did not improve from 0.00872\n",
            " 3/17 [====>.........................] - ETA: 1s - loss: 0.0090\n",
            "Epoch 43: loss did not improve from 0.00872\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0097\n",
            "Epoch 43: loss did not improve from 0.00872\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0094\n",
            "Epoch 43: loss did not improve from 0.00872\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0098\n",
            "Epoch 43: loss did not improve from 0.00872\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0102\n",
            "Epoch 43: loss did not improve from 0.00872\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0101\n",
            "Epoch 43: loss did not improve from 0.00872\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0108\n",
            "Epoch 43: loss did not improve from 0.00872\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0110\n",
            "Epoch 43: loss did not improve from 0.00872\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0113\n",
            "Epoch 43: loss did not improve from 0.00872\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0117\n",
            "Epoch 43: loss did not improve from 0.00872\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0116\n",
            "Epoch 43: loss did not improve from 0.00872\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0114\n",
            "Epoch 43: loss did not improve from 0.00872\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0117\n",
            "Epoch 43: loss did not improve from 0.00872\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0117\n",
            "Epoch 43: loss did not improve from 0.00872\n",
            "17/17 [==============================] - 1s 78ms/step - loss: 0.0122 - val_loss: 0.0066 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 44: loss did not improve from 0.00872\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0191\n",
            "Epoch 44: loss did not improve from 0.00872\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0183\n",
            "Epoch 44: loss did not improve from 0.00872\n",
            " 3/17 [====>.........................] - ETA: 1s - loss: 0.0149\n",
            "Epoch 44: loss did not improve from 0.00872\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0150\n",
            "Epoch 44: loss did not improve from 0.00872\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0155\n",
            "Epoch 44: loss did not improve from 0.00872\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0156\n",
            "Epoch 44: loss did not improve from 0.00872\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0152\n",
            "Epoch 44: loss did not improve from 0.00872\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0143\n",
            "Epoch 44: loss did not improve from 0.00872\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0142\n",
            "Epoch 44: loss did not improve from 0.00872\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0137\n",
            "Epoch 44: loss did not improve from 0.00872\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0137\n",
            "Epoch 44: loss did not improve from 0.00872\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0134\n",
            "Epoch 44: loss did not improve from 0.00872\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0131\n",
            "Epoch 44: loss did not improve from 0.00872\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0130\n",
            "Epoch 44: loss did not improve from 0.00872\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0131\n",
            "Epoch 44: loss did not improve from 0.00872\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0132\n",
            "Epoch 44: loss did not improve from 0.00872\n",
            "17/17 [==============================] - 1s 76ms/step - loss: 0.0131 - val_loss: 0.0071 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 45: loss did not improve from 0.00872\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0185\n",
            "Epoch 45: loss did not improve from 0.00872\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0200\n",
            "Epoch 45: loss did not improve from 0.00872\n",
            " 3/17 [====>.........................] - ETA: 1s - loss: 0.0155\n",
            "Epoch 45: loss did not improve from 0.00872\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0145\n",
            "Epoch 45: loss did not improve from 0.00872\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0141\n",
            "Epoch 45: loss did not improve from 0.00872\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0137\n",
            "Epoch 45: loss did not improve from 0.00872\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0125\n",
            "Epoch 45: loss did not improve from 0.00872\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0124\n",
            "Epoch 45: loss did not improve from 0.00872\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0126\n",
            "Epoch 45: loss did not improve from 0.00872\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0128\n",
            "Epoch 45: loss did not improve from 0.00872\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0132\n",
            "Epoch 45: loss did not improve from 0.00872\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0128\n",
            "Epoch 45: loss did not improve from 0.00872\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0128\n",
            "Epoch 45: loss did not improve from 0.00872\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0131\n",
            "Epoch 45: loss did not improve from 0.00872\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0127\n",
            "Epoch 45: loss did not improve from 0.00872\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0128\n",
            "Epoch 45: loss did not improve from 0.00872\n",
            "17/17 [==============================] - 1s 78ms/step - loss: 0.0126 - val_loss: 0.0077 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 46: loss improved from 0.00872 to 0.00768, saving model to best_model_lstm.hdf5\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0077\n",
            "Epoch 46: loss did not improve from 0.00768\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0115\n",
            "Epoch 46: loss did not improve from 0.00768\n",
            " 3/17 [====>.........................] - ETA: 1s - loss: 0.0120\n",
            "Epoch 46: loss did not improve from 0.00768\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0121\n",
            "Epoch 46: loss did not improve from 0.00768\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0117\n",
            "Epoch 46: loss did not improve from 0.00768\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0118\n",
            "Epoch 46: loss did not improve from 0.00768\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0118\n",
            "Epoch 46: loss did not improve from 0.00768\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0115\n",
            "Epoch 46: loss did not improve from 0.00768\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0117\n",
            "Epoch 46: loss did not improve from 0.00768\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0115\n",
            "Epoch 46: loss did not improve from 0.00768\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0116\n",
            "Epoch 46: loss did not improve from 0.00768\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0120\n",
            "Epoch 46: loss did not improve from 0.00768\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0121\n",
            "Epoch 46: loss did not improve from 0.00768\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0123\n",
            "Epoch 46: loss did not improve from 0.00768\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0121\n",
            "Epoch 46: loss did not improve from 0.00768\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0124\n",
            "Epoch 46: loss did not improve from 0.00768\n",
            "17/17 [==============================] - 1s 78ms/step - loss: 0.0124 - val_loss: 0.0087 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 47: loss did not improve from 0.00768\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0149\n",
            "Epoch 47: loss did not improve from 0.00768\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0140\n",
            "Epoch 47: loss did not improve from 0.00768\n",
            " 3/17 [====>.........................] - ETA: 1s - loss: 0.0129\n",
            "Epoch 47: loss did not improve from 0.00768\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0116\n",
            "Epoch 47: loss did not improve from 0.00768\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0121\n",
            "Epoch 47: loss did not improve from 0.00768\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0126\n",
            "Epoch 47: loss did not improve from 0.00768\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0127\n",
            "Epoch 47: loss did not improve from 0.00768\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0135\n",
            "Epoch 47: loss did not improve from 0.00768\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0130\n",
            "Epoch 47: loss did not improve from 0.00768\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0128\n",
            "Epoch 47: loss did not improve from 0.00768\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0127\n",
            "Epoch 47: loss did not improve from 0.00768\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0125\n",
            "Epoch 47: loss did not improve from 0.00768\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0121\n",
            "Epoch 47: loss did not improve from 0.00768\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0123\n",
            "Epoch 47: loss did not improve from 0.00768\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0121\n",
            "Epoch 47: loss did not improve from 0.00768\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0119\n",
            "Epoch 47: loss did not improve from 0.00768\n",
            "17/17 [==============================] - 1s 78ms/step - loss: 0.0118 - val_loss: 0.0076 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 48: loss did not improve from 0.00768\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0163\n",
            "Epoch 48: loss did not improve from 0.00768\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0133\n",
            "Epoch 48: loss did not improve from 0.00768\n",
            " 3/17 [====>.........................] - ETA: 1s - loss: 0.0131\n",
            "Epoch 48: loss did not improve from 0.00768\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0131\n",
            "Epoch 48: loss did not improve from 0.00768\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0132\n",
            "Epoch 48: loss did not improve from 0.00768\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0127\n",
            "Epoch 48: loss did not improve from 0.00768\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0126\n",
            "Epoch 48: loss did not improve from 0.00768\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0124\n",
            "Epoch 48: loss did not improve from 0.00768\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0124\n",
            "Epoch 48: loss did not improve from 0.00768\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0131\n",
            "Epoch 48: loss did not improve from 0.00768\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0130\n",
            "Epoch 48: loss did not improve from 0.00768\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0131\n",
            "Epoch 48: loss did not improve from 0.00768\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0131\n",
            "Epoch 48: loss did not improve from 0.00768\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0133\n",
            "Epoch 48: loss did not improve from 0.00768\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0132\n",
            "Epoch 48: loss did not improve from 0.00768\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0132\n",
            "Epoch 48: loss did not improve from 0.00768\n",
            "17/17 [==============================] - 1s 82ms/step - loss: 0.0131 - val_loss: 0.0090 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 49: loss did not improve from 0.00768\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0091\n",
            "Epoch 49: loss did not improve from 0.00768\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0095\n",
            "Epoch 49: loss did not improve from 0.00768\n",
            " 3/17 [====>.........................] - ETA: 1s - loss: 0.0095\n",
            "Epoch 49: loss did not improve from 0.00768\n",
            " 4/17 [======>.......................] - ETA: 1s - loss: 0.0099\n",
            "Epoch 49: loss did not improve from 0.00768\n",
            " 5/17 [=======>......................] - ETA: 1s - loss: 0.0095\n",
            "Epoch 49: loss did not improve from 0.00768\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0099\n",
            "Epoch 49: loss did not improve from 0.00768\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0101\n",
            "Epoch 49: loss did not improve from 0.00768\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0107\n",
            "Epoch 49: loss did not improve from 0.00768\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0103\n",
            "Epoch 49: loss did not improve from 0.00768\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0106\n",
            "Epoch 49: loss did not improve from 0.00768\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0109\n",
            "Epoch 49: loss did not improve from 0.00768\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0105\n",
            "Epoch 49: loss did not improve from 0.00768\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0108\n",
            "Epoch 49: loss did not improve from 0.00768\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0110\n",
            "Epoch 49: loss did not improve from 0.00768\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0112\n",
            "Epoch 49: loss did not improve from 0.00768\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0113\n",
            "Epoch 49: loss did not improve from 0.00768\n",
            "17/17 [==============================] - 2s 92ms/step - loss: 0.0114 - val_loss: 0.0089 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 50: loss did not improve from 0.00768\n",
            " 1/17 [>.............................] - ETA: 1s - loss: 0.0084\n",
            "Epoch 50: loss did not improve from 0.00768\n",
            " 2/17 [==>...........................] - ETA: 1s - loss: 0.0099\n",
            "Epoch 50: loss did not improve from 0.00768\n",
            " 3/17 [====>.........................] - ETA: 1s - loss: 0.0124\n",
            "Epoch 50: loss did not improve from 0.00768\n",
            " 4/17 [======>.......................] - ETA: 0s - loss: 0.0118\n",
            "Epoch 50: loss did not improve from 0.00768\n",
            " 5/17 [=======>......................] - ETA: 0s - loss: 0.0124\n",
            "Epoch 50: loss did not improve from 0.00768\n",
            " 6/17 [=========>....................] - ETA: 0s - loss: 0.0134\n",
            "Epoch 50: loss did not improve from 0.00768\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.0128\n",
            "Epoch 50: loss did not improve from 0.00768\n",
            " 8/17 [=============>................] - ETA: 0s - loss: 0.0119\n",
            "Epoch 50: loss did not improve from 0.00768\n",
            " 9/17 [==============>...............] - ETA: 0s - loss: 0.0118\n",
            "Epoch 50: loss did not improve from 0.00768\n",
            "10/17 [================>.............] - ETA: 0s - loss: 0.0120\n",
            "Epoch 50: loss did not improve from 0.00768\n",
            "11/17 [==================>...........] - ETA: 0s - loss: 0.0121\n",
            "Epoch 50: loss did not improve from 0.00768\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 0.0119\n",
            "Epoch 50: loss did not improve from 0.00768\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 0.0118\n",
            "Epoch 50: loss did not improve from 0.00768\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 0.0117\n",
            "Epoch 50: loss did not improve from 0.00768\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 0.0119\n",
            "Epoch 50: loss did not improve from 0.00768\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 0.0117\n",
            "Epoch 50: loss did not improve from 0.00768\n",
            "17/17 [==============================] - 1s 78ms/step - loss: 0.0119 - val_loss: 0.0080 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6118076880>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "model_lstm.fit(X_train, y_train,validation_data=(X_test, y_test), epochs=50, verbose=1, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xDtqdXshvId",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de416a15-9b60-4cc8-fb91-ea78bbded4cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 8ms/step\n"
          ]
        }
      ],
      "source": [
        "model_lstm.load_weights('best_model_lstm.hdf5')\n",
        "pred_lstm = model_lstm.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yd6JawdVZ_vI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddcd9b84-a127-4dd0-ebb6-0b937728b827"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM model Results\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MLP': {'mse': 0.003234977257735753,\n",
              "  'mae': 0.04369475587181178,\n",
              "  'mape': 0.0766240223561974},\n",
              " 'LSTM': {'mse': 0.008040517372466234,\n",
              "  'mae': 0.07269689632233525,\n",
              "  'mape': 0.14168762735965318}}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "print('LSTM model Results')\n",
        "results['LSTM'] = {'mse': mean_squared_error(pred_lstm, y_test),\n",
        "                  'mae': mean_absolute_error(pred_lstm, y_test),\n",
        "                  'mape':mean_absolute_percentage_error(pred_lstm, y_test)}\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVPgFK-XaCqr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "a8b33f66-2f93-4ce2-ed35-4fd286a0db64"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f60d8841490>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(pred_lstm, label='pred')\n",
        "ax.plot(y_test.reset_index(drop=True), label='true')\n",
        "plt.title('lstm MODEL')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LGBM regressor"
      ],
      "metadata": {
        "id": "cl2nHHArMvG6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZGuke_9QoIp"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1]))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcSqQIifca9L"
      },
      "outputs": [],
      "source": [
        "model_LGBM = LGBMRegressor()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIgNu1FVQXQs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "6b4b8a03-bd83-4dd0-dda5-0d9e2adbb744"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 20 rounds.\n",
            "[50]\tvalid_0's rmse: 0.0614359\tvalid_0's l2: 0.00377437\n",
            "[100]\tvalid_0's rmse: 0.0608019\tvalid_0's l2: 0.00369688\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[97]\tvalid_0's rmse: 0.0606972\tvalid_0's l2: 0.00368415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMRegressor()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "model_LGBM.fit(X_train, y_train,\n",
        "          eval_set=[(X_test, y_test)],\n",
        "          verbose=50,\n",
        "          eval_metric='rmse',\n",
        "          early_stopping_rounds=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4W29q7pEQx1n"
      },
      "outputs": [],
      "source": [
        "pred_LGBM = model_LGBM.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sx1jf6kZQ4zg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "665785e0-57c2-4382-c01a-4e205befda62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LGBM model Results\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MLP': {'mse': 0.003234977257735753,\n",
              "  'mae': 0.04369475587181178,\n",
              "  'mape': 0.0766240223561974},\n",
              " 'LSTM': {'mse': 0.008040517372466234,\n",
              "  'mae': 0.07269689632233525,\n",
              "  'mape': 0.14168762735965318},\n",
              " 'LGBM': {'mse': 0.0036841520042503184,\n",
              "  'mae': 0.046490840215175175,\n",
              "  'mape': 0.08625817146208868}}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "print('LGBM model Results')\n",
        "results['LGBM'] = {'mse': mean_squared_error(pred_LGBM, y_test),\n",
        "                  'mae': mean_absolute_error(pred_LGBM, y_test),\n",
        "                  'mape':mean_absolute_percentage_error(pred_LGBM, y_test)}\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9qCpwg3REGP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "f2218b99-96e2-4fac-acf0-03af7a3f4999"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f60d87b38b0>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "fig,ax = plt.subplots()\n",
        "ax.plot(pred_LGBM, label='pred')\n",
        "ax.plot(y_test.reset_index(drop=True), label='true')\n",
        "plt.title('LGBM MODEL')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVR regressor"
      ],
      "metadata": {
        "id": "AzOEf5vRM0HD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param = {'kernel' : ('linear', 'poly', 'rbf', 'sigmoid'),'C' : [1,5,10],'degree' : [3,8],'coef0' : [0.01,10,0.5],'gamma' : ('auto','scale')}\n",
        "model_SVR = GridSearchCV(SVR(),param,cv=5)"
      ],
      "metadata": {
        "id": "CE0UaXc06z0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_SVR.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "mYa4Z1mh-Ug9",
        "outputId": "d3d586b0-70ce-4e39-ffc4-2c9dd58877cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=SVR(),\n",
              "             param_grid={'C': [1, 5, 10], 'coef0': [0.01, 10, 0.5],\n",
              "                         'degree': [3, 8], 'gamma': ('auto', 'scale'),\n",
              "                         'kernel': ('linear', 'poly', 'rbf', 'sigmoid')})"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SVR(),\n",
              "             param_grid={&#x27;C&#x27;: [1, 5, 10], &#x27;coef0&#x27;: [0.01, 10, 0.5],\n",
              "                         &#x27;degree&#x27;: [3, 8], &#x27;gamma&#x27;: (&#x27;auto&#x27;, &#x27;scale&#x27;),\n",
              "                         &#x27;kernel&#x27;: (&#x27;linear&#x27;, &#x27;poly&#x27;, &#x27;rbf&#x27;, &#x27;sigmoid&#x27;)})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SVR(),\n",
              "             param_grid={&#x27;C&#x27;: [1, 5, 10], &#x27;coef0&#x27;: [0.01, 10, 0.5],\n",
              "                         &#x27;degree&#x27;: [3, 8], &#x27;gamma&#x27;: (&#x27;auto&#x27;, &#x27;scale&#x27;),\n",
              "                         &#x27;kernel&#x27;: (&#x27;linear&#x27;, &#x27;poly&#x27;, &#x27;rbf&#x27;, &#x27;sigmoid&#x27;)})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVR</label><div class=\"sk-toggleable__content\"><pre>SVR()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVR</label><div class=\"sk-toggleable__content\"><pre>SVR()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_SVR = model_SVR.predict(X_test)"
      ],
      "metadata": {
        "id": "rmvsu0Vb-gXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('SVR model Results')\n",
        "results['SVR'] = {'mse': mean_squared_error(pred_SVR, y_test),\n",
        "                  'mae': mean_absolute_error(pred_SVR, y_test),\n",
        "                  'mape':mean_absolute_percentage_error(pred_SVR, y_test)}\n",
        "results"
      ],
      "metadata": {
        "id": "EO61a-B0-p1Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2ab2cf7-c726-49f0-da78-f1bf86879535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVR model Results\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MLP': {'mse': 0.003234977257735753,\n",
              "  'mae': 0.04369475587181178,\n",
              "  'mape': 0.0766240223561974},\n",
              " 'LSTM': {'mse': 0.008040517372466234,\n",
              "  'mae': 0.07269689632233525,\n",
              "  'mape': 0.14168762735965318},\n",
              " 'LGBM': {'mse': 0.0036841520042503184,\n",
              "  'mae': 0.046490840215175175,\n",
              "  'mape': 0.08625817146208868},\n",
              " 'SVR': {'mse': 0.0026444878875929454,\n",
              "  'mae': 0.040567308445866576,\n",
              "  'mape': 0.0747836688725313}}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3wFOKiSMFcq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "5b68158e-25c2-4a8b-a3f2-50f24485f392"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f60d870de20>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAABjFElEQVR4nO29d3hkZ3n3/3mmN2lm1HvbXmzvrtfruu4G2xgDCaa8EAIESAIJLW8IhIQQfiShJMCbhIRA6GBqKMYxNu692+vtVdKql9H03p7fH+dIK2lVVzMaSft8rkuXNOecOXPrSPM999zPXYSUEoVCoVCsfgylNkChUCgUhUEJukKhUKwRlKArFArFGkEJukKhUKwRlKArFArFGkEJukKhUKwRlKArFArFGkEJumLFIIS4SgjxlBAiJITwCyGeFEJcIoS4TAgRE0K4ZnjOy0KIPxNCtAkhpBAiqn91CyE+Ps/rSSHEiBDCNGmbWd8mpx17mxDiOd2OMSHED4UQTZP2v1MIkZv0+l1CiG8LITZOOma6jeNfb9b3f0cI8dmlXEPF+Y0SdMWKQAhRDtwN/BtQATQCfw+kpJTPAH3AG6c9ZzuwFfjRpM0eKaVLP/ZvhRA3zfPSAeCWSY9v0bdNfp03AncCXwGqgG1ACnhCCOGddOjT+mu7gRuBBPCibudkPFJK16Svn8xjo0KxIJSgK1YKGwGklD+SUuaklAkp5e+klPv1/d8F3jHtOe8A7pFSjk0/mZTyBeAQsGOe1/3+tPO+A/je+AMhhAD+BfislPJO3a4h4D1AFPjIDK+dk1KeklK+H3gU+PQ8NigUBUEJumKlcBzICSG+K4S4ZZrnC5rwXi2EaAYQQhiA/4Mm9GchhLgM2A6cnOd1f6Wf16O/5l7g15P2bwJagJ9NfpKUMg/8DzDfJ4Bf6OdUKIqOEnTFikBKGQauAiTwDWBUCHGXEKJW398LPAL8gf6UGwAr8L/TTuUTQiSAp4H/QBPsuUgCvwHerH/dpW8bp0r/PjjDcwcn7Z+NAbQQ0nQbg5O+tsxzDoViQShBV6wYpJRHpJTvlFI2oXnXDWhx63G+yxlB/wPgx1LKzLTTVAEu4C+AawHzAl76e2ihlinhFh2f/r1+hufVT9o/G42Af7qNUkrPpK8jC7BRoZgXJeiKFYmU8ijwHTRhH+cXQJMQ4jrg95gl3KLHsL+E5mm/fwEv9ziaONcCT0zbdwxtQfaOyRv1kM/vAw/Oc+436OdXKIqOaf5DFIriI4TYDLwG+ImUsk+Plb8VeGb8GCllTAjxc+DbwGl94XMuPgd8XQjxNSllcraDpJRSCPHaST9P3/d/gW8IIfrQbioe4B+BcuDLM/wuRrS4+0fRPiVcPo+dkzEKIWyTHuellOlFPF9xHqM8dMVKIQJcCjwrhIihCflBtNDJZL4LtHJ2aGQm/hctBfG98x0opTwkpTw0y76foIV4PgKMAYcBO3DltAyby4UQUSCMFu8vBy6RUh6YdsrgtDz0j07a93G0dMfxr4fm/zUVCg2hBlwoFArF2kB56AqFQrFGUIKuUCgUawQl6AqFQrFGUIKuUCgUa4SSpS1WVVXJtra2Ur28QqFQrEpefPFFn5SyeqZ9JRP0trY2XnhhvjRihUKhUExGCHF6tn0q5KJQKBRrBCXoCoVCsUZQgq5QKBRrhBXVyyWTydDX10cyOWvbjTWBzWajqakJs3khjQAVCoViYawoQe/r66OsrIy2tjYmN0haS0gpGRsbo6+vj/b29lKbo1Ao1hArKuSSTCaprKxcs2IOIISgsrJyzX8KUSgUy8+KEnRgTYv5OOfD76hQKJafFSfoCsVq5Vcv9xOKTx+gpFAsH0rQi8gjjzzCbbfdVmozFMtAty/Gh3+yj1/t6y+1KYrzGCXo50Aulyu1CYoVxsmRKAAjEbU2oigdStCn0d3dzebNm3nb297Gli1beOMb30g8HqetrY2/+qu/YteuXfzsZz/jd7/7HZdffjm7du3ijjvuIBrV3tD33nsvmzdvZteuXfziF78o8W+jWC46fdrf3xdR0+IUpWNFpS1O5u9/c4jDA+GCnnNrQzl/99pt8x537NgxvvnNb3LllVfy7ne/m//4j/8AoLKykpdeegmfz8fv/d7v8cADD+B0Ovn85z/Pl770JT72sY/x3ve+l4ceeoj169fz5je/uaD2K1Yup0ZiAPiiqRJbojifUR76DDQ3N3PllVcC8Pa3v50nntAGwY8L9DPPPMPhw4e58sor2bFjB9/97nc5ffo0R48epb29nQ0bNiCE4O1vf3vJfgfF8jLhoStBV5SQFeuhL8STLhbT0wrHHzudTkArDrrpppv40Y9+NOW4ffv2LYt9ipXHqdFxD12FXBSlQ3noM9DT08PTTz8NwJ133slVV101Zf9ll13Gk08+ycmTJwGIxWIcP36czZs3093dzalTpwDOEnzF2iQQS+OPpbGaDPiiKWSysKFChWKhzCvoQohvCSFGhBAHZ9kvhBD/KoQ4KYTYL4TYVXgzl5dNmzbx1a9+lS1bthAIBPjTP/3TKfurq6v5zne+w1vf+lYuvPBCLr/8co4ePYrNZuPrX/86r3nNa9i1axc1NTUl+g0Uy8l4uGVni4d1uU74Qjv0Pl9iqxTnIwsJuXwH+Hfge7PsvwXYoH9dCvyn/n3VYjKZ+MEPfjBlW3d395TH119/Pc8/f/ab9uabb+bo0aPFNE+xwhDPfYMNwsOe9g04ep5G5LMwtB+aLym1aYrzjHkFXUr5mBCibY5DXgd8T0opgWeEEB4hRL2UcrBQRioUK5ZkmF2H/pFPm7eTbno97YbntO2hvtLapTgvKUQMvRHonfS4T992FkKI9wkhXhBCvDA6OlqAly48bW1tHDw4Y3RJoTgbv7ZecqXhIBtGfkubYVjbHuqd40kKRXFY1kVRKeXXpZS7pZS7q6tnnHGqUKwuxk5N/NjwxCfIS0HQ2aE8dEVJKISg9wPNkx436dsUijVPdvQ4eSk4WHUrhkyc5+UmBhxbIKg8dMXyUwhBvwt4h57tchkQUvFzxflCpP8YA1QytvMDIIw8aNzLkKEaIgOQU50XFcvLvIuiQogfAdcCVUKIPuDvADOAlPJrwD3ArcBJIA68q1jGKhQrjZzvJJ35etZt3QXb9vHot07RlH8MZB4ig+BpKbWJivOIhWS5vHWe/RL4QMEsKiHBYJA777yT97///aU2RbEakBJnpJsh05Xs9dhBtFDhGqArXqntD/YqQVcsK6pSdBLBYHCiEddkstlsCaxRrHjiY9jzUdLujon2EFVlVk6kPNp+tTCqWGaUoE/i4x//OKdOnWLHjh1ccskl7N27l9tvv52tW7fS3d3N9u3bJ47953/+Zz796U8DcOrUKW6++WYuvvhi9u7dqwqLzhNSQ8cAcNRvmthW5bJwOFauPQj1lMKsOcnnJcmM6ue/Vlmxzbn47cdh6EBhz1l3AdzyuVl3f+5zn+PgwYPs27ePRx55hNe85jUcPHiQ9vb2sypFJ/O+972Pr33ta2zYsIFnn32W97///Tz00EOFtV2x4hjoPEg7UNN+5kZf5bLiTxvJeCp5+vmX2bknQ5nNXDojp/GDZ0/z7w+d5Nm/vkHNtgU49TA89s/wjl+BceX8nc6VlSvoK4A9e/bQ3t4+5zHRaJSnnnqKO+64Y2JbKqVaqJ4PhPuPkpFGNmzcMrGt2mUF4HjSg4z1cmggzGUdlaUy8SxODEcZiaRIZvLYLcZSm1N6TvwOTj8BkSHwNM9//Apn5Qr6HJ70cjHeLhe0/i75fH7icTKpjRrL5/N4PB7VOvc8RI6dpF/U0uZxTWyrKrMA0JOrYL0Y4HB4ZY2k88e09r7RVFYJOpwpDIsOrwlBVzH0SZSVlRGJRGbcV1tby8jICGNjY6RSKe6++24AysvLaW9v52c/+xmg9Up/5ZVXls1mRekoj50m6Gidsq21UnMC6ls20ih8DAUTpTBtVsYFPZ5WC/0AjGktsIkMFf+17vog+ZOP0OuPk87m5z/+HFCCPonKykquvPJKtm/fzl/+5V9O2Wc2m/nUpz7Fnj17uOmmm9i8efPEvh/+8Id885vf5KKLLmLbtm38+te/Xm7TFSWgOj9Kwt4wZdu6ahf7PnUTO7ZvxyFShAIjJbJuZiZ76Oc9uQwET2s/R4ss6IkgvPRd0q/8lL1feJg7nz1dlJdZuSGXEnHnnXfOuu+DH/wgH/zgB8/a3t7ezr333ltMsxQrjXSMMuIkbGf3vPc4LBP55/mxLuCKZTZudvxxTdBjKZXpQrAH8tqN7fjJk/x89Ah/feuWeZ50jujN2vKjx4HXUFNuK8rLKA9doTgHpP4RPWWfZYhJ1QYAbKFTM+8vAVJKArFxQVce+uTGai8dPsq3nuhCq5MsAnpvH1NAe82aMmtRXkYJukJxDqQDAwBkHHUzH1DRQQ4j3njXMlo1N+FklmxeEywVcmGi9fGQrKBWBMnmJeFEka6L7qFbUn7KiVJTdp546EW7Q64gzoffca2TCWqCnnPO4qEbzQTszdRnesjlV8bfezx+DmpRFICxkySNLo7mm7nQo2Uj+WJFSjkOniky6xBD1JSfBx66zWZjbGxsTQuelJKxsTFstuLcoRXLQzakd4guq5/1mFjZOtbRz1h0ZdQl+CeJVVTF0GHsFKPmJsLmSlwZPzD1pldQgj1g0t7zW63D2MzFSRldUYuiTU1N9PX1sVKnGRUKm81GU1NTqc1QLAEZHiIhLZgcnlmPyVVuoHX4YY4EwkVbBFsM/tiZdr4qhg6MnaLXsI6ktRpL0oeBfPFuvqFeaLqEXPeTbLMMF+c1WGGCbjab563MVChWBJFBhqUXh3X2t5CpdjOmI3nC/cegdZbQzDIy2UM/7wU9k4RQL6esV2B0VSMSOSqIMFY0D70XNr+G4d5O1hmKJ+grKuSiUKwWDLFhRvBgn+Ojs6txGwDZ4ZXRrG3cQ7ebjWpRNNANSA6lqhHl2sJ2jQjgjxZB0NNxiPvA00KXrKdFFm+gmxJ0heIcMMeHGZHeOcvn3c1bATD6jy+XWXPij6WwmQ1UlVmIp8/zGLqe4XIkVY3Fra2DtFqL5KHrGS7S3czRbC3V6T7Iq0pRhWLFYEmMaCEXy+whF6PNxSDVOFZILro/lqHCYcFpMSkPPaxlKQ3IShyVjQC0WYok6HoOeszRwMlcHWaZnhD5QqMEXaFYLKkIpmycYenBMU+Dq0FLCxWJ7uWxax78sRQVLgsuq0nF0GOjSAR+yvHUaE25ms3h4iyK6n3xfYYaOvN6q4jxHjIFRgm6QrFY9CrR4XlCLgB+ezt1md6ifcReDP54Bq/DglMJOkRHSFs85DBSU+EGm5s6Y6g4aYvBHjCYGMh56JR6mqsSdIVihRAZBGAE75yLogAJdwc20nzo63dz2789XtIaC38sRaXTgtNqJDYtht4zFicYL1KGx0okNkrMVAFAXbkNXHVUEyxeyKW8kZFYllHc9P7+3bDj/xT+dVCCrlAsnske+jyCbqhYB8BY71EO9ofp8sWKbt5sBGIZvE4LblNuwkMfDCX48I9f5uovPsxn7j5cMtuKgZRy9htodISg0UOZ1YTTagJXDRUygD+WJl/oyt6QNix8JJIEBO4Nl4G1rLCvoaMEXaFYLLqHHjJVYjDMPcZt76V7APiHa7QhGPt6g0U1bTZS2RzRVJbfG/gSnzzxJgwpzY6//dUhfntwCLfdTH9gZfVuXyq3/dsTfOn+WTKMYiP4pJtat17wVVZHWXaMXF4STmZmfs65EjitCXpYyzIqm6N2YakoQVcoFktkiJTBjrTM72WV17aCwUwzQzgtRl7uCRbfvhkIxDK8wfA4Fwz+HFc2wBuz9yClpHssxnWbariso4LAGgq5+KIpDg2E+e3BWfqcR0cZypVr4RYAVy2OtF9/bgGvQyqq9Vqv6GAkkqKmzFbUWa5K0BWKxRIZJGSqmjfcAoDBCN5WDIEuLmr2lMxDjwwc5R/M38JftZvuiqt4p/FekqFRPhL+An8Y/hoVTsuU1gCrnQP9IQBOjkQZmT4GMB2DTIy+tIvacUG3ezHlElhJF3Zh1N+pfa9cx0gkWbS2ueMoQVcoFktkmJBx/gyXCbztEOhiR7OHI4NhkpnlL+oxnrwfh0jRs/dfOLzhj/GKKJb/uozX8ATbIk9Q4bQQiKfXTGO8A32hiZ+fOjU2dWdUmyLVnXJS7z4j6ABuYoVNXRzPZqlcr3noReqyOI4SdIVisSSDhCibNwd9gooO8Hezs9lDNi852B+a/zkFJhceIi2NuOo6SNTs4oncNkQyxIv5DZQlh6i0CT1+vDbSGQ/0h2ivcuK2m3nqlG/qzpjW/G8kX34mhu7QMl68osDFRXpFKhUdjIZTReuDPo4SdIVisSRDRHAuLOQCUNEO6Qg7qzTPvBRx9HxkGB9uqsvsOK0mPpD5EHdd+T/cmb0BQZ5GoYleoFjNqZaTRz7P+tM/5aImN5d3VPLkyWktuXVB90n3mRi6fVzQo4UNuYx1Qlk9gwkDkVSW1kpH4c49A0rQFYrFkgwRko6Fe+herYNoVbqfJq+9JHF0ER0mILy4HWZcVhMhXOyLV3Naal0g63Ja5o5/tS+MnnwQHvlH/jj7Ay6qs3HF+kr6gwl6/ZMyePSQy1RB10Iu9ZZE4UMulet5Rf+b72j2FO7cM6AEXaFYDLkspKME8/aFx9Ar9JbQ/i4uavJMLNgtJ+bkGHFLJQAOq2Z3py/GaVkLQGVa621SlG6Dy0U6Dnd/hIy5DI+IsVc+zxXrtN95SthF99CjJi8barV00vGQS6M1WfiQS0UHL/cGMRsFW+rLC3fuGVCCrlAshlQYgEDegd28wHxiTysgINBFS6WDwVBi2cfSlWXHyDmqAXDpedBdvihBoxdpsuNO9gGr3EN/4ssQPM1dm77IgKygrfdXrKt24bAYOT4cPXNcdIQwLi5ZV3tmcpDuodeZ44wV6qaWCEB8DCrXs68nyNb68qJNKhpHCbpCMRNSgu8E9L80dXsyCIA/Z194yMVsg/JG8HfR6LGTyUlGI3N/rC9kHDeeTOGVIYxlmjfu1AW9P5CgpsyO8LZhj2oNpFZ1DP3Ug9B6Fb+NbeBh642Yuh5GRAZp9NjpC8QnDov5BxnJl3PtpklDR8wOMFqpNsYKdu2zo1qGS66igwP9oaKHW0AJukJxNsOH4Utb4d93w3/fyLOHO/m3B09o+5JauMSXtS1c0EELuwQ0QQfoD8ZnPbRnLM7uz97PUyd9sx6zGHr7+jAKib1C6/Tn0lv+5iVaGl1FO8bQaSwmw+r10KWE0ePImi28eNpPT8vrQebhlR/T6LXTHzwTQ4+MDeDDzbWbqs88XwhwVOARsYJVin7nNw8C0JWvJ57OsaPFU5DzzsWCBF0IcbMQ4pgQ4qQQ4uMz7G8RQjwshHhZCLFfCHFr4U1VKJaJrscgMgDb3wgyxxd+9jBfefCElimhC/pYdhExdABvG/g7afSOC3py1kN7/HHyEp7t8i/lt5hgZEjrve2u1vp+j8fQAa3QxduOCHRTYTevXg89MgTpCEOWFgLxDJu2XgRNe+DQL2jy2umb1NZARkdIWCporXROPYfdi5sI4URhBN0c6iQnBX//hNa/Z0eztyDnnYt5BV0IYQS+CtwCbAXeKoTYOu2wvwF+KqXcCbwF+I9CG6pQLBv+TrCUIXe9AwBLSuvxEUllJwQ9vJi0RYDK9RAbpcGmCeZcfVOCCe2YQwPhc/wFphIY1gS9qq4FALPRgMWkvfVry23ap4dMnA5HbPVWi/qOAfByXPO6r1hXBVtvh6EDbLb6CSUyRJIZEukczowfh7f+7HPYKyjLR4ilc2RzS293XJPuY0BW8XhXBLfdTFuRUxZhYR76HuCklLJTSpkGfgy8btoxEhhfvnUDA4UzUaFYZvydUNHOU8OaYO/0agIbimfOCPpi0hYBqjcD4Aqf0hphzRFyCcY1UT08UJhsmJhfezvaJ4nY+MLouIcOsMkyOqWfi5SS3x0aIp0tfS/3efFpIbEHRj10VDupc9tgy+0A7Io+BkB/MMG+riHKRZzq+uazz+Hw4shpN9HIEgusMrk8DflBQg7tJnpRs6eoPVzGWYigNwKT5yX16dsm82ng7UKIPuAe4M9nOpEQ4n1CiBeEEC+Mjo6eg7kKRWHwRVMkZpurqaeaPaCtE/La9Zr4BeLpSR66A/sc4+fOonqT9n30KI0eOwNzhFxC+kf+gVCyICGQTEhvUOU6swjo1MMuNeU2LRwEdBhGprzeSz0B3vf9F7nrlYX5Z0+d8pWkChaA0WNIaxn39TCRqoi3Fep30Dp8P6B9Kuo83QVA7UyCbvdiy2r2L1XQA/E0rWIYc/U6vvjGC/nQDeuXdL6FUqhF0bcC35FSNgG3At8XQpx1binl16WUu6WUu6urq886iUJRNF76Ptz9UcgkCcbTvOrLj/GF+46efVwuo02YqVzHk/1Zspjw5AIABHQPXQoDMRa5KOppAZMNRo9pi3RzhVwmecmFCLsYYqOkhQ0sroltTsskD93TAsJAsxiekoP9TKcWwz+8QBt8P/4AL//880u295zwHSNe1kEsndfCLeNsvR2n7xXqGaM/mGCkTxN0p75APAV7BdZMCFh6C92gfwSPiJH3tHHH7mYubq1Y0vkWykIEvR+YfDtr0rdN5o+AnwJIKZ8GbEAVCsVK4fn/hhe+CT96M/927yv4Y2l6xmYIe4R6IZ8l7mrl+EiMhKUSZ1YTtqDuoefMZUgMi4uhG4xQtUETdI+WdTFbI6xgPDMREjm4xLBLKJHBlR0jYa3SMjl0xs9fW24DkwXcTTRk+wglMmTjQfjydjj0SwCODi1A0Dsf5fbMvWwNP74ke88Z3wl6jJpMXdZReWb7Fi06/HrzM/QFErQO3UcWEzTuPvscdi+GfAYHqSUvjCaGtJRFQ2XHks6zWBYi6M8DG4QQ7UIIC9qi513TjukBbgAQQmxBE3QVU1GsDHIZGDkMdRciux5jy8ufAbSwy1mMae1Oj2e0T5DCVY0tpXXrC+oeetaiLRctKssFtDi6LujRVHbWRljBRIYmr51Gj33JHnq3L0Y1IfLOqZ+IHZNj6ABtV9MWfAYLGRIH74ZQL+tHHwDgyGB47i6MUiIf+DQAzmyw8BN/ZmBKYVYyBJFBDqfrWF/josJpObOvaj20X817TPcwODjADakHOVl5HbhmiBCMN+gismQPPePT/o9sNeuWdJ7FMq+gSymzwJ8B9wFH0LJZDgkhPiOEuF0/7C+A9wohXgF+BLxTrpU+nIrVj+845NL83PoG7udyrjAe5vrNNTMPMtD7Vz8b8mAQYPM2YE5ovsl4DD1t0gZbLCrkAlC1CUI9NLu0RcbZwi7BeBqPw8y2hnIOLdFDv//wMNUiiM07NcTgshoxGwVehy5+296AJRtlr2E/4tCvALiYw+xochOIZxiZqxDqyG8QAy8xJsuoIMxoIXuhzMBTp3xs/7v7zvQ592ne8LFc/Zl2uJO59hNUygDv6vk4bhEnvO3tM59Yb9DlETHCiaXF0EVAC+2U1W9Y0nkWy4Ji6FLKe6SUG6WU66SU/6Bv+5SU8i7958NSyiullBdJKXdIKX9XTKMVikUxdACAb550EfJspQEfF3hz+KKpsz1PfyeYnTwxaGBTXTmm8hpEbJQyq2nCQ0+dq6DrC6PtQmuENbnYZTLBeAaP3cK2BjddvtjE/M8FkU3Df98IB39BMpPjR8/10GAKY/fUTTmswW2no8p1ZoRexzVkLG7eYnwYR++jxKw1VIkwH9iuvfaRwTk+Kbz8AzJlzfwsdy0VhOkdi85+7DmQzub59F2HGAxp1+vwQJhEJsfL403O9JTFg+laqlwz9BtvvYITzovZJY5zKl9P/UU3zfxCevm/RyzdQ7eETzMiPXjcniWdZ7GoSlHF2mfoACksVLdt547btJq39bKLVDZPdLpY+juRFe283BtiV4sHXLUQHcHrME7E0FNGbXFxUVkuMJG6WJ/uBmBgNkFPZPA4zGyqcyElixssHR2Cvufhrj/nkaefJRyL48pHtN9jEv/31Zv4yR9fdmaD0Uy0/WZuMr6EIZ/mJ973AXCV6QgAR4cis79mIkDc1cKI9GASeYZHhhdu7wI4PBjmO09188Bh7bzjnxYmbjK+42AwczDupXJyuGUSr6z/UwD+x3ATTRWz5INP9ESPLTmG7or1MiDq5p05W2iUoCvWPoOv0GloxVtmh7qLAGhNa4MHzgq7+E8RcbYQTWW5uNULzhqQOZrtqYksl/i4oC+20VJFOxhMlIVPYTEZZvTQpZSE4hncdhPlNjPA4jz0uF5dmo7S/tiHuaxKD0tMSlkEsJmNeBxTxU9ufT0AUWsdX/NdxJipFnv/kzS4bXN76OkoCeHAJ7W1hcBIYctQTo9pN7SxwBjc/3dEA5qwHx3UbzJjp8h7WgmnBZUzeeiAse1yXpX6PC/Xv3n2fPBJDbqWOujDk+xjxDxDJk2RUYKuWNtICUMHOJhrodJpBWcllDdSG9c+pk9ZGM1lIXCafqEV4Oxo9kwIYYs5QjChC7pBE/RFh1yMZqhcj/Ad1zJdZoihJzI5avJD/MWLN+INa95xfDEj6xJaimXognexKXuMb6Q+pm2f5qHPhHPz9fTLSr4Tv5yRaIZE4xXQ/SRb6lxnxHMmUhHiws6YXlsY9Q8u3N4FcFrPRqrtux+e/Aq39P0rAEfGs28CXaTKWwGodM3soTd5HRyXzWxtnCN9UI+h15riS/PQMwm8OR9B2/RyneKjBF2xtgn1QTLIK9mWM2/2ugtwhzSxnDLMINwH+QwnsjXYzUat14cu6I3mKJFYAtJRYsKJEGA1ncPbp3oTjB6lwWOb0UMPxjNcbTiAJRejPKot0CZnK4CaiYTmofeseyvvSP8VmTJdVCrnz7awWm28zfpVfuJ4Gz/4o0tp2vlqSPi5qnyEU6NRUtlZ7EhFiEo7ft1DT4QKG3Lp1j30puDzAOxNPMhew35Oj8WJJjPg7ybq0FIWq2YR9PXVLpwWI1etnyOb2mQBi4sqY2xpHnrgNAAxvUp0OVGCrlh5RIbg4P8U5lz6gujhfOuZN3vdhViDp7CRYnRyyEXPcNkX9bKxrgyjQUx4tnXGENm4XkWIE4fZeG6l3FWbtK6LLsHw9Gn0aIK+26B9erBJTfDjixF0PeQSli4ey1/Eqdf/L3z0yJlK1Xn4nw9ez/3/93qu2lAFLZcCsMvUSTYvOTKTly4lpKNEpI2YSQtZ5COFzVjWPHTJpsQ+2HgLXTTwOeu3sZLm1OluSEcIWLUbV6Vz5pCL12lh/6dfzXWba2bcP4HdS4VhiR0X9QyXjLv13M9xjihBV6w8nv0a/PzdMPjK0s81dACJ4KhsOfNmr78QIfNsFr34Jqfj6Z7V034XW+q0TBb0/O0qEUakJpf9n+OggupNIPNstowyEkmdNegiGE+zW2iCbslpoYbEokIuQQDGpLbw57KZoXzhsdxKl/XMEAZPKxgtbDKPYjMb+NGzPWc/IZuEfJZgzgoOraDHlPAVpLnVOKfHYrSJIWqkj0zHjXwu/SYa5TAXiVMMdmqftIaN9br9M3vogHaDng+7F4+ILinkktNrGfJ6j5zlRAm6YuUxuF/7/sK3l36uUC9pWzVxbJNCLhcCsNvWNzWGHuhGGswcS5SzaVzQbW4wWqiUAcrQPvqH8ksRdC3TZT195PLyrPmVCX8fLQbNw7XktNdLLkrQ/WApI5LR3trltkVm4kzGYISKDmyhTt54cRO/fLn/7MEcKS1FMZC1Uu6ykzK78RJmaIZPH+dCNJXFF01zg027yfV5L+Gl/EYAdlt7CA8e17YLLS1zxrTFxeCowC0jS+rlkho5SVjacbqXv72JEnTFykJKGNIF/cDPIDXHYtxCSARImt3ApDe7pwVsHnaauqcKevA0CUcDeQxsrtObhwot7OLOBykXmscckg4cCx0/N53K9SAMNGY1b3e68FkGnp/42ZzVXm9RIZdEAOzeCUFyLUXQx+0dO8m7r2wnncvz/WdOT92vj+TzZSx4HRZy9koqRHjqUOYlMJ7hcrPjOAOygpciFYziIWWv5TJ7L/mxTkDQlavCZTUtfcSbo4ryXGBpHnqgl35ZTWXZDEVORUYJumJlERnShvhe8CZIR2H/T5d2vrifmFET5wkPXQhovJgL5Imp8yMD3YyZtY/um8c9dABnNc6Mn3I0gfXnFjncYjJmrbthZaIbgMHQVEF3j75AQlqQjkoMmSgWo2FxIZe4HxxeosksRoNYfGrldCrXg7+Tjko7N26p4QfPnJ66OJrWPPTRtJkKpwWDq5oqEZ4y8m0pnB6LI8izPf0KT+e3cUBvhZCu3s5m2Yk92oMsb2QkPne4ZcF4mnFnRoim0uc+9zU6wqh0T21BsEwoQVesLPRFTHa/C+ougBeXGHZJ+AmLMmxmA47JhUDNe2jKdhOPBM5sC5ymV9ZQV27DO/nN6KrFkR6jXGje4khmkZ0Wp1O9GVdYK1efvjBaHdjHfrkeYfdCKorNbJi9ze9MJPy6h641+FpyD+7K9ZDPQPA0r72oAX8sTbdvkljrn6CGUpqHbimvpZIwvXN0k1wM3WMx9ohj2DMBnshtZ39fEABD406qk6fZIHtIlbUwFkvPWlS0KDwtGGWWGoJEzzHsYoyPMoqnMPYsEiXoipXFkL4QWrsddv2hJvDjIn8uxP0EpOvs7IemSzAgaYwd1h4nw5DwcyRVweb6sqnHuqqxJIZx6zH0F0fybGso55yp3oQx0InVkGdosoeejlMTP8Eh0xat1W06it1iXKSgB8BeQSSVpWyp4RbQOkQCjJ2amIc6XoIPTMTQR1NmvA4LBlcV1YYIhwrUF/20L84HbPcg7ZXck7+UQwNhrcdOy8UIJFsNpxk1N+CLpmctKloUbi3VsEmMnlumi5RYUj5Gpacw9iwSJeiKlcXgfm2Cjq0cX9tt5A1meOXH53YuKSHhZyzvOjs/uWk3EsGW7FFt0TGoxYb3RdxnFkTHab0KY2KMtxkfJI+BYNYytef2YqnahMhn2OkMTBX0yCBGcvisLWAtg1QUh8W0+JCLHkMfb5G7JCr1wQxjJ7UpQDDtJqQJegwbFU4zOKspJ8KLXaPnHrKYRGboMFfLFxGXvg+L1UEqm6fKZcXYuGPimG5Zw1g0NWsO+qLwLFHQkyFM+TRjlOOxm5duzyJRgq5YWQwdgHotC+XTDwzyYG4Hcv9PtSrOxZKKQD7LcNZxtrdkcxMqW8fFhuNa5kagG4CuXPXU+DnAhW9Ctu2lzTBMWNoxGoxc0r6EgQV6TvhOx/DURdG41qY3Y6vUPfQINrNx4Yui+Twkg+CoIJrMTrQOWBKOSi3Tx3eCmjIbQkyL++uLohHp0MJUzmoMSEyp4NztAhbItf6fkhZWuOS91Oo3lJpyK5TVa20ZgEPxSj3kUgCP2KMVKDUJ36wdF6WUsxdZRUcAiJurlr2PCyhBV6wkkiGtKKPuApKZHA8fHeHnmasQsRHofHjx59OrJofS9hnjmbHqi9lpOIkvkpjIQR8z17N3w7R0MyEQt/8rCSxEpIOLmj1L836rtLS7zabBqYIe82kv56gAq0v30I0LT1tMhUDm9ZBLZukZLqAtIOuZLhaTgSqXdaqHnprkoTssE7noFSLMM51jS3rpaCzKq3OPcqz2NnBWUluuCXZNmU2zq2EHAA+POsnlZWEWRc12MvbqGT30ZCbHH37rOXZ85n42/+29M4/bi2pVshlHaeb7KEFXrByGDmrf6y7iyZM+YukcD+d3aFkq++5c/Pn0qsm+pH3GeGau8RLKRZzkwBFGeo8Rlg7efPWFM+cyV3TweduH+a/cbWdmVp4rVhe4m2mXvQyFkmda+MZ1QXdWn4mhm43E0wv8dDLemMuuZbkUJIYOULkBxrRmZvVuG4OTb0KpCBJBHOuEhw6wzZ2aGGF3rhw/egiryGJqvxzQpysxaShHwy7yGDmS1P4ehYpZ58ubNUGflrp4eDDMo8dHubDJjZSwv28GQY9pHjquurP3LQNK0BUrh56nte8NO7j34BBlNhPXbWvi7vyVyKN3T3iwC0b30Edzjhnjq5Z2rX1s9Pij9J46woCo5T17Zx8Ztr/8Wn6Qu4nLlyroALXbaEkcJZ7OERnvpqj/fqay6gkP3WY2ksgssOpSrxLFUVG4GDpoHnq4D9Jx6sptDE1eFE1HyRgdSAxamp4u6JdU5Xiua2xJcfTeTm3ma3PHFgDqpgv65R/gpeu/TxgnAFUFyioR3hbdQ596Iz2mtxD+zOu2YzEaOO2foa2xHnKxuOdvhlYMlKArVg4n7of6HWTtVTxwZJgbt9Ry6wX1fCN5HSKXhpe+B0DPWJzQQgo/4vpwZ8pm/DjuadrCkXwLOzu/Rn3qFM7adXOKoNdhwWoysKvFe26/32Ta9uJJ9FDHGMN6CCMbHSUurTjLysBSBtkELrNceMglccZD17JcCrQoN97Ya+wE9W7btJBLmLRRE1SPwwxOLdSwzZMmnMwubB4pQCYJqSiheGaiR31wUEvtdNVqN9nxRdlqXdixldNw4fVnzCyQh26qaKNBjBGOT62KPTYUwWEx0lrhoMlrp9d/dq69jAyTlkZcnuWvEgUl6IqVQtwPfc8Rbr6O7zzVTSCe4dXbarl2Yw3dopnT5RfDC98mlU5z+1ef4LN3H57/nLrABWdKWwRsFhOjr/4qHlOaBuGned2WOU93x+4m/uJVG5dejQjQcQ0AVxoOTcTRg75B/JTR5HVoHjrgNqYXHnLRW+emLW7S2XzhQi5Nl2jfux6jzm0nnMye6dGeipIw2HFZTVhNRq2nuDDQ7tB+pxe6A7OcdBq/+RB897W853vP86c/eJF8XpL3d5MRlonwxVkhF7QQkFvPJilIDB0weJuxiiz5yNCU7UcGw2ysLcNgEDRXOOiZQdDToUF8uKkptxfElsWiBF1RXLqfgKP3EE5m5hamzodB5vnDxz189n+P0Fxh5+qN1bgdZi7tqOBbqRsg1MORx35BMJ7h4WOjcw8uhomYchDXrG/2q6+8GtOtn9ceVMzdYvbm7fW87+oCDf2t2UbOVsEVxoMTWSNjIwMEKOeGzTVaDB1wG1MLz0PXf9+o0LJ0Cibonmao2QrH75uY2TmxmJuOEseO16l/GjAYwVFJWTaA0SDO7v0yGyOHYOAlDKOHefyEj3sODlKTGyLhaACDJlO7W71ct6laGzyiI4Rgc10ZQnBmPuqSf1+tS6Il0jexSUrJseEIW/QahdZKB6fH4mf9D2ZCw/ikW8vEKQFK0BXF5ZHPwW8+yLu+9Rx/88uDsx934n4SJjevyHX84v1XcP9Hrpmo7Lzj4mZ+GNpOyl6D4ZUfANpgijnHogEk/KRNZeQwzp3StusP4Q9+BRe+eZG/3BIwGKD9aq40HGI4mCCZyZGNjGJyVeO0miY89HJDcuF56Ak/IAijPbdgMXSADa+CnqdptGutEibCLqkIEWmnYvL1dVYj4j7cdrM2WHshhDTxvDr1KACfvusQTcKHqbJt4pBKl5Vvv2vPWYvWV6yrYn21a2HdFBeCnotujfVPbBqJpAjGM2yq1QS9pcJBJJk9K/Qno8OMSo+WiVMClKAriktkEGKjRPoOc2JkluHB+TycuJ9DjkuoczvY1eKdEta45YI63E4Hzxp20Bh+hWs2aHHax0/M03c7ESBh0io65+yrIQSsuw4ss8yaLBLGdddSJwIMdh3k3oNDuGWYylq91a1F97JFikxOkllIO9pEAGxuohnNayxYDB1g46shn6Ut9BwwKRc9FWUsY6G9ctK1c1RCzIfHYdamPM1HOj4RLnqd8SnKrEZ80TQthlHs1fO3oP3z69dzz4f2LvpXmhW3losuA6cnPPDxnPpNetO2Zn0u6fSwiyk+yqh0T6RYLjdK0BXFQ0oIa+PI9ohDZzWimmDoFYj7eEzupL3aedZuq8nImy9p5p5gC5UizAd2GNhY6+LxE/NkvcT9RA3llNlMWM5lulCxab8aAEP3Y/zlz1+hUkSoqtEFXffQywxaRsmCFkb1KtHx/OmCeuhNe8Dmwdv/CMBEpks+FcaXsdBR7TpzrLMaYqN47GZC8QUIeljzhCONV9MkfHxqRxQnCbxEEN75h0QYDAKzsYB/X4uDhKWCsuTAxPi78QyX8aKzVv0GNr4fgHwea8rPKMpDV6xFUhHIaKldlxkO44umSGdn8DT7XgDg3kg7bZVnCzrA2y5r5WWpFeTsEifYu6GaZ7v8cwtdwk9IlJWkSdKCqOiA8kb+pG2YcmMGOykMepbIeAzdiXYTXFAcPRGYqBKFAsbQAYwmWH8DplMPUOkwTdyc88kIUWlj3VmC7sPjsBBMLCDkoodbTra/jaQ0c136Uf7mCt3j9yz/1B8Ag7eVVjHCY/qnwGNDEWrLrRNN25q9M3joCT8GckSN3nPvxrlElKArikdE885TBjuXGY4AcsaxawzsI++o4njSTXvVzILe6LFz49V7SZlcmPqfY++GKtLZPM91zVG8ojfmmj7dfsUgBNRupynbw9MfvEjbNi7o1nFB1zzhBcXRE/4pvdALKugA626A2AiXuEa1GLqUGNJRotjpmPzJylkFqRCVNgjEFuCh64LeY2zmgfzFeLv/l7eu15+3AA+9GFjrtrDJNMBjx7VPgUeHImypdcLT/wGB0zitJqpclqmpi3qVaNpempRFUIKuKCbhAQCeslxBlQizXvRPKXVPZnJ84hcHSPe9RMS7DRCzCjrAX968FWvrpdD7HJe2VyIEvHh6jrS4RICxvKskfakXTPUm8J3AktTDR+Ml43oM3b6YuaJxP9grJvK4CxpDB2jYCcDFll7NQ8+mMMgsMexT/276TanBHJu3XuCbT3Txs4efAeB02s1d+SswJsYmag5K5aFTs5kqGeDQqW6ODIY5MRLhLcYH4b5PwPduh+gIe8qDrOv5ubYGBBOCLp3zzC0tIkrQFcVD99B/ENMqMi83HJ4SR3/k2Ai/eO4kJt8xBhxaw6q5BB2A5kth5DD2fPTsviKTyWUgFWYk69AKXlYq1Zsgl4L+F7XH0zz08UHR83roUk6aVlSEGDpoPWhMNraILu3GrHdaNNvLp+bm69WidaYI0VR2zgXdF0/7yQX6yDtrGYxJ9lsv0ZqBnXwAzM6J3jDLTrVWk9CYOc2b/+tpGm1pbhr+JtRs06pBv3E9/+r/E94b+n/Q+ZD2HL1K1FhemrJ/UIKuKCa6oD+ZWU/UVscew9EpZeO/OzTMVnEaAzmOiXUY9YKNOWneA0jof1ErQ59tdqWeNTGYdmhNo1Yq+oxRup/Qvo8LmMkGwogtr32kT87noQd7tM6HVRuIpLJYTYbCLwQbTVCzlY5MJ/5YmqFRLb7sLJtWOat/yqg2aJkhc3npo5EUDWKMpKOO0UgSr7sMttyu7fS2amGpUlCj/V02G/tJZvL8ePPjGBMBeMN/wh3fhVSYw7W3kZRmcsfvB7QqUQCbVwm6Yi0SHiRtLieJFVm9lXWGYQaCepl7Ls9Dx0bYYeoG4N5APc1e+/zZCo0XgzBAz7PUuW0zx+RhoshmJOuYOn1opaF3XuT0U9r3cQ9dCLC6sOYWOFe0T59F2ryHSCEbc02n/kLqEscByWMHugBwe6YJuu6he9EEPThHpsu4oAdNNYxEUloV6AV3aDtLFW4BLXXR4uLNrTH+84711B39Hux4G9RfBBtfBX91muN7/oFn8ltJH/0dAJnhI0SlDY97Ca2Vl4gSdEXxiAwSMlVhMRpw1K2jVQwzFNQ89Oe7AwTjGd5Y78Mny7m310jbfOEWAFu5lh0yeoS6cttZqZDBeJp/e/AEuZjWujVAWeEqCIuBrRzKG7VOiwYzWCdNQrKUYdE99LlCLs93+3nm0XtIYOOe4Qq902KRwkx1F2JIhXhVY5oHXzkBQGXltLCIflPy5LVuhME5iotGI0nqxRiDspKRsC7obVdpN7rGi4vzOywEIaB6ExdYBrjBdAByadj1B1P237ilhpcsu7GHO4meeg7T4V9wV+5yatylSVkEJeiKYhIZZFB62VDrwljRjpM4kZC2+Pe7w0NYTAa2yFOcMKxjvgXRKXjbwd9FndtGKJGZkrr4wJER/uX+4/T2a5kTAenCu5Jj6HDGS3dUTg0xWF2Yslra51xpi39+58u4Rl9mv1zHnS8MTMwTLQr1WjbOW5oCpONabnZt1bSsDpsbDGbKckFgdg89lspiTIdxihSdGTej0ZRWMm8wwvufgWv+sji/w0Kp3gIjR+HYb7W/zXhPGx2Pw8KrXvd2ACI/fjeGXIrv5G6muqw0RUWgBF1RTMKD9GbcrK9xgbcNAFOoGykl9x8e5vqOMgy+YySqLwAWsCA6ToUm6LX6G2fywui4NxgLagtUQela2SEXOBNHHw+3jGOZJOizeOgjkSShcJCthtOk6y/huW4/vmi6eCGXmq0gDFxq76NcaJ+2GmrPHgiCswpHNggwa7WoFm7RQmMvBLQhFRMFOYbS5HFPoWaz1t/82D2w4dUz2rT9gp2E7U3UZ3rZZ76I47K5ZEVFoARdUSzyOWR0mK5UOR1VZwS9LNHPvt4gfYEEb6nrA5nDu/FKADbUlM1xwklUdEA6QpNVC0dMXhgdH0qQDGkLdv6VHnKBiZF0Z2V0WF0YM3ML+qGBMBeKLgwyh3vjFaSzeQ4OhIrnoVscULURp/8wF9VoAlfhnSFm7KzCmtLCXrOFXEajKeqFdszxhBuY2kmx5OiZLqSjsOnmmY8RgrLttwDwb7EbAUpW9g8LFHQhxM1CiGNCiJNCiI/PcsybhBCHhRCHhBDnMF5GseJ54NNw/L6FHRsdQcgcQ9KrFZ3oC1zNjPCdp7oxGQSXpZ8Bs4MdV9/OT//4ci7rWOBiklfr79EotSyayQuj4xkVMjxI2uQige1MJ8CVyhweukEX9NkWRQ/1h7jYcByAdTuvw2wUSFmEHPTJ1F0Ag6/whq1avF9YZ7gRO6sxJcYwiNlDLqORFI1CC8ENSO1mVqouhTOiZ7pgtMC662c9TFz2p2T3foxo83V4Hebi3UwXwLyvLIQwAl8FbgL6gOeFEHdJKQ9POmYD8AngSillQAhRusx6RXFIhuCJL4Pzh/DBl7Sp9HOhpywOS68WSrG6SFsrac4O8439g1y5rhLbqftg3fUIi4M97YtojFWhCXpVZgBwT1kYHf94b44NEbFo/4Ye+2rx0KcJurUMkdLG0M3W4uBgf5g/sHWCZwNObw07W7w81+UvXsgFtIrRAz/Du/+b2mOL6+xjHFWIsZNzlv+PRjQPPS9MjOIBKGm44izKG8Hqhqbdc/+/V67DdMMn+c7eHKORFKJUqZYszEPfA5yUUnZKKdPAj4HXTTvmvcBXpZQBACnlSGHNVJScwf3a99gIPPn/5j9eF/QhWTFRFp7ztNIiRsjmJW9v8UNkADbftnhbPK2AwB7pwWU1TYmhj3vojtQIQWMlZdYV2phrMo4KuOwDsPX2qdstLkhHsFtmnyt6aCDIBZycWLC7ar12UyiqoF/0Fi2FLzKg2WiY4fo6qyE2hsduntNDv8DQjazoIK9LUSkXFM9CCLjj23Dz5xZ0uN1ipKVyeTt2Tmch/+mNQO+kx336tslsBDYKIZ4UQjwjhJgl4KRYtQy8rH2rvBye+neG+07x/h++SJdvhrmKMFH2L8vqJvqaGyvaaREjmAyCvflnQRi1tqyLxWzTvCd/F7Xl1hlDLu7sKD5DJZ6VHm4Z5+Z/1NL1JqPPFbWbjSTSZ1dbhuIZ0oEBynMBaNgBwFV6a+GifuwXAm77CrRepf0dZsJZBZkYNfbcrIVFgVCYPYajGNffQJXLittuLsw0qEKy/gao3lhqKxZMoVwXE7ABuBZ4K/ANIYRn+kFCiPcJIV4QQrwwOjpPL2vFikIO7qNfVvGmgbeQz2V46Huf5Z4DQzxweHjmJ0QGyWHAU90wsclc1U6DGOOa9R4t3NJyueadngsV7RDQUheHpgm6gTwV+QBDsmJlV4nOh8UF+Qzl5vyMIZdDAyG2G7TiHup3AHBRk4f37m3nhi1FHlJsssA7fgV/9LuZ9+vrAU2W2KxDLirGnsdGGtbfyIYa18QQaMW5sxBB7weaJz1u0rdNpg+4S0qZkVJ2AcfRBH4KUsqvSyl3Syl3V1eXriPZWub0WIznu+foQHiO5Ptf5kC+nTFTHY9mt7E39Tguq5Ej04YAhxIZXjztRw7so5da2qvdE/tERTsmkeef1h+BkcOw7fXnbpC3Dfyd1JbbJoYsg5blUiNCmESe44myldtpcSHocdsKU2rGkMuhgTDbRTcSAXXbATAaBJ98zVYtVbTYGM1g98y8T68WbTTHZg25rAs9QwYztF7B3962lX/8ve1FMvT8YSGC/jywQQjRLoSwAG8B7pp2zK/QvHOEEFVoIZjOwpmpWCj/+uBJ/uzOlwp70mQIY6CT/fl2/vo1W/C13kqTGOWNdaMcHZw6Bu67T3Xznv+8D9n5CPdkL5naVlVPXax58u+hrAF2vv3cbarogNgoLc4cI5EUubxESkkokWGXR0tnPBpbBUVFc6EvNnpM6RnTFg8OhNht7UFUbQTLAnP4lwtd0GtNkVmHXFyUfJFO5w6wONjaUM7FraUrmV8rzCvoUsos8GfAfcAR4KdSykNCiM8IIcZXce4DxoQQh4GHgb+UUo4Vy2jF7PiiKUZ1gSsYg68AcFC20+y1c8fb/hgMZm42PM3JkeiUbnrdvhi3GJ/HIHP8Jnf51Ek2uqCTCsE1HwPzEiaj65ku60w+snnJWDRFIpMjk5Nc6Nbz02XFyi8qmgu946LXmJyxUvTkSJStonuienNFoefUV4sIkRk6LuYDPbTTR3/VlaWwbs2yoBi6lPIeKeVGKeU6KeU/6Ns+JaW8S/9ZSik/KqXcKqW8QEr542IarZidYCJDXrLw4bwLQV8QPZBv14Yt272w7nouDD5EOpebsjDaG4jzWuPTnMw3cES20DG5+rOsXsvprehYmncOE7noTWgx/KFwcmLxbZNDa+s6LCtWflHRXNg1j7VSRM/y0KWURMcGqcyNrkxBd9WCwURHVPu0GJ62MBo/onUoDDUUcBaoQlWKrjXGq/J80VThTjqwj5i9gQDlZ4p0tr0BR2KQvYYD2gDdsVPw6BfZ6HuQSw1HeMRyNRaTkUbPJC/cYIRbvgBv+LoWf10Kuodel9WWc4ZCyYlYbZMxQFoaGaNsdXvoetiiUoSnFhb5ThI7eA+tmZPa45Uo6BYHXPFB1g3ezTWGVwhMC7ukBw4SlTYsdVtLZODapHQlTYqiMC5qvkgaCtWWefQoI44NEEDz0AG23IZ8tJ3/9H+Fp/dl4L5vQ8LPP+hPufS29/B3qRoMhmlFFrvfVRibbG5w1uBJnAYuZCCYoNyu3STcWR9jogKJYXXH0F1aYZSX0NQsl/s+gevE7/hbk54yWHdBCYxbANd+nNiBu/in4DcYDv0fmLRQKwNd9MoaqlVmS0FRHvoaIpeXExPfR6Oz9Ak/FxIBQqIMu9l4ZvittQzxrnvwG6u4qftfwO6h/y0P8L70R3h2xz9ywY5LeNulRe5nXbURW/AUVpOB/mCCaERr1+pIjhAya97tqk5btHlAGPHmg2di6Pk89DxL2uJhg6GfdHnr7JkmpcZkZWDv52gQfqzH7wa03Pn/evQUeX83PbJmZRUSrQGUoK8hQokMUl8L9UUKGENPhgnmHWfP5ixv4Bvr/p2vGf8P/NH9dBrb+F3+EuSFbynca89F9UaE7ziNHhty6CDX/+oSLjccwpoYImbVy/5Xs6AbDOCsojwfJJ7JIaWE0SOQCvFY+0f4m8y7yF/3N6W2ck5c668gJq2I4UMA/OzFXv7pt0coi/cpQS8CStDXEJO72hUshp7LQCZGIGebcdhyU1MLn4vdRlCU0xfQ2qnOO0auUFRthGSQre40tWPPYZBZ3mW8F1NsiKxTizet6AHRC8FZQ1kuiJSQyuah52kAXmIz99pfg23nm0ps4NzUuR10ihbMY0cAONgfYosrgU1k2LNzV0kbWa1FlKDPgpSS933jIQ798vPwndtgYF+pTZqXyQtPo4US9JSWZ+7L2mdcYNzaoHXc298Xotcfx2QQy1fxpw+GuMg2TGNcE4wbDS8hMnHcta20VznXgKBX4cxqhWLxdA56ngVXHfsi7uW7cS4BIQQ+5waq4ydBSg70h7imWsuKuujCHaU1bg2iBH0WRgNhPtX3Xra98o/Q/TicuJ8TwxHtY+8KJaR3tTMZBKORAgl6MgjAcNpC5QzieHGrF4vRwOMnRukLJGjw2DFOXwgtFrqgbzAOsjl/kl7bJtBfevOGjTz8f69d+Y255sNZjSurDbzu8sWg5xlouZSeQIKWVSDoALnqLbhlBP9wL52+GDvLgtqO8boERcFY5f/txSNw8Hc0CR8fyX6AvLOWodNHuenLj/H0qZVbLxWIaR56W5UTX7RAMfSkVto/nLLO6O06LCYuaffy2HEfvYE4Td4lFAstlvJGMDtYlzhEh2GIB9jDM8aLz+xbC7hqsOmDIk6dPAahHnJNlzEQTNC6SgS9vOVCAJ55+nGkhA1mHyC0QcyKgqIEfRYsx+8mLB3cnb2UgLWR4IA2ELfHHy+xZbMzXky0ocZVuBh6ShP00ezMMXSAazZWc2w4wtHBCM3eZRQZgwGqNtAw+AAAD0ea+bXrTZrnPt5jfLXjrMKQTdDkzJPqfAqAEc8O8nIZ1yqWSNPm3QD0HH0OgHo5DOUNWtdMRUE5vwU9FYHe5yARmLo9l6Fu8CEeyu+izOngYMJLWUIrYClowU6BCSUyGIQ2m9MfS5MvRPl/UksFjMgZslx0rt6opQgmMrnl9dABqjZi1Odu7su1M1C+A/7s+XPv4rjS0IuLLqvN4xjdByYbp4xtAKsm5FJf38gIXqrjp6gps2KP9qpwS5E4vwX9oc/CN2+Cz7fBz95JNJXVutp1P449F+YF59Vcv7mGfRE39YzhNOYLF5suNHE/1YOP0GhLU1NmJZeXhSn/10MuYeyzltFvqi2bmKO47F6jHkfvknWEcU4UF60ZnFr65a7KDDXJTvJVmzkd1EJrpR6msFCEEAza1rFZ9HBBoxsC3UrQi8T5LeinHoLGi6HjOuSJ33H7vz3On935Mhy+iwQ2Rqqv4MYtNfTkazAIyS5PpHCx6ULz7H/xjq6P8Yh8N9d0/jNQoEwXPeQSlk4qXTMLuhCCqzdonmQpPHSAk2YtxOJec4Ku9RXfXJ5io+gl4Oygxx/HYjRQu5LGtc1D0ruZ9WKAnbUmbZqVEvSicP4KengQfMdh6+th062IdIyIb4AnT/qQJ37HY/IiGmsquHpjNe7G9QBssvpXroceGSAqynjZcjFtnT/CTrIwxUV6yCWKfc4UwDfsbKTBbWND7TyzRguNPmB5yKX1BFl7gq7dKNeLAWpFkBM0c8+BQbbUl53dVmEFY2+6AKvIcHPs19oGJehF4fwV9O4ntO/tezmQ1Fp9XlcVxpqNIML9vJTtoK3SicNi4lN/8BpAa9VasPzuQhP3M2qo5AnP6xAyx4WiqzDx/mSYjNFBDuOcZfRXrK/iqU/csPyCWrMZ3vQ9TjT9PgCeNSroZUPPAPDt43Z6/Qk+fsuWUlq1aLbu/T0izlbWH/yytkEJelE4jwX9MbC5kbUX8C8vaH0yPnm5hY2GPgCOyybaxlu/uurAaKWFEXwr1UOPj+GXLnxuLUVsl+FEYQQ9FSJpdGEQK9j73fo6aiu9wAq28Vwx28BajjitVYgeyDTwhp2NXL6ussSGLQ5TeQ1lH34OrvsktO2FGtVlsRicv4Le9Ri0XsVTXUEeG7WTEybc8R6u8Wg5vydkE23ji04GA3haqM0PEUllZ5zvWHLiY4zmXFjKq5EV67jYeLIw4aFkiLhw4HVYVvRH/PHY/ZoTdJgYuJw2Okk56vnrW1eXdz6B2aYNNnnn3RPDOxSF5fwU9GCPttLevpdvPtFFhcuGqGiHsZPscY0Qk1aGRdXUXt7eNirSgwArMo4uYz5Gcy48DjOieQ87DScZjRSg42IyTFSs/BL6Cxrd2MyG5ZmludzomS7m+q08+YkbVEMrxaycn4Kux8973Rfz0NER3n5ZK4aqDeDvZD29nJCNNFW4MBknXR5vK2UJLRyz4uLo+RwkAvgp1/p/N+2mkiAD3cf4zpNdDIYS537uZIjQHDnoK4WOahdHPnPz8i/KLgd6pouo2YLNbCyxMYqVzPkp6IOvgNnBD7qcmI2Ct1/Wqo1F83fijZ2aGm4Zx9uGOROmnOjK89ATQQQSv9Sn3DftAaAlcYhP/+Yw//C/R8793KkwwdzsOegrCSFWbkhoSegLo1Sv0lCLYtk4P3tXjhyGmi3s74uwtcFNlcsKlesgm8SQTVLR9mbesKtp6nP0VfkWMbLyqkXjWtw/IMvwOMzagpPZyed3Junrr5xoa3tOJMP4c7bVPcpttaNPLqJGCbpibs5PD334MLJ6C4cGQmzT279SuX5i9w1XX8PtFzVMfY4u6M1idOV56HEfAH7KNE/aaILGXYjeZ2nw2BkOn2MsXUpkMsRY1qbdKBSloaJDG65du73UlihWOOefoEdHIO4jWLaBcDJ7RtAr1p05Ri9WmYJHG6e2yTpWMg89GE/P3L53koc+keXRdhUM7qfVkWYkkiJ3Ln1dsklEPkMw71h7+d2riQvugA/uA1d1qS1RrHDOO0GP9OwH4ASaQG+t1wW9rB7MDrCUgbvp7CfaysFewXqzryQeejiZ4YrPPcQPn+2ByDBMFnZd0MfkpCn37VcDkguyh8jl5bndhPQ+LhHsykMvJQYjuNdIO2BFUTmvBP3u/QN85c5fAfBSohaDgM11uqAbDFocvWYzzLa45m2jRYyURNA7R2PE0zm6n/of+JdN0PnImZ26oMdMbpzjQ5wbd4PJTkf0RQAGQ+cQdtHL/sPSiduuYugKxUrnvBL0/368iw30EjN5eN5nZl2168wUe4Db/h/c+s+zn8DbRn1+uCQNuk6PxfAQ4Y9DXwEkjB47szM2RlLYqPa6z2R6mCzQchk1vmcBGDoXQU+d6bSoPHSFYuVz3gj6gb4Q+3qDbDX1cSjbyP7+SQui4zRdDA07Zj+Jt5WK7BBjkSVkjZwLPc/gPPQjvmT+T9xEyQkThPvO7I+PERLlZw+XaL8aW+AYlYQYOpdcdH38XEQ6VkXaokJxvnPeCPr3nu7GaRFsNQ5wKNvEaCTFtgb34k7ibcMoc3gyI8RS2eIYOp1UFL77Wm488f9xvXEfP3K9gyFRA6Gpgu7Lu2iumNa6tv0aAK4yHWUofO4x9DBO5aErFKuA80LQg/E0d70ywLu2GjDl4gzbtIyWszz0+RjPRTeMMLJccfSepyGX5svuT/BH1T8ie/mH6M54OXrsKK/+8mOMRJLkYj5Gc2U0TffQ6y8CaznXWo+em4euh1wi0r42e6QoFGuM80LQDw2ESWXzvKZGWzxct/0SLCYDW89R0JvEKN1jsQJbOQudj4DRyi9iF+CpbuR1OxpIOuqoyo9ybDjCs51+ctEx/JSdHXIxmqBmCxuMgwydSy66viiaNpepknOFYhVwXgj6+Ci2et/TYHHxe7feyoMfvUYrk18M5U1IYaRFjHB0MFIES2eg81FyTZfSG4W2SgdVLis3XHoxldKP1ZDnyGAYQ8JHQJadHXIB8LRQJ0cZPseQSw4jFtsa7I+iUKxBzg9Bj6UBSVnvQ9BxLUaL7dxmXxpNCHcTmyxjHBsKF9zOs4j5YPgA/trLgUkzJN2NCJlnT1WKEwM+TNk4fjlDyAXA3Yw3O8JwKDZzUdJcpMIkDQ48quxfoVgVrH5Bf/o/4N5PzHlIIJ5ho+jDGOmHDa9a2ut52+gw+Tg6tAweetdjAHS6LgagtVIfuFGuFT5d4k0wONgPQMyod1qcjqcZo8zhzowRTixyITcZIirUgqhCsVpY/YJ+4Kfw4nchn5/1EH8szc0WrUKUDTct7fW8bdTLIU6NRklnZ3/NQnD6hXvImss4KNsBaK0446EDbHNFyEW1dQGjq3rmboOeFkCL+w+GF7kwmgwTkXY8qqhIoVgVLEjQhRA3CyGOCSFOCiE+Psdxvy+EkEKI3YUzcQ7yeRg9DpkY+E/NelgwnuZ64z6ovQDKG2Y9bkF4W3FmAphzCTp90aWday4SQVzdv+Px7BYODMYos5nOeMrlmqB3mANUCC30Yymfpc+HWxP0RuFbfHFRuI8h6VUeukKxSphX0IUQRuCrwC3AVuCtQoizBgIKIcqADwHPFtrIWQn3aWIOWo/zWUhGA1yQPwIblxhugSltdI8VMeySue9v8cgw/5K8nV/tG6C10nHGA7eVg9VNnRijAs0Gl7d25hPpfWkWLehSIv3ddOZqcCtBVyhWBQvx0PcAJ6WUnVLKNPBj4HUzHPf/AZ8HCjD3bIGMHj/z8xyC3hDeh5E8rLt+6a9ZuQGAjcYBjhQr06Xrccz7vsd/524l5N0GQGuFc+ox7kbs8SEutfWQlQbKaltmPpfFgXRW02wYXVw/l7gfkY7QnatWIReFYpWwEEFvBHonPe7Tt00ghNgFNEsp/3euEwkh3ieEeEEI8cLo6OiijT2L0aPad0/LnILeHD9MDiM07Fz6a1ZtAASXuHzFy3R57AskHA18OftG/vENF1BdZuXCpmlVreWNEOjidh7jwfwu6qprZj2dcDfTZvIvbhRdoAuA07Jm5sVWhUKx4ljyoqgQwgB8CfiL+Y6VUn5dSrlbSrm7uroAvZ1HjyIdVYzVXkmm/xWGgjML1obMcUbtHWBxzrh/UZjt4Glhm3mweCGX4cN0u/eQxMpFzR6e+KvreN/VHVOPcTfByGHK80F+lLtu5pTFcTwtNBt8DAQX4aH7xwW9VsXQFYpVwkIEvR9onvS4Sd82ThmwHXhECNENXAbctSwLo77jnKKJLx20Y04H+cwP7zvrkFQmy3ZOMuYu4LSX6k205PsYCCXxxwrceTHuh7iPLhrxOsyU28xYTcazM1j0TJe0swHD+hvoqJ7jZuVppiY/wkBgEdWtgW4AemWNap2rUKwSFiLozwMbhBDtQggL8BbgrvGdUsqQlLJKStkmpWwDngFul1K+UBSLz7wwjB7leK6edLUm1rmBfXoR0RkiAyfwiBiRygsL99pVG6lInsZAnue6xgp3XgDfCQAOp+toqZxDpPVcdMvud/Ctd18+d2m+uwWzzJAMDZNf6OSiQBdJWw0pLMpDVyhWCfMKupQyC/wZcB9wBPiplPKQEOIzQojbi23grESHIRlif7oeR/NFSGFkq+jm0eNTY/PpnucAyNQVIH4+TvUmDLk0GyxjPHWq0IKuLfQ+H6s8k3c+E21XalOJLn7n/OfUc9Frc8P4YgtsAeDvImzXbhpK0BWK1cGCYuhSynuklBullOuklP+gb/uUlPKuGY69tujeOUwMeDiQqqW+ygtVG9llPs1DR0emHtf/EglpwVhXwInpVZsAuLk2XARBP4Y0WnkxVE5r5dxxcf7wN1BeP/85PVrErFH46A8scGE00MWYVQvrqCwXhWJ1sHorRXVBP5FvoslrRzTuYoehi0eODZPNnangtI/s44Bsp6LsHHq3zEb1RgAuL/dxciTKyLl0MpwN3wkyng6y0kDLufSbmQn3GUFf0MJoJgGRQUaN9VhNhqlTnRQKxYpl9Qr62EmyJicjeLQMj4adlOUClCWHeKknqB2Ty1AePMwr+XWFnbhj94Kzho3GQQCe7iygl+47TtDRBkzq3bJUbOXkbV5axAj9wfj8xwdOA9Av6lS4RaFYRaxeQY+NELNUAYImrx0atQZWu0xdPHBkWDum8xGM+TTP5zcVXpiqN+GNdVFuM/HUyQIJeiYJgW4GLVrMe86QyyIxVHawzjS8sJCLnoPena9R4RaFYhWxigXdR8jgwWY2UOm0QO12MFq4tWKAX+/rJ5eX8PL3iZk8PGe+BKupwGGDqo0I33Eua68onIfu7wSZ51S+AZvZQE2ZtTDnBahcT4cYon+WXP2pdmiC/mzIfW5thhUKRUlYxYI+ik+W0+TVe5yYNFHfY+1mOJzi6QNH4eg9PF9+Ey7HDIMflkrVRkiF2FOTpccfJ5XNLf2ceobLgVQtLRWOmbsnnisV66iRPkb8wdmPOfkA/Mfl8Mg/kbe42DdmYHebt3A2KBSKorKqBX0o69LCLeM0XkxF6DCVdgNDj38f8hnut95ERTEGNFRolZvtBi2rZuRcJgJNRxf0p0MVdFS5ln6+yVRqc1SNoe7Zj3nma1o66NbbOXTR3wKC3a1K0BWK1cLqFPRcFuJ+elPOaYK+C5GO8r5NcS4a/TXZ+l0czDYtftTcQqjQepQ3yCEAhguR6dL/EnlPK8f8WTbVFXjsm34Dqkn3E05mzt6fDCO7HiW88Y3wuq/yG3ENFpOBC6b3kFEoFCuW1SnoCT8g6cu4pg5G1hdG39P5YdbRz0MVbyEQS1NRjEwNTwsIA9WZAYBzm9k5mZgPTt7PWPOrkRI2F1rQdQ+9TQwxMFMc/eQDiFyaP3mhjl5/nBe6/VzY6C782oNCoSgaq1PQY1o16JgeQ5+gcgPY3BjJ85Xqv+cjB1oZDifxFiPkYrJCeRPliT4AhpbqoR/4GeSzvFxxKwAbCy3oNjcZWyXtYnDmTJej/0vE4OaZ7Aa+eN8xDvSHuFjFzxWKVcUqF3T31JCLwQB/8Ev4k8d541vfS05KUtl8YXPQJ1PRhjnUjcVkOLeQi5QQG2MwlCDyzHegYScvJOqwmAxzl/2fI7Kig3bDEL3+abno2TSc+B2PiN0gDNz1ygCZnGR3a0XBbVAoFMVjlQq6DwAf5VMFHbSwS0UHLZUOPnSDVtFZFA8dwNuOCHRRV25b/Hg3gP0/gS92kPjv11IWPEp405s4OhRhQ40Lk7Hwfxpz9Xo6DMPs7w9N3dH9OKTC/Cqxg3de0Y7NrL32xWpBVKFYVZhKbcA5oXvocZN3zgyW9+xtxyDg5m11xbGjoh3iY7TX5M7NQ+9+Akx26qKHSEgLv8ldzvEhP1esqyy8rYCoXE81AY50DwA7ptiRFyaezG/n7RuqqC23sq83WJzsIIVCUTRWraDnMFBRWTNnrrbZaOCPr1lXPDv0zJEttjHuHTuHxcPBV6DlMt7uey9jo0NYXwkzFE4WPn4+jr4wKgJd+KIpqlx64VLf8/jLNpJMWNlSX851m2effqRQKFYuqzTkMkoQN+01RRK+heLVUhc3mEYYCieRcoG9xkGLW48cQdZdyJGAkRFTI8eHowCFT1kcp+JMpstLpwPatnwO+l/ihHkzHoeZ2vICVqcqFIplZVUKei4yyki+jHXVBS6+WSx6LnqzGCaZyRNOZhf+3NGjkM8Q8W4lkcnxlj1nhkJtqi2Wh74eaS3jg+ZfcqhTa8DFyBHIxHg63cGWuvLCVqcqFIplZVUKejo8jE+Wzz12bTmwloGjitqs1nVxUXH0of0A9FjXA3D1hmq2N5ZTZjNR77YV3FQALA7Em77POjHILfs/DOk49D0PwL3BZjbXl/gTj0KhWBKrUtBldJQxykvvoQNUtONNaSNWF5XpMrgfzE5OZmsBaK5w8OnXbuOzr99eXC953XX8uuPv2Zw5TOjez9K17xHSVi/HM1VsqS8v3usqFIqisyoF3ZQcY0y6S++hA1R04Ij1AIssLhraD3Xb6Qloz2ny2tndVsHrdjQWw8opOHf+Pj/PXY39xa/h6n2Yx+JtgGCrEnSFYlWz+gQ9HceSi5O2VuCwrIAkHXczxuggBvILn1yUz8PQAai7kB5/nLpy29xDngvMFeureLjp/UiTlWoRonLzVbz/2nXKQ1coVjmrT9DjWlGRuXyFpNa5ahAyT6s9uXAPPdAF6SjUa4JesFFzC8RtN/PVP74F6w2fBGDnlbfwsZs3YzSoBVGFYjWzAlzcxSGjowjA7i1SsdBicVYDsMmVYCi0sAZd3Qefpg04Zeqg1x/n8iIVEs3LZe+HpkugeU9pXl+hUBSUVeehh3xad0NvdUOJLdFxaZ8U2u3xBWe5xE6/REYa+dwLWtx9uT30CQwGaLkUVKqiQrEmWHWC7hvWMkqq65rnOXKZcGqC3maL0RdYwABmwOk/xAnZxP3HQ0hJ6QRdoVCsKVadoIfHtJzv5uYVIuguLeTSao0SiGcIxNJzHy8llZFjnDC047RoC6FK0BUKRSFYdYIe2/ImvtT8r9RWlijuPB2bB4wW6owRALrGYnMfHxmiLBdgxLmJd1zRhkFAW9UKSL9UKBSrnlW3KLp35zb27txWajPOIAQ4q6kkCEDXaIxdLXO0ndUrREPuLXz0po3cdmH9mSZZCoVCsQRWnYe+InFW48z4MRoEXb55PPRBTdAz1dswGw1sa1AzOxUKRWFQgl4IXDUYYqO0VDjmFfTswD668rV4K1ZIyEihUKwZlKAXAmcNxEZpr3JyajQ656FycD+HZFvxGnApFIrzFiXohcBVDbFROirtdI/FyOdn6YueCGIO93A430ZtuRJ0hUJRWJSgFwJnDeSzbPLkSGbys7cA8J0A4KhsVh66QqEoOErQC4FeLbreoRUWzRpHj2g59EOyQnnoCoWi4CxI0IUQNwshjgkhTgohPj7D/o8KIQ4LIfYLIR4UQrQW3tQVjC7orVZNyDtnFfQhAJK2mmXtrqhQKM4P5hV0IYQR+CpwC7AVeKsQYuu0w14GdkspLwR+Dnyh0IauaPTyf68MYjcb6Rqd3UPPYsTmXiGdIhUKxZpiIR76HuCklLJTSpkGfgy8bvIBUsqHpZTjjUyeAZoKa+YKR/fQhZ7p0uWbJdMlOkzA4KXOo0r9FQpF4VmIoDcCvZMe9+nbZuOPgN/OtEMI8T4hxAtCiBdGR0cXbuVKx+YBgwmiI3RUO+cIuQwynPeo+LlCoSgKBV0UFUK8HdgNfHGm/VLKr0spd0spd1dXVxfypUuLwaD1RY+N0FHlpNcfJ53Nn3VYPjzIQM6tMlwUCkVRWIig9wOTWxs26dumIIS4EfgkcLuUcmGTHtYSzmqIjtJe7SQvocd/ditdGRliWHqpUx66QqEoAgsR9OeBDUKIdiGEBXgLcNfkA4QQO4H/QhPzkcKbuQpw1UBshPYqFzBD6mI2hTEZYFh6aaqwl8BAhUKx1plX0KWUWeDPgPuAI8BPpZSHhBCfEULcrh/2RcAF/EwIsU8Icdcsp1u7uOogPEh7pdYK96yFUT1lcQQPW9UwZoVCUQQW1D5XSnkPcM+0bZ+a9PONBbZr9eFpgegQbnOOSqflbA89OgxAzlGLx2EpgYEKhWKtoypFC4VXr6UK9dFR7eTU9Fx0vUq0vKZlmQ1TKBTnC0rQC4VHF+rgaT0XfaqgpwPaOnJd4/lVRKtQKJYPJeiFYkLQe2ivcjEaSRFJZiZ2jw33kpFGOlqVoCsUiuKgBL1QlNWDwawLurYw2u07k7oY9/VpC6KNnhIZqFAo1jpK0AuFwQjuJgiepqNaE/TOSZku+fAgfuGlQRUVKRSKIqEEvZB4WiDYQ0uFAyGm5qKbEyMkbTUIIUpooEKhWMsoQS8kuqDbzEaavHZOjGgeejaXx50dQ5TXldhAhUKxllGCXkg8rVq+eSbB1vpyjgyEATg54MMrojgrz68mlAqFYnlRgl5IJuWib2tw0zUWI5rKMnjwUQAqWreX0DiFQrHWUYJeSCblom9rKEdKODIYpvz4L4hip2bXa0trn0KhWNMoQS8k44IeOM22BjcAR3uG2BJ4mBccexEWNdhCoVAUDyXohcRVN5GLXltupcplIXf0HhwkGGx93fzPVygUiiWgBL2QGAzgaYbgaYQQbG1w09Z/NwOyAu/W60ptnUKhWOMoQS80dRdC5yOQDLPX62cv+/hl7ioubK4otWUKhWKNowS90Fz1YUgE4Jn/5LbR/yaOjV9aX6/GzikUiqKzoH7oikXQsBM23wZPfJn6bIIvZd9IS3uLqhBVKBRFR3noxeDaT0A2gXRW83DFHVy/uabUFikUivMA5aEXg7rtcPPnERUd/Gbjq0ptjUKhOE9Qgl4sLvuTUlugUCjOM1TIRaFQKNYIStAVCoVijaAEXaFQKNYIStAVCoVijaAEXaFQKNYIStAVCoVijaAEXaFQKNYIStAVCoVijSCklKV5YSFGgdPn+PQqwFdAcwqFsmtxKLsWzkq0CZRdi6UQdrVKKatn2lEyQV8KQogXpJS7S23HdJRdi0PZtXBWok2g7FosxbZLhVwUCoVijaAEXaFQKNYIq1XQv15qA2ZB2bU4lF0LZyXaBMquxVJUu1ZlDF2hUCgUZ7NaPXSFQqFQTEMJukKhUKwRVp2gCyFuFkIcE0KcFEJ8vIR2NAshHhZCHBZCHBJCfEjfXiGEuF8IcUL/7i2BbUYhxMtCiLv1x+1CiGf1a/YTIYSlBDZ5hBA/F0IcFUIcEUJcvkKu1Uf0v99BIcSPhBC2UlwvIcS3hBAjQoiDk7bNeH2Exr/q9u0XQuxaZru+qP8d9wshfimE8Eza9wndrmNCiFcvp12T9v2FEEIKIar0x8tyvWazSQjx5/r1OiSE+MKk7YW/VlLKVfMFGIFTQAdgAV4BtpbIlnpgl/5zGXAc2Ap8Afi4vv3jwOdLYNtHgTuBu/XHPwXeov/8NeBPS2DTd4H36D9bAE+prxXQCHQB9knX6Z2luF7A1cAu4OCkbTNeH+BW4LeAAC4Dnl1mu14FmPSfPz/Jrq36e9IKtOvvVeNy2aVvbwbuQytarFrO6zXLtboOeACw6o9rinmtiv6mKfAFuxy4b9LjTwCfKLVdui2/Bm4CjgH1+rZ64Ngy29EEPAhcD9yt/xP7Jr0Bp1zDZbLJrQunmLa91NeqEegFKtDGMd4NvLpU1wtomyYGM14f4L+At8503HLYNW3fG4Af6j9PeT/qwnr5ctoF/By4COieJOjLdr1m+Bv+FLhxhuOKcq1WW8hl/A04Tp++raQIIdqAncCzQK2UclDfNQTULrM5XwE+BuT1x5VAUEqZ1R+X4pq1A6PAt/VQ0H8LIZyU+FpJKfuBfwZ6gEEgBLxI6a/XOLNdn5X0Png3mvcLJbZLCPE6oF9K+cq0XaW0ayOwVw/hPSqEuKSYNq02QV9xCCFcwP8AH5ZShifvk9qtd9nyQoUQtwEjUsoXl+s1F4gJ7aPof0opdwIxtBDCBMt9rQD0mPTr0G44DYATuHk5bVgopbg+8yGE+CSQBX64AmxxAH8NfKrUtkzDhPYJ8DLgL4GfCiFEsV5stQl6P1qMbJwmfVtJEEKY0cT8h1LKX+ibh4UQ9fr+emBkGU26ErhdCNEN/Bgt7PL/AI8QwqQfU4pr1gf0SSmf1R//HE3gS3mtAG4EuqSUo1LKDPALtGtY6us1zmzXp+TvAyHEO4HbgLfpN5tS27UO7cb8iv7/3wS8JISoK7FdfcAvpMZzaJ+cq4pl02oT9OeBDXoWggV4C3BXKQzR77LfBI5IKb80adddwB/qP/8hWmx9WZBSfkJK2SSlbEO7Ng9JKd8GPAy8sRQ26XYNAb1CiE36phuAw5TwWun0AJcJIRz633PcrpJer0nMdn3uAt6hZ29cBoQmhWaKjhDiZrSw3u1Syvg0e98ihLAKIdqBDcBzy2GTlPKAlLJGStmm///3oSUtDFHa6/UrtIVRhBAb0RICfBTrWhVrwaJYX2gr1sfRVoU/WUI7rkL7CLwf2Kd/3YoWs34QOIG2ul1RIvuu5UyWS4f+z3IS+Bn6ivsy27MDeEG/Xr8CvCvhWgF/DxwFDgLfR8s6WPbrBfwILY6fQROjP5rt+qAtdH9Vfw8cAHYvs10n0eK/4//3X5t0/Cd1u44BtyynXdP2d3NmUXRZrtcs18oC/ED//3oJuL6Y10qV/isUCsUaYbWFXBQKhUIxC0rQFQqFYo2gBF2hUCjWCErQFQqFYo2gBF2hUCjWCErQFQqFYo2gBF2hUCjWCP8/q1e3fMaoIgYAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "fig,ax = plt.subplots()\n",
        "ax.plot(pred_SVR, label='pred')\n",
        "ax.plot(y_test.reset_index(drop=True), label='true')\n",
        "plt.title('SVR MODEL')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Intervalo de Predição para SVR "
      ],
      "metadata": {
        "id": "1PSzSg4SM7Sm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MapieRegressor(\n",
        "    model_SVR, \n",
        "    cv=\"prefit\",\n",
        "    method='base', agg_function=None, n_jobs=-1,\n",
        ").fit(X_test, y_test)\n",
        "\n",
        "forecasts = model.predict(X_test, alpha=0.05, ensemble=False)\n",
        "y_test,y_ic = forecasts"
      ],
      "metadata": {
        "id": "L1qJBsR-iCjP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "743ba746-3b13-4b4e-ed63-292354707932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ensemble"
      ],
      "metadata": {
        "id": "iXMHGD4DNAJy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## O Ensemble é uma técnica de aprendizado de máquina que combina vários modelos para melhorar a precisão e a estabilidade das previsões. A ideia por trás do ensemble é que a combinação de vários modelos fracos pode produzir um modelo forte que pode fazer previsões mais precisas. A ideia do ensemble aplicado foi utilizar o Intervalo de Predição obtido a partir do SVR como critério para calculo da média dos preditores."
      ],
      "metadata": {
        "id": "kF5zpRXcnnRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ensemble(yhat1, yhat2, yhat3, yhat4, upper, lower):\n",
        "    if upper <= lower:\n",
        "        raise ValueError(\"Upper bound must be greater than lower bound.\")\n",
        "    \n",
        "    yhats = [yhat1, yhat2, yhat3, yhat4]\n",
        "    yhats_in_interval = [yhat for yhat in yhats if lower < yhat < upper]\n",
        "    \n",
        "    if not yhats_in_interval:\n",
        "        return None\n",
        "    out = sum(yhats_in_interval) / len(yhats_in_interval)\n",
        "    return out.item()\n",
        "\n"
      ],
      "metadata": {
        "id": "4YN29KISwunu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dat =[ensemble(yhat1,yhat2,yhat3,yhat4,upper,lower) for yhat1,yhat2,yhat3,yhat4,upper,lower in zip(pred_LGBM,pred_SVR,pred_mlp,pred_lstm,y_ic[:,1,0],y_ic[:,0,0])]"
      ],
      "metadata": {
        "id": "vm-lNA2mKUdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Ensemble model Results')\n",
        "results['Ensemble'] = {'mse': mean_squared_error(dat, y_test),\n",
        "                  'mae': mean_absolute_error(dat, y_test),\n",
        "                  'mape':mean_absolute_percentage_error(dat, y_test)}\n",
        "results"
      ],
      "metadata": {
        "id": "iOA_-BSpzElY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b1f2a86-96aa-4a6d-fba0-683f9bdfecf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble model Results\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MLP': {'mse': 0.003234977257735753,\n",
              "  'mae': 0.04369475587181178,\n",
              "  'mape': 0.0766240223561974},\n",
              " 'LSTM': {'mse': 0.008040517372466234,\n",
              "  'mae': 0.07269689632233525,\n",
              "  'mape': 0.14168762735965318},\n",
              " 'LGBM': {'mse': 0.0036841520042503184,\n",
              "  'mae': 0.046490840215175175,\n",
              "  'mape': 0.08625817146208868},\n",
              " 'SVR': {'mse': 0.0026444878875929454,\n",
              "  'mae': 0.040567308445866576,\n",
              "  'mape': 0.0747836688725313},\n",
              " 'Ensemble': {'mse': 0.0004891377136526729,\n",
              "  'mae': 0.018458247897321943,\n",
              "  'mape': 0.03403350594204156}}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax = plt.subplots()\n",
        "ax.plot(dat, label='pred')\n",
        "ax.plot(y_test, label='true')\n",
        "plt.title('Ensemble MODEL')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "1M7j5YmJxLB9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "87895767-c0d8-49e6-ab0e-da8efe6735e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f60d8666610>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Resultado"
      ],
      "metadata": {
        "id": "562vIfcoNQAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt_y = y_test\n",
        "plt_mlp = np.array(pred_mlp)\n",
        "plt_mlp = list(itertools.chain(*plt_mlp))\n",
        "plt_lstm = np.array(pred_lstm)\n",
        "plt_lstm =list(itertools.chain(*plt_lstm))\n",
        "plt_LGBM =np.array(pred_LGBM)\n",
        "plt_SVR =np.array(pred_SVR)\n",
        "plt_Emsemble = dat"
      ],
      "metadata": {
        "id": "1rUS29a_7TJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=np.arange(len(plt_SVR)), y=plt_SVR,name='SVR'))\n",
        "fig.add_trace(go.Scatter(x=np.arange(len(plt_LGBM)), y=plt_LGBM,name='LGBM'))\n",
        "fig.add_trace(go.Scatter(x=np.arange(len(plt_mlp)), y=plt_mlp,name='MLP'))\n",
        "fig.add_trace(go.Scatter(x=np.arange(len(plt_lstm)), y=plt_lstm,name='LSTM'))\n",
        "fig.add_trace(go.Scatter(x=np.arange(len(plt_Emsemble)), y=plt_Emsemble,name='Emsemble'))\n",
        "fig.add_trace(go.Scatter(x=np.arange(len(plt_y)), y=plt_y,name='true',mode='markers'))\n",
        "fig.add_trace(go.Scatter(x=np.arange(len(y_ic[:,0,0])), y=y_ic[:,0,0],name='lower',marker=dict(color=\"#444\"),line=dict(width=0),mode='lines',fillcolor='rgba(190, 190, 190, 0.3)',fill='tonexty'))\n",
        "fig.add_trace(go.Scatter(x=np.arange(len(y_ic[:,1,0])), y=y_ic[:,1,0],name='upper',marker=dict(color=\"#444\"),line=dict(width=0),mode='lines',fillcolor='rgba(190, 190, 190, 0.3)',fill='tonexty'))\n",
        "fig.update_layout(title='Models',height=800,width=1500)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "pkDd1yCnh-ZO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "outputId": "a8b75532-0bc0-4c40-a474-c11de0374638"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"f7cb077d-fad3-4007-b238-dbad243546d4\" class=\"plotly-graph-div\" style=\"height:800px; width:1500px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f7cb077d-fad3-4007-b238-dbad243546d4\")) {                    Plotly.newPlot(                        \"f7cb077d-fad3-4007-b238-dbad243546d4\",                        [{\"name\":\"SVR\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161],\"y\":[0.25465027883565006,0.3139218530495691,0.3869599715158538,0.38769570309991724,0.3566329214938501,0.3324817695579264,0.31793067694221566,0.4377893116639963,0.4596528841447598,0.43584792624567187,0.4838830392945167,0.5045762098954184,0.5179077205514353,0.4815492324953329,0.5456718406715086,0.5152480266326428,0.5377288511107867,0.438389610237469,0.38682862413339353,0.3512012429646295,0.26335805008373664,0.20355075820092386,0.14049418052020277,0.09279385226524153,0.13718548348681117,0.1853790806176742,0.27022220944031106,0.2513921777522916,0.3206428629870122,0.29356698385393676,0.34644757928060876,0.41324492620306036,0.3977665473293533,0.464530975904494,0.43768387667146413,0.43896039657142216,0.38929546733293463,0.4610665879337496,0.5871289927035799,0.4862281804990944,0.4847629597391976,0.39926817850204416,0.32313460052430243,0.282750645631754,0.28652393886629746,0.2836953152852001,0.3341562347266441,0.3162285182215906,0.35580460619397514,0.48455967908026853,0.5985521536537485,0.5885294378028865,0.5982592306797251,0.5473050413450053,0.514522510874894,0.5866797942653709,0.5696679370165941,0.629995863163408,0.6779309255161167,0.5944375885451744,0.6217703011947763,0.6513216361260751,0.6194998924854279,0.6822111486969823,0.6840013335846874,0.7126927371712745,0.6827472503564218,0.6607728693409026,0.6880674348402774,0.6545911228894297,0.5682602437125058,0.49480532800189325,0.6314485904627333,0.5483553737180006,0.6687013717890037,0.7758231514634605,0.7785676757712396,0.7943200800230394,0.6914932254245822,0.6933460472502639,0.7103214575409731,0.7615596797440883,0.8023782029219662,0.8159628554694259,0.6902471776158242,0.7256087180185072,0.9434441272501852,0.9881280930056945,1.0476656350710598,0.9450579688046487,0.9569642837534683,0.8708408567063064,0.8756706196335413,0.8333864319119084,0.7569171790618128,0.6710243945796004,0.6642475996332438,0.6890948194576526,0.8183506306322794,0.7706135362805236,0.5453891939478565,0.4994879363217627,0.5144931774602794,0.5832813904775958,0.6304637936919325,0.6326500166049218,0.5983866470546129,0.7602047024996519,0.7816998650205682,0.8442798128006622,0.9586823794834747,0.7752007611040604,0.8672648153155539,0.8721858635901424,0.7557572128812893,0.7617916243322497,0.8001567177286704,0.7493837528854438,0.7288684337708486,0.6450182506468686,0.6189309244901147,0.6781355533375528,0.7957771065888907,0.7238564892937991,0.6869291778971158,0.5583030297508966,0.5122261877492048,0.5583469222199574,0.5556539987190496,0.6527814508484995,0.5945464924238127,0.6876825636862763,0.6662510521773614,0.706944497327338,0.7724032921736262,0.6850413168372562,0.7791714238410641,0.7284498198651017,0.6787627700103629,0.7852734261705974,0.8206897482180129,0.8662803702787175,0.8309431626155594,0.7564030138265883,0.8045080691665176,0.8364559415170443,0.9228123711815508,0.9325614415053363,0.8230797315466196,0.67539953723347,0.642074617306543,0.6531564182928847,0.7049425278642057,0.7063749129183059,0.6380750893594134,0.6260694799857699,0.6150363589564366,0.7083308518849759,0.8180738332457901,0.8024147785821477,0.8452302179256851,0.939091309942576],\"type\":\"scatter\"},{\"name\":\"LGBM\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161],\"y\":[0.3283561852983318,0.2932801586274659,0.3989971146792923,0.4122436284136627,0.3441321308201608,0.3184125337917795,0.34877049383953623,0.3908298659649907,0.4772875613788551,0.4716241806247706,0.5115447406588738,0.5079513481906095,0.5086808306125258,0.44736682670181976,0.4941746264146826,0.495492850442193,0.4860226427257284,0.405368015524491,0.3519238493781182,0.3058419992910764,0.26452852801025356,0.16019638415027657,0.12033153803545338,0.09316667012643409,0.11189789549144509,0.14214178395200555,0.26053678146537596,0.28413897351660206,0.3398433761855318,0.3276753006154632,0.3395194893902639,0.4024791367597095,0.3659891382022406,0.4177296511251867,0.41578460229678355,0.4866111200483713,0.3925037654082274,0.4472397132348532,0.541042679461624,0.4845181558329785,0.45195154255579567,0.3911280589364678,0.3124112163683202,0.24776344328027952,0.2536389199872697,0.29237168266180613,0.3664051070128094,0.3809469423469011,0.40254889843004266,0.49995537956473607,0.5151655676350886,0.5348842997027355,0.533258876588505,0.5315099355959081,0.5212919427828365,0.5540446497904185,0.5220594859244877,0.5587944854126853,0.6421867912614041,0.5856382771405961,0.5948252958739744,0.6297702666482417,0.6034615689795769,0.6201740526472064,0.6402564518093207,0.7059193608341967,0.6734314457588111,0.632966710774567,0.6080140183999821,0.6161342826032732,0.5871227278075274,0.4812274497131086,0.5843875261366959,0.5835703961311256,0.7311358809808398,0.7781768506329185,0.7695655650644261,0.7272008728032434,0.6660677473943558,0.7022229394941932,0.7166998893197054,0.7797830315296579,0.8303212037894013,0.8528359749232678,0.693087846621416,0.7173495319497972,0.8846359057340742,0.9146082705991927,0.9128154915844078,0.9402982449861569,0.9352619500104519,0.9299137361940848,0.8416321568963202,0.7710123640548369,0.7116862138001988,0.6769775182801908,0.7181387495866298,0.6404565645676874,0.8147062228565093,0.8305922618010253,0.5905823332064203,0.4723157956249442,0.5254122570134198,0.6108730684704472,0.5568956193812279,0.6110614095587859,0.6611823933851387,0.7331245695909271,0.7214073509272354,0.8078438593751301,0.8720662604885291,0.8569241850629691,0.8514350034020559,0.8590000907409345,0.798725227619776,0.787057355086728,0.7962262954269815,0.7254952564725597,0.741400088401352,0.7055603526386318,0.6674523814179344,0.6765927801457315,0.8512918929198202,0.7736829994381975,0.6937203427999955,0.5819763430273895,0.5754285772538005,0.5350409395346447,0.5059778734482948,0.6218156285907578,0.6100242795094237,0.663959949698706,0.6312564967353446,0.6632489263240621,0.7115419327389517,0.6826430615936904,0.735549661367461,0.6710383968085835,0.6700170216064275,0.8063187928816068,0.8049921843405674,0.801757945713367,0.8154359626179627,0.7668277796229132,0.8127265345886362,0.8341062865134644,0.9123986282684967,0.9058215834237721,0.8287815313022063,0.7557380608912891,0.7341963762370507,0.6287651131917346,0.7075042097616491,0.6852977284365103,0.6342052408024722,0.687901643653617,0.6519849101270425,0.6319651317322172,0.6574311015953451,0.7200003343705438,0.7830628044968051,0.8274465942417675],\"type\":\"scatter\"},{\"name\":\"MLP\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161],\"y\":[0.31900322437286377,0.34118303656578064,0.38909411430358887,0.3999159038066864,0.35764217376708984,0.34390756487846375,0.3737863004207611,0.4269339442253113,0.475531667470932,0.5147623419761658,0.5194725394248962,0.5167465806007385,0.5513931512832642,0.5158788561820984,0.5371218323707581,0.5502633452415466,0.5460649728775024,0.45340776443481445,0.422720730304718,0.37114423513412476,0.3159045875072479,0.21429896354675293,0.13725310564041138,0.10523176938295364,0.15023177862167358,0.1993218958377838,0.2723756730556488,0.29143068194389343,0.313156396150589,0.3055412471294403,0.358513206243515,0.4257775545120239,0.4470045566558838,0.4619225561618805,0.4741969406604767,0.49183693528175354,0.454662024974823,0.4635746479034424,0.5489282608032227,0.5544049143791199,0.489607572555542,0.42094942927360535,0.3605339527130127,0.31729891896247864,0.3145357370376587,0.29294267296791077,0.3368825614452362,0.3699972331523895,0.3754170835018158,0.42903396487236023,0.5806328654289246,0.5950459241867065,0.566712498664856,0.5660473704338074,0.5634315013885498,0.5623237490653992,0.5712782740592957,0.6085207462310791,0.6551739573478699,0.6274187564849854,0.599906861782074,0.6195605397224426,0.6588058471679688,0.6787502765655518,0.6653211712837219,0.6966165900230408,0.6906567215919495,0.6499084234237671,0.6413416266441345,0.6334852576255798,0.5797545909881592,0.5273003578186035,0.594951331615448,0.6171153783798218,0.6981093883514404,0.7659739851951599,0.7823847532272339,0.7844440340995789,0.7401286363601685,0.7093505859375,0.7291978001594543,0.7828757166862488,0.8197895884513855,0.8156245946884155,0.740331768989563,0.7334354519844055,0.876488447189331,1.0047879219055176,1.0369932651519775,0.9523752927780151,0.943854570388794,0.9000900983810425,0.8721849918365479,0.8208209872245789,0.7731432318687439,0.6864882111549377,0.6952665448188782,0.7064059972763062,0.8354464769363403,0.8144834637641907,0.593939483165741,0.48600223660469055,0.561128556728363,0.6338337659835815,0.6519891023635864,0.6643797755241394,0.6613254547119141,0.7643494009971619,0.7996641993522644,0.8239081501960754,0.909308671951294,0.9007352590560913,0.8616577982902527,0.8685991168022156,0.8497536778450012,0.8092774748802185,0.7750719785690308,0.7816275358200073,0.7662793397903442,0.7152314782142639,0.6619758009910583,0.6784314513206482,0.8184140920639038,0.8087270855903625,0.6818585991859436,0.5706026554107666,0.5644518136978149,0.5624345541000366,0.5740175247192383,0.6402804851531982,0.6468748450279236,0.711656391620636,0.7384564876556396,0.7127537727355957,0.7596724629402161,0.7653952836990356,0.7765059471130371,0.7791705131530762,0.7605177760124207,0.7792033553123474,0.8134496808052063,0.868631899356842,0.8483782410621643,0.7936850190162659,0.7937228083610535,0.8368802666664124,0.925933837890625,0.9522504806518555,0.8384901881217957,0.7097203135490417,0.6697404384613037,0.6743676662445068,0.7072067260742188,0.7104277014732361,0.6664150953292847,0.673158586025238,0.6802887320518494,0.6955057382583618,0.7827873826026917,0.8158688545227051,0.8440923094749451,0.9352544546127319],\"type\":\"scatter\"},{\"name\":\"LSTM\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161],\"y\":[0.2912774682044983,0.2884982228279114,0.31331363320350647,0.3482339680194855,0.3682490587234497,0.36784589290618896,0.36199963092803955,0.36134493350982666,0.3727133870124817,0.3875128924846649,0.40779605507850647,0.43235892057418823,0.4529579281806946,0.44887399673461914,0.45184507966041565,0.4630178213119507,0.47434133291244507,0.4633745551109314,0.4329849183559418,0.3923233449459076,0.34399592876434326,0.2852402329444885,0.2294217050075531,0.1882261037826538,0.1676103174686432,0.16702604293823242,0.19825366139411926,0.2436119019985199,0.29171448945999146,0.3255198001861572,0.34964799880981445,0.37401285767555237,0.3929714858531952,0.4100968539714813,0.4197447597980499,0.42556872963905334,0.4092544615268707,0.39653363823890686,0.4119695723056793,0.43025925755500793,0.4346189498901367,0.4253768026828766,0.395460307598114,0.35278621315956116,0.31814828515052795,0.2945863604545593,0.29498112201690674,0.3112146258354187,0.3278270959854126,0.35447853803634644,0.4015938937664032,0.4529114365577698,0.4929046928882599,0.513770341873169,0.520113468170166,0.5223560333251953,0.5216683149337769,0.5282119512557983,0.5535176992416382,0.5719769597053528,0.5632158517837524,0.5562511086463928,0.5596604943275452,0.5767868757247925,0.5994974374771118,0.6281964182853699,0.6468216776847839,0.649871826171875,0.6420155167579651,0.6228849291801453,0.5897443294525146,0.5506635308265686,0.5397712588310242,0.5339745879173279,0.5560136437416077,0.6025993227958679,0.6550527811050415,0.6952221989631653,0.7053152918815613,0.6909915208816528,0.6719655394554138,0.6812452673912048,0.7102584838867188,0.7380878329277039,0.7241743803024292,0.7027001976966858,0.7318695783615112,0.7844178080558777,0.8434695601463318,0.8819370269775391,0.911641538143158,0.8993796110153198,0.8625194430351257,0.8147494196891785,0.7699869275093079,0.7286653518676758,0.6983893513679504,0.6668083667755127,0.6861793398857117,0.7212641835212708,0.6868503093719482,0.6156002879142761,0.5817538499832153,0.5813050270080566,0.5860472321510315,0.6035857200622559,0.6271544098854065,0.674003005027771,0.7129881381988525,0.7339950799942017,0.7674888372421265,0.794123113155365,0.8033180236816406,0.8048760294914246,0.7783991098403931,0.7478466629981995,0.7393002510070801,0.7276775240898132,0.7015897631645203,0.6746228933334351,0.6449005007743835,0.6230147480964661,0.6552121639251709,0.696001410484314,0.697120189666748,0.6542143821716309,0.6136221885681152,0.5729370713233948,0.5482475757598877,0.558296799659729,0.5829030871391296,0.6215694546699524,0.647150456905365,0.6490707993507385,0.6634266972541809,0.6790748834609985,0.6968843936920166,0.7051998972892761,0.6922076344490051,0.6999871730804443,0.7234800457954407,0.7478755116462708,0.7587769627571106,0.7545450329780579,0.7425426840782166,0.7418108582496643,0.7707599997520447,0.8126501441001892,0.8189660906791687,0.7710289359092712,0.7091690897941589,0.6544498205184937,0.6364577412605286,0.6413542032241821,0.6483970880508423,0.6557586193084717,0.6504141092300415,0.6499125361442566,0.6767870783805847,0.7155947685241699,0.7604683637619019,0.8133035898208618],\"type\":\"scatter\"},{\"name\":\"Emsemble\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161],\"y\":[0.29832178354263306,0.3092207908630371,0.3720912039279938,0.3870222866535187,0.35666409134864807,0.3406619429588318,0.3506217896938324,0.4042245149612427,0.4462963938713074,0.4524368643760681,0.4806740880012512,0.4904083013534546,0.5077348947525024,0.4734172224998474,0.5072033405303955,0.5060055255889893,0.5110394358634949,0.44013500213623047,0.3986145555973053,0.3551277220249176,0.29694676399230957,0.21582157909870148,0.1568751335144043,0.11985459923744202,0.1417313814163208,0.17346720397472382,0.2503470778465271,0.26764345169067383,0.31633925437927246,0.31307584047317505,0.3485320806503296,0.4038785994052887,0.4009329378604889,0.4385700225830078,0.4368525445461273,0.46074429154396057,0.41142892837524414,0.44210365414619446,0.5590333342552185,0.4888526201248169,0.46523526310920715,0.409180611371994,0.34788501262664795,0.3001497983932495,0.2932117283344269,0.29089897871017456,0.33310624957084656,0.344596803188324,0.36539942026138306,0.47118303179740906,0.56478351354599,0.5728198885917664,0.5660768747329712,0.5396581888198853,0.5298398733139038,0.5563510656356812,0.5461684465408325,0.5991036891937256,0.6584305763244629,0.5948678851127625,0.594929575920105,0.6142258644104004,0.6103569269180298,0.6603785157203674,0.6472691297531128,0.685856282711029,0.6734142899513245,0.648379921913147,0.6448596119880676,0.6317738890647888,0.5812205076217651,0.5134991407394409,0.5876396894454956,0.5707539319992065,0.6993155479431152,0.7733246684074402,0.7768393158912659,0.768655002117157,0.7007512450218201,0.6989777088165283,0.7070462107658386,0.7513659596443176,0.790686845779419,0.8056278228759766,0.7119603157043457,0.7197734713554382,0.9015228152275085,0.9691746830940247,1.0423294305801392,0.9299170970916748,0.9369305968284607,0.9000561237335205,0.863001823425293,0.8099923133850098,0.7529333829879761,0.6907888650894165,0.6940105557441711,0.6756914258003235,0.8228344917297363,0.784238338470459,0.5766370296478271,0.4859353303909302,0.5456969738006592,0.6023232936859131,0.6063489317893982,0.6279192566871643,0.637012243270874,0.7329204082489014,0.7539398670196533,0.825343906879425,0.9133524894714355,0.8087493777275085,0.8459188938140869,0.8511652946472168,0.7956588268280029,0.7764932513237,0.7776888012886047,0.7460460066795349,0.7345344424247742,0.6851081848144531,0.648314893245697,0.6640436053276062,0.8218277096748352,0.7505669593811035,0.6899070739746094,0.5702940225601196,0.5507021546363831,0.5571898818016052,0.5459742546081543,0.6182935833930969,0.6085872054100037,0.6712170839309692,0.6707786321640015,0.6830044984817505,0.7478725910186768,0.7030385732650757,0.7470278143882751,0.7209646701812744,0.7003762722015381,0.7676956653594971,0.8130438327789307,0.8455567359924316,0.8133835792541504,0.7678651809692383,0.7883750200271606,0.8123133182525635,0.9203816056251526,0.9302112460136414,0.8273293972015381,0.7279717326164246,0.6887951493263245,0.65268474817276,0.6890277862548828,0.6858636140823364,0.646773099899292,0.6607220768928528,0.6494309902191162,0.6714286208152771,0.8004305958747864,0.7634696960449219,0.808213472366333,0.9371728897094727],\"type\":\"scatter\"},{\"mode\":\"markers\",\"name\":\"true\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161],\"y\":[0.25465027883565006,0.3139218530495691,0.3869599715158538,0.38769570309991724,0.3566329214938501,0.3324817695579264,0.31793067694221566,0.4377893116639963,0.4596528841447598,0.43584792624567187,0.4838830392945167,0.5045762098954184,0.5179077205514353,0.4815492324953329,0.5456718406715086,0.5152480266326428,0.5377288511107867,0.438389610237469,0.38682862413339353,0.3512012429646295,0.26335805008373664,0.20355075820092386,0.14049418052020277,0.09279385226524153,0.13718548348681117,0.1853790806176742,0.27022220944031106,0.2513921777522916,0.3206428629870122,0.29356698385393676,0.34644757928060876,0.41324492620306036,0.3977665473293533,0.464530975904494,0.43768387667146413,0.43896039657142216,0.38929546733293463,0.4610665879337496,0.5871289927035799,0.4862281804990944,0.4847629597391976,0.39926817850204416,0.32313460052430243,0.282750645631754,0.28652393886629746,0.2836953152852001,0.3341562347266441,0.3162285182215906,0.35580460619397514,0.48455967908026853,0.5985521536537485,0.5885294378028865,0.5982592306797251,0.5473050413450053,0.514522510874894,0.5866797942653709,0.5696679370165941,0.629995863163408,0.6779309255161167,0.5944375885451744,0.6217703011947763,0.6513216361260751,0.6194998924854279,0.6822111486969823,0.6840013335846874,0.7126927371712745,0.6827472503564218,0.6607728693409026,0.6880674348402774,0.6545911228894297,0.5682602437125058,0.49480532800189325,0.6314485904627333,0.5483553737180006,0.6687013717890037,0.7758231514634605,0.7785676757712396,0.7943200800230394,0.6914932254245822,0.6933460472502639,0.7103214575409731,0.7615596797440883,0.8023782029219662,0.8159628554694259,0.6902471776158242,0.7256087180185072,0.9434441272501852,0.9881280930056945,1.0476656350710598,0.9450579688046487,0.9569642837534683,0.8708408567063064,0.8756706196335413,0.8333864319119084,0.7569171790618128,0.6710243945796004,0.6642475996332438,0.6890948194576526,0.8183506306322794,0.7706135362805236,0.5453891939478565,0.4994879363217627,0.5144931774602794,0.5832813904775958,0.6304637936919325,0.6326500166049218,0.5983866470546129,0.7602047024996519,0.7816998650205682,0.8442798128006622,0.9586823794834747,0.7752007611040604,0.8672648153155539,0.8721858635901424,0.7557572128812893,0.7617916243322497,0.8001567177286704,0.7493837528854438,0.7288684337708486,0.6450182506468686,0.6189309244901147,0.6781355533375528,0.7957771065888907,0.7238564892937991,0.6869291778971158,0.5583030297508966,0.5122261877492048,0.5583469222199574,0.5556539987190496,0.6527814508484995,0.5945464924238127,0.6876825636862763,0.6662510521773614,0.706944497327338,0.7724032921736262,0.6850413168372562,0.7791714238410641,0.7284498198651017,0.6787627700103629,0.7852734261705974,0.8206897482180129,0.8662803702787175,0.8309431626155594,0.7564030138265883,0.8045080691665176,0.8364559415170443,0.9228123711815508,0.9325614415053363,0.8230797315466196,0.67539953723347,0.642074617306543,0.6531564182928847,0.7049425278642057,0.7063749129183059,0.6380750893594134,0.6260694799857699,0.6150363589564366,0.7083308518849759,0.8180738332457901,0.8024147785821477,0.8452302179256851,0.939091309942576],\"type\":\"scatter\"},{\"fill\":\"tonexty\",\"fillcolor\":\"rgba(190, 190, 190, 0.3)\",\"line\":{\"width\":0},\"marker\":{\"color\":\"#444\"},\"mode\":\"lines\",\"name\":\"lower\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161],\"y\":[0.15881423485182655,0.2180858090657456,0.2911239275320303,0.29185965911609374,0.2607968775100266,0.2366457255741029,0.22209463295839216,0.3419532676801728,0.3638168401609363,0.34001188226184836,0.3880469953106932,0.4087401659115949,0.4220716765676118,0.3857131885115094,0.44983579668768514,0.4194119826488193,0.4418928071269632,0.34255356625364547,0.29099258014957,0.255365198980806,0.16752200609991313,0.10771471421710034,0.04465813653637925,-0.0030421917185819852,0.04134943950298765,0.08954303663385067,0.17438616545648755,0.1555561337684681,0.22480681900318872,0.19773093987011325,0.25061153529678526,0.31740888221923685,0.3019305033455298,0.3686949319206705,0.34184783268764063,0.34312435258759866,0.2934594233491111,0.3652305439499261,0.4912929487197564,0.3903921365152709,0.3889269157553741,0.30343213451822065,0.22729855654047892,0.1869146016479305,0.19068789488247395,0.18785927130137658,0.23832019074282057,0.2203924742377671,0.25996856221015163,0.38872363509644503,0.502716109669925,0.49269339381906296,0.5024231866959016,0.45146899736118185,0.4186864668910705,0.49084375028154736,0.4738318930327706,0.5341598191795845,0.5820948815322932,0.49860154456135086,0.5259342572109528,0.5554855921422516,0.5236638485016044,0.5863751047131588,0.5881652896008639,0.616856693187451,0.5869112063725983,0.5649368253570791,0.5922313908564539,0.5587550789056062,0.4724241997286823,0.39896928401806975,0.5356125464789098,0.4525193297341771,0.5728653278051802,0.679987107479637,0.6827316317874161,0.6984840360392159,0.5956571814407587,0.5975100032664404,0.6144854135571496,0.6657236357602648,0.7065421589381427,0.7201268114856024,0.5944111336320007,0.6297726740346837,0.8476080832663617,0.892292049021871,0.9518295910872363,0.8492219248208251,0.8611282397696448,0.7750048127224829,0.7798345756497178,0.7375503879280849,0.6610811350779893,0.5751883505957769,0.5684115556494203,0.5932587754738291,0.7225145866484559,0.6747774922967001,0.44955314996403295,0.4036518923379392,0.41865713347645594,0.48744534649377225,0.534627749708109,0.5368139726210983,0.5025506030707894,0.6643686585158284,0.6858638210367447,0.7484437688168387,0.8628463354996512,0.6793647171202369,0.7714287713317304,0.7763498196063189,0.6599211688974658,0.6659555803484262,0.7043206737448469,0.6535477089016203,0.6330323897870251,0.5491822066630451,0.5230948805062912,0.5822995093537293,0.6999410626050672,0.6280204453099756,0.5910931339132923,0.4624669857670731,0.4163901437653813,0.4625108782361339,0.45981795473522613,0.556945406864676,0.49871044843998924,0.5918465197024528,0.5704150081935379,0.6111084533435145,0.6765672481898027,0.5892052728534327,0.6833353798572406,0.6326137758812782,0.5829267260265394,0.6894373821867739,0.7248537042341894,0.770444326294894,0.735107118631736,0.6605669698427648,0.7086720251826941,0.7406198975332208,0.8269763271977273,0.8367253975215128,0.7272436875627961,0.5795634932496465,0.5462385733227195,0.5573203743090612,0.6091064838803822,0.6105388689344824,0.5422390453755899,0.5302334360019464,0.5192003149726131,0.6124948079011524,0.7222377892619666,0.7065787345983242,0.7493941739418616,0.8432552659587524],\"type\":\"scatter\"},{\"fill\":\"tonexty\",\"fillcolor\":\"rgba(190, 190, 190, 0.3)\",\"line\":{\"width\":0},\"marker\":{\"color\":\"#444\"},\"mode\":\"lines\",\"name\":\"upper\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161],\"y\":[0.35048632281947356,0.4097578970333926,0.4827960154996773,0.48353174708374075,0.4524689654776736,0.4283178135417499,0.41376672092603917,0.5336253556478199,0.5554889281285833,0.5316839702294954,0.5797190832783402,0.6004122538792419,0.6137437645352588,0.5773852764791564,0.6415078846553322,0.6110840706164663,0.6335648950946102,0.5342256542212925,0.48266466811721703,0.447037286948453,0.35919409406756014,0.2993868021847474,0.2363302245040263,0.18862989624906507,0.2330215274706347,0.2812151246014977,0.36605825342413456,0.3472282217361151,0.4164789069708357,0.38940302783776026,0.44228362326443227,0.5090809701868839,0.4936025913131768,0.5603670198883175,0.5335199206552876,0.5347964405552457,0.48513151131675813,0.5569026319175732,0.6829650366874034,0.582064224482918,0.5805990037230211,0.49510422248586766,0.41897064450812593,0.3785866896155775,0.38235998285012096,0.3795313592690236,0.4299922787104676,0.4120645622054141,0.45164065017779864,0.580395723064092,0.694388197637572,0.68436548178671,0.6940952746635486,0.6431410853288289,0.6103585548587175,0.6825158382491944,0.6655039810004176,0.7258319071472316,0.7737669694999402,0.6902736325289979,0.7176063451785998,0.7471576801098986,0.7153359364692514,0.7780471926808058,0.7798373775685109,0.808528781155098,0.7785832943402453,0.7566089133247261,0.7839034788241009,0.7504271668732532,0.6640962876963293,0.5906413719857168,0.7272846344465568,0.6441914177018241,0.7645374157728272,0.871659195447284,0.8744037197550631,0.890156124006863,0.7873292694084058,0.7891820912340874,0.8061575015247966,0.8573957237279118,0.8982142469057897,0.9117988994532494,0.7860832215996477,0.8214447620023307,1.0392801712340087,1.083964136989518,1.1435016790548833,1.0408940127884723,1.052800327737292,0.9666769006901299,0.9715066636173648,0.9292224758957319,0.8527532230456363,0.7668604385634239,0.7600836436170673,0.7849308634414761,0.9141866746161029,0.8664495802643472,0.64122523793168,0.5953239803055862,0.610329221444103,0.6791174344614193,0.726299837675756,0.7284860605887453,0.6942226910384364,0.8560407464834754,0.8775359090043917,0.9401158567844857,1.0545184234672982,0.871036805087884,0.9631008592993774,0.9680219075739659,0.8515932568651128,0.8576276683160732,0.8959927617124939,0.8452197968692673,0.8247044777546721,0.7408542946306921,0.7147669684739382,0.7739715973213763,0.8916131505727142,0.8196925332776226,0.7827652218809393,0.6541390737347201,0.6080622317330283,0.6541829662037809,0.6514900427028731,0.748617494832323,0.6903825364076362,0.7835186076700998,0.7620870961611849,0.8027805413111615,0.8682393361574497,0.7808773608210797,0.8750074678248876,0.8242858638489252,0.7745988139941864,0.8811094701544209,0.9165257922018364,0.962116414262541,0.926779206599383,0.8522390578104118,0.9003441131503411,0.9322919855008678,1.0186484151653743,1.0283974854891598,0.9189157755304431,0.7712355812172935,0.7379106612903665,0.7489924622767082,0.8007785718480293,0.8022109569021294,0.7339111333432369,0.7219055239695934,0.7108724029402601,0.8041668958687994,0.9139098772296136,0.8982508225659712,0.9410662619095086,1.0349273539263995],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Models\"},\"height\":800,\"width\":1500},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('f7cb077d-fad3-4007-b238-dbad243546d4');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8crRD7O8aQ8t"
      },
      "outputs": [],
      "source": [
        "invn = (max - min) + min \n",
        "y_plt = np.array([k*invn for k in y_test])\n",
        "pred_mlp = np.array([k*invn for k in pred_mlp])\n",
        "#pred_mlp = list(itertools.chain(*pred_mlp))\n",
        "pred_lstm = np.array([k* invn for k in pred_lstm])\n",
        "#pred_lstm =list(itertools.chain(*pred_lstm))\n",
        "pred_LGBM =np.array([k* invn for k in pred_LGBM])\n",
        "#pred_LGBM =list(itertools.chain(*pred_LGBM))\n",
        "pred_SVR =np.array([k* invn for k in pred_SVR])\n",
        "#pred_SVR =list(itertools.chain(*pred_SVR))\n",
        "pred_Ensemble =np.array([k* invn for k in dat])\n",
        "#pred_Ensemble =dat"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_mlp = list(itertools.chain(*pred_mlp))\n",
        "pred_lstm =list(itertools.chain(*pred_lstm))"
      ],
      "metadata": {
        "id": "LgqnYUvHuHNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESLKX3goReWC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "outputId": "074d0835-91e3-4431-a826-0acf6248ecf6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"d8b6cc5b-afad-491c-856b-99249598b38d\" class=\"plotly-graph-div\" style=\"height:800px; width:1500px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d8b6cc5b-afad-491c-856b-99249598b38d\")) {                    Plotly.newPlot(                        \"d8b6cc5b-afad-491c-856b-99249598b38d\",                        [{\"name\":\"pred\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161],\"y\":[6694.51708984375,7159.9765625,8165.42578125,8392.529296875,7505.3837890625,7217.15283203125,7844.18017578125,8959.5224609375,9979.380859375,10802.666015625,10901.5126953125,10844.306640625,11571.390625,10826.0966796875,11271.896484375,11547.6806640625,11459.57421875,9515.0947265625,8871.1044921875,7788.734375,6629.48974609375,4497.22119140625,2880.357177734375,2208.365966796875,3152.72412109375,4182.91650390625,5716.00341796875,6115.88671875,6571.81689453125,6412.00732421875,7523.6630859375,8935.2548828125,9380.71875,9693.7841796875,9951.37109375,10321.5595703125,9541.416015625,9728.4541015625,11519.6630859375,11634.5947265625,10274.7744140625,8833.9326171875,7566.06982421875,6658.7509765625,6600.763671875,6147.6171875,7069.72802734375,7764.66357421875,7878.4033203125,9003.5927734375,12185.0068359375,12487.4755859375,11892.8779296875,11878.919921875,11824.0234375,11800.7763671875,11988.6943359375,12770.2548828125,13749.306640625,13166.84375,12589.486328125,13001.9326171875,13825.5244140625,14244.0732421875,13962.2529296875,14619.0107421875,14493.9384765625,13638.8056640625,13459.025390625,13294.1533203125,12166.576171875,11065.78515625,12485.490234375,12950.619140625,14650.337890625,16074.5263671875,16418.91796875,16462.134765625,15532.142578125,14886.2431640625,15302.7509765625,16429.22265625,17203.88671875,17116.48046875,15536.40625,15391.681640625,18393.75390625,21086.212890625,21762.064453125,19986.294921875,19807.48046875,18889.05078125,18303.443359375,17225.53125,16224.978515625,14406.458984375,14590.6787109375,14824.4482421875,17532.45703125,17092.533203125,12464.255859375,10199.1142578125,11775.6953125,13301.466796875,13682.4697265625,13942.4970703125,13878.400390625,16040.43359375,16781.541015625,17290.318359375,19082.509765625,18902.591796875,18082.521484375,18228.189453125,17832.705078125,16983.28125,16265.455078125,16403.02734375,16080.9345703125,15009.658203125,13892.0478515625,14237.3818359375,17175.021484375,16971.732421875,14309.3037109375,11974.515625,11845.435546875,11803.1025390625,12046.1796875,13436.755859375,13575.1435546875,14934.6318359375,15497.0517578125,14957.6611328125,15942.2841796875,16062.3818359375,16295.5478515625,16351.4658203125,15960.0244140625,16352.154296875,17070.83984375,18228.87890625,17803.83984375,16656.0625,16656.85546875,17562.546875,19431.40234375,19983.67578125,17596.33203125,14894.001953125,14054.9951171875,14152.1005859375,14841.2529296875,14908.8466796875,13985.2099609375,14126.7275390625,14276.3583984375,14595.6982421875,16427.3671875,17121.607421875,17713.896484375,19627.001953125],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"name\":\"true\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161],\"y\":[5344.023014670782,6587.880504885346,8120.639030879285,8136.0788981978385,7484.203626112821,6977.373975791941,6672.008616749272,9187.330042623724,9646.153158994746,9146.588644643289,10154.640749746275,10588.902123593418,10868.673660038754,10105.664101051212,11451.324099622661,10812.858030937557,11284.634633536574,9199.9277488072,8117.882609649378,7370.215865325086,5526.761985815975,4271.662067102907,2948.373500944957,1947.3471004736564,2878.9380651156116,3890.3160750070665,5670.811408206657,5275.64937199031,6728.9258316438845,6160.718634341012,7270.456743726767,8672.248098147054,8347.422956352219,9748.52349509212,9185.117411916151,9211.906118982377,8169.651124854656,9675.82077066528,12321.33286456527,10203.855259257982,10173.10652613951,8378.935788708417,6781.216772799271,5933.729837556251,6012.91516568038,5953.554423621344,7012.513856414916,6636.287566612454,7466.820821561515,10168.84053230388,12561.056281704694,12350.72223290092,12554.90907808935,11485.598014525285,10797.632550232633,12311.906105627799,11954.899794558998,13220.925605447681,14226.878073255037,12474.709112810477,13048.306149973458,13668.462604186603,13000.65995672779,14316.701698389317,14354.270042253516,14956.380206008278,14327.952185211274,13866.803670404937,14439.600161620396,13737.075183718882,11925.35831732582,10383.852995230483,13251.412154125857,11507.64001031655,14033.189113799135,16281.218287653892,16338.81414473348,16669.38991022222,14511.49289156232,14550.37571754547,14906.617162447155,15981.888864234626,16838.495533918405,17123.57943876182,14485.343663696442,15227.4315444174,19798.867498334537,20736.593317744766,21986.032338542333,19832.735147914656,20082.59790635081,18275.234575170663,18376.590695244675,17489.22597931242,15884.462579821573,14081.939452158536,13939.723436041751,14461.160581916321,17173.688653181267,16171.890689182419,11445.392550664126,10482.12096785745,10797.01696699622,12240.588107712958,13230.745471049773,13276.624963566472,12557.583004239988,15953.45367220683,16404.54543515755,17717.831573004492,20118.653406327256,16268.15696912736,18200.18872177134,18303.460531863013,15860.11983810811,15986.75639166452,16791.876036566962,15726.368101975657,15295.839072111647,13536.181433220512,12988.719745723633,14231.172338284696,16699.966682164108,15190.659738493516,14415.713004187552,11716.398873746402,10749.442523938871,11717.319989426716,11660.807013154317,13699.097887640684,12476.994540639149,14431.523357958255,13981.767358214227,14835.749173675227,16209.450030280002,14376.094854156381,16351.484241129829,15287.05415203694,14244.334940540653,16479.539238884794,17222.776752630194,18179.529420090672,17437.952179768876,15873.672444963104,16883.192340382142,17553.641891396248,19365.89495352529,19570.486350087547,17272.93230702877,14173.755032104698,13474.40712694691,13706.966854687213,14793.73637504581,14823.796026776732,13390.47409732288,13138.527572499692,12906.989429388297,14864.842841651503,17167.879856856507,16839.26310099385,17737.77652215046,19707.520432166453],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"name\":\"pred\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161],\"y\":[6112.67138671875,6054.34716796875,6575.11669921875,7307.9453125,7727.97705078125,7719.51611328125,7596.828125,7583.0888671875,7821.6640625,8132.24267578125,8557.8994140625,9073.369140625,9505.654296875,9419.9501953125,9482.30078125,9716.7685546875,9954.4013671875,9724.2548828125,9086.5068359375,8233.193359375,7219.00732421875,5985.9755859375,4814.5830078125,3950.06298828125,3517.425537109375,3505.1640625,4160.49853515625,5112.37451171875,6121.8427734375,6831.27197265625,7337.6201171875,7848.9345703125,8246.794921875,8606.18359375,8808.65234375,8930.8720703125,8588.505859375,8321.5498046875,8645.484375,9029.306640625,9120.7978515625,8926.8447265625,8299.025390625,7403.4775390625,6676.5751953125,6182.111328125,6190.3955078125,6531.0673828125,6879.6923828125,7438.99267578125,8427.7431640625,9504.6787109375,10343.966796875,10781.84765625,10914.962890625,10962.025390625,10947.5927734375,11084.916015625,11615.9755859375,12003.3564453125,11819.498046875,11673.337890625,11744.88671875,12104.2958984375,12580.8935546875,13183.1630859375,13574.0283203125,13638.037109375,13473.1669921875,13071.697265625,12376.2177734375,11556.078125,11327.49609375,11205.8486328125,11668.3544921875,12645.9892578125,13746.763671875,14589.748046875,14801.5595703125,14500.96484375,14101.6904296875,14296.4326171875,14905.2958984375,15489.3154296875,15197.3310546875,14746.6796875,15358.8203125,16461.583984375,17700.828125,18508.095703125,19131.466796875,18874.142578125,18100.603515625,17098.115234375,16158.7412109375,15291.5771484375,14656.2138671875,13993.462890625,14399.9775390625,15136.2587890625,14414.05859375,12918.82421875,12208.5322265625,12199.11328125,12298.6318359375,12666.689453125,13161.2958984375,14144.4482421875,14962.580078125,15403.42578125,16106.31640625,16665.255859375,16858.21875,16890.9140625,16335.27734375,15694.111328125,15514.7587890625,15270.84765625,14723.3759765625,14157.45703125,13533.7109375,13074.421875,13750.1083984375,14606.1005859375,14629.5791015625,13729.1689453125,12877.3125,12023.5048828125,11505.3779296875,11716.2685546875,12232.6494140625,13044.091796875,13580.927734375,13621.2275390625,13922.49609375,14250.884765625,14624.630859375,14799.1376953125,14526.4853515625,14689.7451171875,15182.759765625,15694.716796875,15923.4921875,15834.681640625,15582.8037109375,15567.4453125,16174.96484375,17054.060546875,17186.60546875,16180.6083984375,14882.4345703125,13734.1103515625,13356.533203125,13459.2890625,13607.0888671875,13761.576171875,13649.41796875,13638.8916015625,14202.8740234375,15017.28125,15958.9873046875,17067.7734375],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"name\":\"true\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161],\"y\":[5344.023014670782,6587.880504885346,8120.639030879285,8136.0788981978385,7484.203626112821,6977.373975791941,6672.008616749272,9187.330042623724,9646.153158994746,9146.588644643289,10154.640749746275,10588.902123593418,10868.673660038754,10105.664101051212,11451.324099622661,10812.858030937557,11284.634633536574,9199.9277488072,8117.882609649378,7370.215865325086,5526.761985815975,4271.662067102907,2948.373500944957,1947.3471004736564,2878.9380651156116,3890.3160750070665,5670.811408206657,5275.64937199031,6728.9258316438845,6160.718634341012,7270.456743726767,8672.248098147054,8347.422956352219,9748.52349509212,9185.117411916151,9211.906118982377,8169.651124854656,9675.82077066528,12321.33286456527,10203.855259257982,10173.10652613951,8378.935788708417,6781.216772799271,5933.729837556251,6012.91516568038,5953.554423621344,7012.513856414916,6636.287566612454,7466.820821561515,10168.84053230388,12561.056281704694,12350.72223290092,12554.90907808935,11485.598014525285,10797.632550232633,12311.906105627799,11954.899794558998,13220.925605447681,14226.878073255037,12474.709112810477,13048.306149973458,13668.462604186603,13000.65995672779,14316.701698389317,14354.270042253516,14956.380206008278,14327.952185211274,13866.803670404937,14439.600161620396,13737.075183718882,11925.35831732582,10383.852995230483,13251.412154125857,11507.64001031655,14033.189113799135,16281.218287653892,16338.81414473348,16669.38991022222,14511.49289156232,14550.37571754547,14906.617162447155,15981.888864234626,16838.495533918405,17123.57943876182,14485.343663696442,15227.4315444174,19798.867498334537,20736.593317744766,21986.032338542333,19832.735147914656,20082.59790635081,18275.234575170663,18376.590695244675,17489.22597931242,15884.462579821573,14081.939452158536,13939.723436041751,14461.160581916321,17173.688653181267,16171.890689182419,11445.392550664126,10482.12096785745,10797.01696699622,12240.588107712958,13230.745471049773,13276.624963566472,12557.583004239988,15953.45367220683,16404.54543515755,17717.831573004492,20118.653406327256,16268.15696912736,18200.18872177134,18303.460531863013,15860.11983810811,15986.75639166452,16791.876036566962,15726.368101975657,15295.839072111647,13536.181433220512,12988.719745723633,14231.172338284696,16699.966682164108,15190.659738493516,14415.713004187552,11716.398873746402,10749.442523938871,11717.319989426716,11660.807013154317,13699.097887640684,12476.994540639149,14431.523357958255,13981.767358214227,14835.749173675227,16209.450030280002,14376.094854156381,16351.484241129829,15287.05415203694,14244.334940540653,16479.539238884794,17222.776752630194,18179.529420090672,17437.952179768876,15873.672444963104,16883.192340382142,17553.641891396248,19365.89495352529,19570.486350087547,17272.93230702877,14173.755032104698,13474.40712694691,13706.966854687213,14793.73637504581,14823.796026776732,13390.47409732288,13138.527572499692,12906.989429388297,14864.842841651503,17167.879856856507,16839.26310099385,17737.77652215046,19707.520432166453],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"name\":\"pred\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161],\"y\":[6890.795561925503,6154.699396433805,8373.247315427123,8651.235129083967,7221.865358245097,6682.1207364202955,7319.204810765146,8201.851606396947,10016.229804605326,9897.37960255939,10735.14185656611,10659.731878069513,10675.040602133524,9388.321225588486,10370.617259487903,10398.281158281645,10199.541898219171,8506.945345904838,7385.380291305254,6418.318843150719,5551.325324234731,3361.83870553952,2525.2456490229074,1955.1709569390923,2348.259469943266,2982.949668302257,5467.55559304851,5962.864917252456,7131.862694291505,6876.506697086147,7125.0656921599,8446.320104588885,7680.55070120146,8766.363342425968,8725.545065096088,10211.891526777188,8236.979614855461,9385.653656182909,11354.177753828904,10167.969136481435,9484.534852965608,8208.109404777037,6556.178685322014,5199.497715604033,5322.798906900125,6135.634361473076,7689.280112012352,7994.451200205402,8447.784104445893,10491.930607414588,10811.127568348978,11224.939634337887,11190.828937225195,11154.126126772859,10939.694047583827,11627.033644624878,10955.801503788043,11726.712431537493,13476.76117972535,12290.04910429083,12482.845435682524,13216.19129698907,12664.083965828053,13014.807702556269,13436.251589454223,14814.23593191647,14132.453187929837,13283.271023169997,12759.620458413132,12930.030162993118,12321.201391123173,10098.911253177674,12263.801176422747,12246.653103482431,15343.423116119564,16330.612392340161,16149.898244001739,15260.844081216701,13977.920572797144,14736.663816923234,15040.473235092779,16364.319277395014,17424.89991728417,17897.388915370368,14544.957187829834,15054.106462522946,18564.733804584357,19193.72588099468,19156.103097469622,19732.848849946324,19627.15850324064,19514.922310715236,17662.268570472443,16180.260382765968,14935.257574278101,14206.870122608223,15070.668773917623,13440.451102571313,17097.208081011424,17430.58826861468,12393.803749769304,9911.893650983442,11026.161866023262,12819.619722684592,11686.863334099693,12823.572198665737,13875.397833063882,15385.157206299686,15139.262772203616,16953.19634637989,18300.95057298698,17983.18300589824,17867.98849968464,18026.747410265114,16761.835165918073,16516.97629659362,16709.39323963605,15225.050470594917,15558.825042767257,14806.701881420526,14006.978134103314,14198.796110458803,17864.98522117183,16236.305626532163,14558.230584389521,12213.200729065551,12075.791058246708,11228.226836184138,10618.317062071577,13049.257378648437,12801.807263326416,13933.686891030424,13247.38092625981,13918.765543622365,14932.229730305533,14325.765707550803,15436.049537247614,14082.233299211382,14060.798990904741,16921.191706614492,16893.351852650114,16825.478981127162,17112.522205534508,16092.443806977077,17055.66286961892,17504.33265649935,19147.354914807554,19009.33080119009,17392.588760020775,15859.717919540397,15407.649855474667,13195.097413921632,14847.495149938171,14381.47583977284,13309.262484886629,14436.120911877593,13682.381895940021,13262.25215180727,13796.674221406889,15109.73549701129,16433.147720463956,17364.574125963663],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"name\":\"true\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161],\"y\":[5344.023014670782,6587.880504885346,8120.639030879285,8136.0788981978385,7484.203626112821,6977.373975791941,6672.008616749272,9187.330042623724,9646.153158994746,9146.588644643289,10154.640749746275,10588.902123593418,10868.673660038754,10105.664101051212,11451.324099622661,10812.858030937557,11284.634633536574,9199.9277488072,8117.882609649378,7370.215865325086,5526.761985815975,4271.662067102907,2948.373500944957,1947.3471004736564,2878.9380651156116,3890.3160750070665,5670.811408206657,5275.64937199031,6728.9258316438845,6160.718634341012,7270.456743726767,8672.248098147054,8347.422956352219,9748.52349509212,9185.117411916151,9211.906118982377,8169.651124854656,9675.82077066528,12321.33286456527,10203.855259257982,10173.10652613951,8378.935788708417,6781.216772799271,5933.729837556251,6012.91516568038,5953.554423621344,7012.513856414916,6636.287566612454,7466.820821561515,10168.84053230388,12561.056281704694,12350.72223290092,12554.90907808935,11485.598014525285,10797.632550232633,12311.906105627799,11954.899794558998,13220.925605447681,14226.878073255037,12474.709112810477,13048.306149973458,13668.462604186603,13000.65995672779,14316.701698389317,14354.270042253516,14956.380206008278,14327.952185211274,13866.803670404937,14439.600161620396,13737.075183718882,11925.35831732582,10383.852995230483,13251.412154125857,11507.64001031655,14033.189113799135,16281.218287653892,16338.81414473348,16669.38991022222,14511.49289156232,14550.37571754547,14906.617162447155,15981.888864234626,16838.495533918405,17123.57943876182,14485.343663696442,15227.4315444174,19798.867498334537,20736.593317744766,21986.032338542333,19832.735147914656,20082.59790635081,18275.234575170663,18376.590695244675,17489.22597931242,15884.462579821573,14081.939452158536,13939.723436041751,14461.160581916321,17173.688653181267,16171.890689182419,11445.392550664126,10482.12096785745,10797.01696699622,12240.588107712958,13230.745471049773,13276.624963566472,12557.583004239988,15953.45367220683,16404.54543515755,17717.831573004492,20118.653406327256,16268.15696912736,18200.18872177134,18303.460531863013,15860.11983810811,15986.75639166452,16791.876036566962,15726.368101975657,15295.839072111647,13536.181433220512,12988.719745723633,14231.172338284696,16699.966682164108,15190.659738493516,14415.713004187552,11716.398873746402,10749.442523938871,11717.319989426716,11660.807013154317,13699.097887640684,12476.994540639149,14431.523357958255,13981.767358214227,14835.749173675227,16209.450030280002,14376.094854156381,16351.484241129829,15287.05415203694,14244.334940540653,16479.539238884794,17222.776752630194,18179.529420090672,17437.952179768876,15873.672444963104,16883.192340382142,17553.641891396248,19365.89495352529,19570.486350087547,17272.93230702877,14173.755032104698,13474.40712694691,13706.966854687213,14793.73637504581,14823.796026776732,13390.47409732288,13138.527572499692,12906.989429388297,14864.842841651503,17167.879856856507,16839.26310099385,17737.77652215046,19707.520432166453],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"name\":\"pred\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161],\"y\":[5344.023014670782,6587.880504885346,8120.639030879285,8136.0788981978385,7484.203626112821,6977.373975791941,6672.008616749272,9187.330042623724,9646.153158994746,9146.588644643289,10154.640749746275,10588.902123593418,10868.673660038754,10105.664101051212,11451.324099622661,10812.858030937557,11284.634633536574,9199.9277488072,8117.882609649378,7370.215865325086,5526.761985815975,4271.662067102907,2948.373500944957,1947.3471004736564,2878.9380651156116,3890.3160750070665,5670.811408206657,5275.64937199031,6728.9258316438845,6160.718634341012,7270.456743726767,8672.248098147054,8347.422956352219,9748.52349509212,9185.117411916151,9211.906118982377,8169.651124854656,9675.82077066528,12321.33286456527,10203.855259257982,10173.10652613951,8378.935788708417,6781.216772799271,5933.729837556251,6012.91516568038,5953.554423621344,7012.513856414916,6636.287566612454,7466.820821561515,10168.84053230388,12561.056281704694,12350.72223290092,12554.90907808935,11485.598014525285,10797.632550232633,12311.906105627799,11954.899794558998,13220.925605447681,14226.878073255037,12474.709112810477,13048.306149973458,13668.462604186603,13000.65995672779,14316.701698389317,14354.270042253516,14956.380206008278,14327.952185211274,13866.803670404937,14439.600161620396,13737.075183718882,11925.35831732582,10383.852995230483,13251.412154125857,11507.64001031655,14033.189113799135,16281.218287653892,16338.81414473348,16669.38991022222,14511.49289156232,14550.37571754547,14906.617162447155,15981.888864234626,16838.495533918405,17123.57943876182,14485.343663696442,15227.4315444174,19798.867498334537,20736.593317744766,21986.032338542333,19832.735147914656,20082.59790635081,18275.234575170663,18376.590695244675,17489.22597931242,15884.462579821573,14081.939452158536,13939.723436041751,14461.160581916321,17173.688653181267,16171.890689182419,11445.392550664126,10482.12096785745,10797.01696699622,12240.588107712958,13230.745471049773,13276.624963566472,12557.583004239988,15953.45367220683,16404.54543515755,17717.831573004492,20118.653406327256,16268.15696912736,18200.18872177134,18303.460531863013,15860.11983810811,15986.75639166452,16791.876036566962,15726.368101975657,15295.839072111647,13536.181433220512,12988.719745723633,14231.172338284696,16699.966682164108,15190.659738493516,14415.713004187552,11716.398873746402,10749.442523938871,11717.319989426716,11660.807013154317,13699.097887640684,12476.994540639149,14431.523357958255,13981.767358214227,14835.749173675227,16209.450030280002,14376.094854156381,16351.484241129829,15287.05415203694,14244.334940540653,16479.539238884794,17222.776752630194,18179.529420090672,17437.952179768876,15873.672444963104,16883.192340382142,17553.641891396248,19365.89495352529,19570.486350087547,17272.93230702877,14173.755032104698,13474.40712694691,13706.966854687213,14793.73637504581,14823.796026776732,13390.47409732288,13138.527572499692,12906.989429388297,14864.842841651503,17167.879856856507,16839.26310099385,17737.77652215046,19707.520432166453],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"name\":\"true\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161],\"y\":[5344.023014670782,6587.880504885346,8120.639030879285,8136.0788981978385,7484.203626112821,6977.373975791941,6672.008616749272,9187.330042623724,9646.153158994746,9146.588644643289,10154.640749746275,10588.902123593418,10868.673660038754,10105.664101051212,11451.324099622661,10812.858030937557,11284.634633536574,9199.9277488072,8117.882609649378,7370.215865325086,5526.761985815975,4271.662067102907,2948.373500944957,1947.3471004736564,2878.9380651156116,3890.3160750070665,5670.811408206657,5275.64937199031,6728.9258316438845,6160.718634341012,7270.456743726767,8672.248098147054,8347.422956352219,9748.52349509212,9185.117411916151,9211.906118982377,8169.651124854656,9675.82077066528,12321.33286456527,10203.855259257982,10173.10652613951,8378.935788708417,6781.216772799271,5933.729837556251,6012.91516568038,5953.554423621344,7012.513856414916,6636.287566612454,7466.820821561515,10168.84053230388,12561.056281704694,12350.72223290092,12554.90907808935,11485.598014525285,10797.632550232633,12311.906105627799,11954.899794558998,13220.925605447681,14226.878073255037,12474.709112810477,13048.306149973458,13668.462604186603,13000.65995672779,14316.701698389317,14354.270042253516,14956.380206008278,14327.952185211274,13866.803670404937,14439.600161620396,13737.075183718882,11925.35831732582,10383.852995230483,13251.412154125857,11507.64001031655,14033.189113799135,16281.218287653892,16338.81414473348,16669.38991022222,14511.49289156232,14550.37571754547,14906.617162447155,15981.888864234626,16838.495533918405,17123.57943876182,14485.343663696442,15227.4315444174,19798.867498334537,20736.593317744766,21986.032338542333,19832.735147914656,20082.59790635081,18275.234575170663,18376.590695244675,17489.22597931242,15884.462579821573,14081.939452158536,13939.723436041751,14461.160581916321,17173.688653181267,16171.890689182419,11445.392550664126,10482.12096785745,10797.01696699622,12240.588107712958,13230.745471049773,13276.624963566472,12557.583004239988,15953.45367220683,16404.54543515755,17717.831573004492,20118.653406327256,16268.15696912736,18200.18872177134,18303.460531863013,15860.11983810811,15986.75639166452,16791.876036566962,15726.368101975657,15295.839072111647,13536.181433220512,12988.719745723633,14231.172338284696,16699.966682164108,15190.659738493516,14415.713004187552,11716.398873746402,10749.442523938871,11717.319989426716,11660.807013154317,13699.097887640684,12476.994540639149,14431.523357958255,13981.767358214227,14835.749173675227,16209.450030280002,14376.094854156381,16351.484241129829,15287.05415203694,14244.334940540653,16479.539238884794,17222.776752630194,18179.529420090672,17437.952179768876,15873.672444963104,16883.192340382142,17553.641891396248,19365.89495352529,19570.486350087547,17272.93230702877,14173.755032104698,13474.40712694691,13706.966854687213,14793.73637504581,14823.796026776732,13390.47409732288,13138.527572499692,12906.989429388297,14864.842841651503,17167.879856856507,16839.26310099385,17737.77652215046,19707.520432166453],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"name\":\"pred\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161],\"y\":[5344.023014670782,6587.880504885346,8120.639030879285,8136.0788981978385,7484.203626112821,6977.373975791941,6672.008616749272,9187.330042623724,9646.153158994746,9146.588644643289,10154.640749746275,10588.902123593418,10868.673660038754,10105.664101051212,11451.324099622661,10812.858030937557,11284.634633536574,9199.9277488072,8117.882609649378,7370.215865325086,5526.761985815975,4271.662067102907,2948.373500944957,1947.3471004736564,2878.9380651156116,3890.3160750070665,5670.811408206657,5275.64937199031,6728.9258316438845,6160.718634341012,7270.456743726767,8672.248098147054,8347.422956352219,9748.52349509212,9185.117411916151,9211.906118982377,8169.651124854656,9675.82077066528,12321.33286456527,10203.855259257982,10173.10652613951,8378.935788708417,6781.216772799271,5933.729837556251,6012.91516568038,5953.554423621344,7012.513856414916,6636.287566612454,7466.820821561515,10168.84053230388,12561.056281704694,12350.72223290092,12554.90907808935,11485.598014525285,10797.632550232633,12311.906105627799,11954.899794558998,13220.925605447681,14226.878073255037,12474.709112810477,13048.306149973458,13668.462604186603,13000.65995672779,14316.701698389317,14354.270042253516,14956.380206008278,14327.952185211274,13866.803670404937,14439.600161620396,13737.075183718882,11925.35831732582,10383.852995230483,13251.412154125857,11507.64001031655,14033.189113799135,16281.218287653892,16338.81414473348,16669.38991022222,14511.49289156232,14550.37571754547,14906.617162447155,15981.888864234626,16838.495533918405,17123.57943876182,14485.343663696442,15227.4315444174,19798.867498334537,20736.593317744766,21986.032338542333,19832.735147914656,20082.59790635081,18275.234575170663,18376.590695244675,17489.22597931242,15884.462579821573,14081.939452158536,13939.723436041751,14461.160581916321,17173.688653181267,16171.890689182419,11445.392550664126,10482.12096785745,10797.01696699622,12240.588107712958,13230.745471049773,13276.624963566472,12557.583004239988,15953.45367220683,16404.54543515755,17717.831573004492,20118.653406327256,16268.15696912736,18200.18872177134,18303.460531863013,15860.11983810811,15986.75639166452,16791.876036566962,15726.368101975657,15295.839072111647,13536.181433220512,12988.719745723633,14231.172338284696,16699.966682164108,15190.659738493516,14415.713004187552,11716.398873746402,10749.442523938871,11717.319989426716,11660.807013154317,13699.097887640684,12476.994540639149,14431.523357958255,13981.767358214227,14835.749173675227,16209.450030280002,14376.094854156381,16351.484241129829,15287.05415203694,14244.334940540653,16479.539238884794,17222.776752630194,18179.529420090672,17437.952179768876,15873.672444963104,16883.192340382142,17553.641891396248,19365.89495352529,19570.486350087547,17272.93230702877,14173.755032104698,13474.40712694691,13706.966854687213,14793.73637504581,14823.796026776732,13390.47409732288,13138.527572499692,12906.989429388297,14864.842841651503,17167.879856856507,16839.26310099385,17737.77652215046,19707.520432166453],\"type\":\"scatter\",\"xaxis\":\"x5\",\"yaxis\":\"y5\"},{\"name\":\"true\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161],\"y\":[5344.023014670782,6587.880504885346,8120.639030879285,8136.0788981978385,7484.203626112821,6977.373975791941,6672.008616749272,9187.330042623724,9646.153158994746,9146.588644643289,10154.640749746275,10588.902123593418,10868.673660038754,10105.664101051212,11451.324099622661,10812.858030937557,11284.634633536574,9199.9277488072,8117.882609649378,7370.215865325086,5526.761985815975,4271.662067102907,2948.373500944957,1947.3471004736564,2878.9380651156116,3890.3160750070665,5670.811408206657,5275.64937199031,6728.9258316438845,6160.718634341012,7270.456743726767,8672.248098147054,8347.422956352219,9748.52349509212,9185.117411916151,9211.906118982377,8169.651124854656,9675.82077066528,12321.33286456527,10203.855259257982,10173.10652613951,8378.935788708417,6781.216772799271,5933.729837556251,6012.91516568038,5953.554423621344,7012.513856414916,6636.287566612454,7466.820821561515,10168.84053230388,12561.056281704694,12350.72223290092,12554.90907808935,11485.598014525285,10797.632550232633,12311.906105627799,11954.899794558998,13220.925605447681,14226.878073255037,12474.709112810477,13048.306149973458,13668.462604186603,13000.65995672779,14316.701698389317,14354.270042253516,14956.380206008278,14327.952185211274,13866.803670404937,14439.600161620396,13737.075183718882,11925.35831732582,10383.852995230483,13251.412154125857,11507.64001031655,14033.189113799135,16281.218287653892,16338.81414473348,16669.38991022222,14511.49289156232,14550.37571754547,14906.617162447155,15981.888864234626,16838.495533918405,17123.57943876182,14485.343663696442,15227.4315444174,19798.867498334537,20736.593317744766,21986.032338542333,19832.735147914656,20082.59790635081,18275.234575170663,18376.590695244675,17489.22597931242,15884.462579821573,14081.939452158536,13939.723436041751,14461.160581916321,17173.688653181267,16171.890689182419,11445.392550664126,10482.12096785745,10797.01696699622,12240.588107712958,13230.745471049773,13276.624963566472,12557.583004239988,15953.45367220683,16404.54543515755,17717.831573004492,20118.653406327256,16268.15696912736,18200.18872177134,18303.460531863013,15860.11983810811,15986.75639166452,16791.876036566962,15726.368101975657,15295.839072111647,13536.181433220512,12988.719745723633,14231.172338284696,16699.966682164108,15190.659738493516,14415.713004187552,11716.398873746402,10749.442523938871,11717.319989426716,11660.807013154317,13699.097887640684,12476.994540639149,14431.523357958255,13981.767358214227,14835.749173675227,16209.450030280002,14376.094854156381,16351.484241129829,15287.05415203694,14244.334940540653,16479.539238884794,17222.776752630194,18179.529420090672,17437.952179768876,15873.672444963104,16883.192340382142,17553.641891396248,19365.89495352529,19570.486350087547,17272.93230702877,14173.755032104698,13474.40712694691,13706.966854687213,14793.73637504581,14823.796026776732,13390.47409732288,13138.527572499692,12906.989429388297,14864.842841651503,17167.879856856507,16839.26310099385,17737.77652215046,19707.520432166453],\"type\":\"scatter\",\"xaxis\":\"x5\",\"yaxis\":\"y5\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.16799999999999998]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.208,0.376]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0]},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.416,0.584]},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,1.0]},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.624,0.792]},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,1.0]},\"xaxis5\":{\"anchor\":\"y5\",\"domain\":[0.832,1.0]},\"yaxis5\":{\"anchor\":\"x5\",\"domain\":[0.0,1.0]},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"MLP\",\"x\":0.08399999999999999,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"LSTM\",\"x\":0.292,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"LGBM\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"SVR\",\"x\":0.708,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Emsemble\",\"x\":0.9159999999999999,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Models\"},\"height\":800,\"width\":1500},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d8b6cc5b-afad-491c-856b-99249598b38d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig = go.Figure()\n",
        "#y_plt= list(itertools.chain(*y_plt))\n",
        "y_hat=np.array(fitted.iloc[585:791])\n",
        "fig = make_subplots(rows=1, cols=5,subplot_titles=(\"MLP\", \"LSTM\",\"LGBM\",\"SVR\",\"Emsemble\"))\n",
        "fig.add_trace(go.Scatter(x=np.arange(len(pred_mlp)), y=pred_mlp,name='pred'),row=1,col=1)\n",
        "fig.add_trace(go.Scatter(x=np.arange(len(y_plt)), y=y_plt,name='true'),row=1,col=1)\n",
        "fig.add_trace(go.Scatter(x=np.arange(len(pred_lstm)), y=pred_lstm,name='pred'),row=1,col=2)\n",
        "fig.add_trace(go.Scatter(x=np.arange(len(y_plt)), y=y_plt,name='true'),row=1,col=2)\n",
        "fig.add_trace(go.Scatter(x=np.arange(len(pred_LGBM)), y=pred_LGBM,name='pred'),row=1,col=3)\n",
        "fig.add_trace(go.Scatter(x=np.arange(len(y_plt)), y=y_plt,name='true'),row=1,col=3)\n",
        "fig.add_trace(go.Scatter(x=np.arange(len(pred_SVR)), y=pred_SVR,name='pred'),row=1,col=4)\n",
        "fig.add_trace(go.Scatter(x=np.arange(len(y_plt)), y=y_plt,name='true'),row=1,col=4)\n",
        "fig.add_trace(go.Scatter(x=np.arange(len(pred_Ensemble)), y=pred_SVR,name='pred'),row=1,col=5)\n",
        "fig.add_trace(go.Scatter(x=np.arange(len(y_plt)), y=y_plt,name='true'),row=1,col=5)\n",
        "fig.update_layout(title='Models',height=800,width=1500)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "cm2YuZnwEZbs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "332ed8e0-7b88-434d-96ca-da0a71261153"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           MLP      LSTM      LGBM       SVR  Ensemble\n",
              "mse   0.003235  0.008041  0.003684  0.002644  0.000489\n",
              "mae   0.043695  0.072697  0.046491  0.040567  0.018458\n",
              "mape  0.076624  0.141688  0.086258  0.074784  0.034034"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad761186-0840-470a-bd53-52f69de5581d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MLP</th>\n",
              "      <th>LSTM</th>\n",
              "      <th>LGBM</th>\n",
              "      <th>SVR</th>\n",
              "      <th>Ensemble</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>mse</th>\n",
              "      <td>0.003235</td>\n",
              "      <td>0.008041</td>\n",
              "      <td>0.003684</td>\n",
              "      <td>0.002644</td>\n",
              "      <td>0.000489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mae</th>\n",
              "      <td>0.043695</td>\n",
              "      <td>0.072697</td>\n",
              "      <td>0.046491</td>\n",
              "      <td>0.040567</td>\n",
              "      <td>0.018458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mape</th>\n",
              "      <td>0.076624</td>\n",
              "      <td>0.141688</td>\n",
              "      <td>0.086258</td>\n",
              "      <td>0.074784</td>\n",
              "      <td>0.034034</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad761186-0840-470a-bd53-52f69de5581d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ad761186-0840-470a-bd53-52f69de5581d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ad761186-0840-470a-bd53-52f69de5581d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Análise de resíduos"
      ],
      "metadata": {
        "id": "fVqeQQcEkUaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diff_SVR   = y_plt - pred_SVR\n",
        "diff_Ensemble   = y_plt - pred_Ensemble  \n",
        "diff_mlp   = y_plt - pred_mlp\n",
        "diff_lstm  = y_plt - pred_lstm\n",
        "diff_LGBM   = y_plt - pred_LGBM\n",
        "#diff_arima =list(itertools.chain(*diff_arima)) \n",
        "#diff_mlp =list(itertools.chain(*diff_mlp)) \n",
        "#diff_lstm =list(itertools.chain(*diff_lstm)) \n",
        "#diff_cnn =list(itertools.chain(*diff_cnn)) "
      ],
      "metadata": {
        "id": "vgcpm1nwkuqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure()\n",
        "fig = make_subplots(rows=1, cols=5,subplot_titles=(\"SVR\",\"MLP\",\"LSTM\",\"LGBM\",\"Ensemble\"))\n",
        "fig.add_trace(go.Bar(x=np.arange(len(diff_SVR)), y=diff_SVR,name='Erro SVR'),row=1,col=1)\n",
        "fig.add_trace(go.Bar(x=np.arange(len(diff_mlp)), y=diff_mlp,name='Erro MLP'),row=1,col=2)\n",
        "fig.add_trace(go.Bar(x=np.arange(len(diff_lstm)), y=diff_lstm,name='Erro LSTM'),row=1,col=3)\n",
        "fig.add_trace(go.Bar(x=np.arange(len(diff_LGBM)), y=diff_LGBM,name='Erro LGBM'),row=1,col=4)\n",
        "fig.add_trace(go.Bar(x=np.arange(len(diff_Ensemble)), y=diff_Ensemble,name='Erro Ensemble'),row=1,col=5)\n",
        "fig.update_layout(height=800,width=1500)\n",
        "fig.update_traces(marker_color='rgb(225,0,0)', marker_line_color='rgb(190,190,190)')\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "2LtKxV48k0K9",
        "outputId": "a78efc7a-0e9c-478c-ee74-51014b96eaf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"0330b037-799f-477f-a8d4-bf2987897871\" class=\"plotly-graph-div\" style=\"height:800px; width:1500px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0330b037-799f-477f-a8d4-bf2987897871\")) {                    Plotly.newPlot(                        \"0330b037-799f-477f-a8d4-bf2987897871\",                        [{\"name\":\"Erro SVR\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161],\"y\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"type\":\"bar\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"marker\":{\"line\":{\"color\":\"rgb(190,190,190)\"},\"color\":\"rgb(225,0,0)\"}},{\"name\":\"Erro MLP\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161],\"y\":[-1350.4940751729682,-572.0960576146535,-44.7867503707148,-256.4503986771615,-21.18016294967856,-239.77885623930888,-1172.1715590319782,227.80758168622378,-333.22770038025374,-1656.0773709817113,-746.8719455662249,-255.40451703158215,-702.716964961246,-720.4325786362879,179.42761524766138,-734.8226331249425,-174.93958521342574,-315.16697775529974,-753.2218825381224,-418.51850967491373,-1102.727760277775,-225.5591243033432,68.01632321058196,-261.0188663232186,-273.7860559781384,-292.6004288991835,-45.19200976209322,-840.2373467596899,157.10893711263452,-251.28868987773785,-253.20634221073306,-263.0067846654456,-1033.2957936477815,54.739315404620356,-766.2536818338485,-1109.653451330123,-1371.7648907703442,-52.63333089722073,801.6697786277691,-1430.7394673045183,-101.6678879229894,-454.996828479083,-784.853051419479,-725.0211390062486,-587.8485061946203,-194.06276387865637,-57.21417092883439,-1128.3760076062963,-411.582498750985,1165.2477588663805,376.0494457671939,-136.75335303657994,662.0311484018494,-393.3219073497148,-1026.3908872673674,511.12973844029875,-33.79454137850189,450.67072263518094,477.5714326300367,-692.1346371895233,458.81982184845765,666.5299869991031,-824.8644573347101,72.62845620181724,392.0171125660163,337.36946382077804,-165.9862913512261,227.9980063424373,980.5747709953957,442.9218634063818,-241.21785454918063,-681.9321610195166,765.9219197508573,-1442.9791303084494,-617.1487768258648,206.69192046639182,-80.10382401651987,207.25514459722035,-1020.6496865626796,-335.86744651702975,-396.13381411534465,-447.33379201537355,-365.3911848315947,7.098970011818892,-1051.0625863035584,-164.2500962075992,1405.1135920845372,-349.61957288023405,223.96788541733258,-153.5597739603436,275.11743760080935,-613.8162060793366,73.14733586967486,263.69472931242126,-340.51593580342706,-324.51953221646363,-650.9552748957485,-363.28766027117854,-358.768378068733,-920.642513942581,-1018.8633087108738,283.0067100449505,-978.6783455037803,-1060.878689162042,-451.7242555127268,-665.8721067460283,-1320.8173863850116,-86.97992154317035,-376.99558046745005,427.5132136294924,1036.1436407022557,-2634.43482774764,117.66723739634108,75.27107873801287,-1972.5852400168897,-996.5248583354805,526.4209584419623,-676.6592417743432,-785.0954982008534,-1473.4767699044878,-903.3281058388675,-6.2094976528042025,-475.0548022108924,-1781.0726833814842,106.40929325005163,-258.1167512535976,-1095.993022936129,-85.78254963578365,-385.37267434568275,262.34202826568435,-1098.149014048351,-503.10847797924544,-1515.284399598273,-121.91195913727279,267.16585059250247,-1686.2869817811188,55.93638956732866,-1064.4116682755594,-1715.6894735218466,127.38494200979403,151.9369088801941,-49.34948615932808,-365.8876639811242,-782.3900550368962,226.336871632142,-8.904983603752044,-65.50739022470952,-413.1894311624528,-323.39972422123174,-720.2469210203017,-580.5879902405904,-445.1337312502874,-47.51655464169016,-85.0506529107679,-594.73586361462,-988.1999665628082,-1369.3689690492029,269.1445994640035,740.5126693565071,-282.34432088115136,23.88003777545964,80.51847904145325],\"type\":\"bar\",\"xaxis\":\"x2\",\"yaxis\":\"y2\",\"marker\":{\"line\":{\"color\":\"rgb(190,190,190)\"},\"color\":\"rgb(225,0,0)\"}},{\"name\":\"Erro LSTM\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161],\"y\":[-768.6483720479682,533.5333369165965,1545.5223316605352,828.1335856978385,-243.77342466842856,-742.1421374893089,-924.8195082507282,1604.2411754362238,1824.4890964947463,1014.3459688620387,1596.741335683775,1515.5329829684179,1363.019363163754,685.7139057387121,1969.0233183726614,1096.0894762500575,1330.2332663490743,-524.3271340052997,-968.6242262881224,-862.9774940499137,-1692.245338402775,-1714.3135188345932,-1866.209506867543,-2002.7158878075936,-638.4874719937634,385.1520125070665,1510.3128730504068,163.2748602715601,607.0830582063845,-670.5533383152379,-67.16337346073306,823.3135278345544,100.62803447721853,1142.3399013421204,376.46506816615147,281.03404866987694,-418.8547345203442,1354.2709659777793,3675.848489565269,1174.5486186329817,1052.3086745770106,-547.908937854083,-1517.808617825729,-1469.7477015062486,-663.6600296321203,-228.55690450365637,822.1183486024156,105.2201837999537,587.128438749015,2729.8478565226305,4133.313117642194,2846.04352196342,2210.9422812143494,703.7503582752852,-117.33034039236736,1349.8807150027988,1007.3070211214981,2136.009589822681,2610.9024873175367,471.35266749797665,1228.8081030984577,1995.1247135616031,1255.77323797779,2212.4057999518172,1773.3764875660163,1773.217120070778,753.9238648987739,228.7665610299373,966.4331694328957,665.3779180938818,-450.85945611168063,-1172.2251297695166,1923.9160603758573,301.7913775040506,2364.834621611635,3635.229029841392,2592.05047285848,2079.6418633472204,-290.06667875017956,49.41087379547025,804.9267327596554,1685.4562470471265,1933.1996354809053,1634.264009074319,-711.9873909910584,480.7518569174008,4440.047185834537,4275.009333369766,4285.204213542333,1324.6394447896564,951.1311094758094,-598.9080029543366,275.98717961967486,391.11074493742126,-274.27863111592706,-1209.6376962789636,-716.4904311457485,467.69769129132146,2773.711114118767,1035.631900119919,-2968.6660430858738,-2436.7032508925495,-1411.5152595662803,41.474826462957935,932.1136351122732,609.9355104414717,-603.7128941975116,1809.0054300193297,1441.96535703255,2314.4057917544924,4012.3370000772557,-397.09889024764016,1341.969971771341,1412.5464693630129,-475.15750564188966,292.64506353951947,1277.1172475044623,455.5204457256568,572.4630955491466,-621.2755980294878,-544.9911917763675,1156.7504632846958,2949.8582837266076,584.5591525560158,-213.86609737494837,-2012.7700715660976,-2127.869976061129,-306.18489338578365,155.42908346681725,1982.8293329531843,244.3451265766489,1387.4315610832546,400.839623839227,1214.5216346127272,2286.9539365300025,125.21008853138119,1726.8533817548287,487.91645672444065,-282.1504110218466,1789.794121697294,2040.016987005194,2484.812623215672,1514.4599922688758,38.99080433810377,1300.388629444642,1986.196578896248,3190.9301097752905,2516.425803212547,86.32683827876826,-2006.8533663328017,-1408.0274433655904,-27.143496875287383,1437.2031719208098,1364.506964276732,-216.61476986462003,-623.0485993753082,-742.4285393617029,1225.9512400890035,2965.005833419007,1821.9818509938486,1778.7892174629596,2639.7469946664532],\"type\":\"bar\",\"xaxis\":\"x3\",\"yaxis\":\"y3\",\"marker\":{\"line\":{\"color\":\"rgb(190,190,190)\"},\"color\":\"rgb(225,0,0)\"}},{\"name\":\"Erro LGBM\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161],\"y\":[-1546.7725472547208,433.18110845154115,-252.60828454783768,-515.1562308861285,262.3382678677244,295.2532393716456,-647.1961940158744,985.4784362267765,-370.07664561057936,-750.7909579161005,-580.5011068198346,-70.82975447609533,193.6330579052301,717.3428754627257,1080.7068401347587,414.57687265591267,1085.092735317403,692.9824029023621,732.5023183441235,951.8970221743675,-24.563338418755848,909.8233615633867,423.12785192204956,-7.823856465435938,530.6785951723455,907.3664067048094,203.25581515814702,-687.2155452621455,-402.9368626476207,-715.788062745135,145.39105156686674,225.92799355816896,666.872255150759,982.1601526661525,459.5723468200631,-999.9854077948112,-67.32849000080569,290.1671144823704,967.1551107363648,35.88612277654647,688.571673173903,170.8263839313804,225.03808747725725,734.2321219522182,690.1162587802546,-182.0799378517322,-676.7662555974366,-1358.163633592948,-980.9632828843778,-323.0900751107074,1749.9287133557154,1125.7825985630334,1364.0801408641546,331.4718877524265,-142.0614973511947,684.8724610029203,999.0982907709549,1494.2131739101878,750.1168935296864,184.660008519646,565.4607142909335,452.2713071975322,336.575990899737,1301.8939958330484,918.0184527992933,142.14427409180826,195.49899728143646,583.5326472349407,1679.9797032072638,807.0450207257636,-395.843073797354,284.9417420528098,987.6109777031106,-739.0130931658805,-1310.2340023204288,-49.3941046862692,188.9159007317412,1408.5458290055194,533.5723187651765,-186.2880993777635,-133.8560726456235,-382.4304131603876,-586.4043833657634,-773.8094766085487,-59.613524133392275,173.32508189445434,1234.13369375018,1542.8674367500862,2829.9292410727103,99.88629796833266,455.4394031101692,-1239.6877355445722,714.3221247722322,1308.9655965464535,949.205005543472,-124.93067044968666,-1130.9453378758717,1020.7094793450087,76.48057216984307,-1258.6975794322607,-948.4111991051777,570.2273168740085,-229.1448990270419,-579.0316149716346,1543.8821369500802,453.0527649007345,-1317.8148288238935,568.296465907144,1265.282662953934,764.6352266246031,1817.702833340274,-1715.0260367708815,332.2002220866998,276.71312159789886,-901.7153278099631,-530.2199049291012,82.48279693091172,501.31763138073984,-262.9859706556108,-1270.5204482000136,-1018.2583883796815,32.376227825892784,-1165.018539007724,-1045.6458880386472,-142.5175802019694,-496.8018553191487,-1326.3485343078373,489.0931532425784,1042.48995108274,649.8405089922471,-324.8127226872675,497.83646692783077,734.3864319544173,916.9836300528623,1277.2202999744695,50.32914660557799,915.4347038822143,1204.8208528255582,183.5359496359124,-441.6524677296984,329.4248999800802,1354.0504389635098,325.4299742343683,-218.77136201397298,-172.4705292367762,49.30923489689667,218.54003871773602,561.1555488974554,-119.65645299200696,-1685.9628874356986,-1933.2427285277572,511.8694407655803,-53.758774892361544,442.320187003892,81.21161243625102,-1297.5933393779014,-775.3924665517243,1602.5906898442336,3371.205635449618,1729.5276039825585,1304.6288016865037,2342.94630620279],\"type\":\"bar\",\"xaxis\":\"x4\",\"yaxis\":\"y4\",\"marker\":{\"line\":{\"color\":\"rgb(190,190,190)\"},\"color\":\"rgb(225,0,0)\"}},{\"name\":\"Erro Ensemble\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161],\"y\":[-916.4785811604934,98.65524056401955,312.0320015066527,14.132138415345253,-0.6541222816085792,-171.66694306527552,-686.0469963694368,704.3818953680639,280.29575205225956,-348.1310429469522,67.34219825942455,297.3239599979788,213.48421624474213,170.65619865059853,807.2897113403615,193.9606683968359,560.0969689952108,-36.62833011316434,-247.33642264388254,-82.40004511577627,-704.883815487412,-257.51218332240205,-343.7663222028168,-567.8896377999047,-95.39900473984017,249.97947466976984,417.0942248421461,-341.0449120320209,90.31438548213737,-409.4076756554741,-43.744791267597066,196.55924273510755,-66.44902942653061,544.8096607911248,17.44611484797315,-457.1510253776287,-464.48692593326996,397.95108432524466,589.6080147521661,-55.07579188447198,409.8030471096754,-208.01967950162543,-519.4055647702044,-365.13399167811076,-140.3481708261661,-151.17416446204334,22.034709183515588,-595.3292823480651,-201.35421579808008,280.71876168991184,708.6596988431502,329.67642100447665,675.3703613918951,160.47481302939923,-321.4460937266522,636.4706315808526,493.1540562598657,648.2949456094811,409.2291410431608,-9.030089308516835,563.2723209813284,778.4819977498737,191.87184336857717,458.1738281668677,770.8522588432061,563.1826948058224,195.85902449390596,260.07509819486404,906.7478770955968,478.8363996597145,-271.9806509695172,-392.30338155598656,919.3619435800792,-470.0501860728855,-642.4609573993293,52.43250081714905,36.270900697401885,538.600498022126,-194.28633663442088,-118.18455160764825,68.73345760732991,213.92269848424257,245.35171109249495,216.88824488746104,-455.6661402309801,122.45693429555467,879.7495030388927,397.7512187992688,111.98416801606436,317.7423062965936,420.4216248474877,-613.103822572084,265.86398732650923,490.9427485699671,83.60288471578133,-414.77192076984466,-624.5974799975957,281.2800539899963,-94.09711628418154,-285.9264745606015,-655.7587680752877,284.41138307127403,-654.8345697893837,-399.6083155834931,506.0680773333188,99.27846925191989,-810.5864877858639,572.5809415239801,582.5639338877318,397.38388471210783,951.2810140419097,-704.0423445276592,447.95983061466904,441.13206836489553,-837.3646564564242,-308.52443340979517,471.5057179454452,70.04505403671283,-118.9053504529802,-841.3166945184403,-616.6441521689612,295.7298724785687,-546.6910269012114,-560.5388202671274,-62.49333496192412,-251.63978549026797,-807.4464064871299,24.281342446787676,203.13653509931646,723.7532126463338,-294.6546678985487,345.5401783272591,-95.01458926335181,502.3984477338072,514.7947692712623,-377.68563612400976,674.5572377761127,157.08136021498285,-453.57520779241895,368.8822126973737,160.4551475910739,434.9006766452767,368.50074557335756,-240.54199071919356,338.56387784747494,506.65066989060506,51.01139938293272,49.320577436708845,-89.18235302305402,-1103.2661081027127,-980.4646573056143,9.898343676684817,333.9825340919833,430.44466136616575,-182.53413551908852,-727.2101811012635,-721.7965827066782,774.4204052352343,370.2562863667408,817.291142734266,776.8235758542432,40.25945671212321],\"type\":\"bar\",\"xaxis\":\"x5\",\"yaxis\":\"y5\",\"marker\":{\"line\":{\"color\":\"rgb(190,190,190)\"},\"color\":\"rgb(225,0,0)\"}}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.16799999999999998]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.208,0.376]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0]},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.416,0.584]},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,1.0]},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.624,0.792]},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,1.0]},\"xaxis5\":{\"anchor\":\"y5\",\"domain\":[0.832,1.0]},\"yaxis5\":{\"anchor\":\"x5\",\"domain\":[0.0,1.0]},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"SVR\",\"x\":0.08399999999999999,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"MLP\",\"x\":0.292,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"LSTM\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"LGBM\",\"x\":0.708,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Ensemble\",\"x\":0.9159999999999999,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"height\":800,\"width\":1500},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('0330b037-799f-477f-a8d4-bf2987897871');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Forecast"
      ],
      "metadata": {
        "id": "XkWewhgYNXTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "npred = 5\n",
        "dat = np.array(geracaoNE['val_geracao'])\n",
        "x1 = np.append(np.array(X_test)[161,1:],np.array(y_test)[161])\n",
        "x2=x4=x3=x1\n",
        "pred_SVR = []\n",
        "pred_MLP = []\n",
        "pred_LGBM = []\n",
        "pred_LSTM = []\n",
        "for i in range(5):\n",
        "  x1_p = x1[i:]\n",
        "  x2_p = x2[i:]\n",
        "  x3_p = x3[i:]\n",
        "  x4_p = x4[i:] \n",
        "  x1_p = x1_p.reshape((1,24))\n",
        "  x2_p = x2_p.reshape((1,24))\n",
        "  x3_p = x3_p.reshape((1,24))\n",
        "  x4_p = x4_p.reshape((1,24,1))\n",
        "  y1 = model_SVR.predict(x1_p)\n",
        "  y2 = model_mlp.predict(x2_p)\n",
        "  y3 = model_LGBM.predict(x3_p)\n",
        "  y4 = model_lstm.predict(x4_p)\n",
        "  x1 = np.append(x1,y1)\n",
        "  x2 = np.append(x2,y2)\n",
        "  x3 = np.append(x3,y3)\n",
        "  x4 = np.append(x4,y4)\n",
        "  pred_SVR = np.append(pred_SVR,y1)\n",
        "  pred_MLP = np.append(pred_MLP,y2)\n",
        "  pred_LGBM = np.append(pred_LGBM,y3)\n",
        "  pred_LSTM = np.append(pred_LSTM,y4)\n",
        "  \n",
        "  \n"
      ],
      "metadata": {
        "id": "BdoPelgxNa5V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3b2976a-d0c9-438a-f0a1-ced417a129f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_MLP =np.array([k* invn for k in pred_MLP])\n",
        "#pred_MLP =list(itertools.chain(*pred_MLP))\n",
        "pred_SVR =np.array([k* invn for k in pred_SVR])\n",
        "#pred_SVR =list(itertools.chain(*pred_SVR))\n",
        "pred_LGBM =np.array([k* invn for k in pred_LGBM])\n",
        "#pred_LGBM =list(itertools.chain(*pred_LGBM))\n",
        "pred_LSTM =np.array([k* invn for k in pred_LSTM])\n",
        "#pred_LSTM =list(itertools.chain(*pred_LSTM))\n",
        "x1 = np.arange(len(y_plt),len(y_plt)+5,1)\n"
      ],
      "metadata": {
        "id": "b1E8cotajhrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure()\n",
        "fig = make_subplots(rows=1, cols=4,subplot_titles=(\"SVR\",\"MLP\",\"LGBM\",'LSTM'))\n",
        "fig.add_trace(go.Scatter(x=np.arange(len(y_plt)), y=y_plt,name='true'),row=1,col=1)\n",
        "fig.add_trace(go.Scatter(x=x1, y=pred_SVR,name='forecast'),row=1,col=1)\n",
        "fig.add_trace(go.Scatter(x=np.arange(len(y_plt)), y=y_plt,name='true'),row=1,col=2)\n",
        "fig.add_trace(go.Scatter(x=x1, y=pred_MLP,name='forecast'),row=1,col=2)\n",
        "fig.add_trace(go.Scatter(x=np.arange(len(y_plt)), y=y_plt,name='true'),row=1,col=3)\n",
        "fig.add_trace(go.Scatter(x=x1, y=pred_LGBM,name='forecast'),row=1,col=3)\n",
        "fig.add_trace(go.Scatter(x=np.arange(len(y_plt)), y=y_plt,name='true'),row=1,col=4)\n",
        "fig.add_trace(go.Scatter(x=x1, y=pred_LSTM,name='forecast'),row=1,col=4)\n",
        "fig.update_layout(title='Models',height=800,width=1500)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "ZazTkFaEqTp3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "outputId": "8e4019d4-dd9c-48b5-ea35-b5b4b844eee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"d4be9790-2533-4d25-b8b1-0ca885575a05\" class=\"plotly-graph-div\" style=\"height:800px; width:1500px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d4be9790-2533-4d25-b8b1-0ca885575a05\")) {                    Plotly.newPlot(                        \"d4be9790-2533-4d25-b8b1-0ca885575a05\",                        [{\"name\":\"true\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161],\"y\":[5344.023014670782,6587.880504885346,8120.639030879285,8136.0788981978385,7484.203626112821,6977.373975791941,6672.008616749272,9187.330042623724,9646.153158994746,9146.588644643289,10154.640749746275,10588.902123593418,10868.673660038754,10105.664101051212,11451.324099622661,10812.858030937557,11284.634633536574,9199.9277488072,8117.882609649378,7370.215865325086,5526.761985815975,4271.662067102907,2948.373500944957,1947.3471004736564,2878.9380651156116,3890.3160750070665,5670.811408206657,5275.64937199031,6728.9258316438845,6160.718634341012,7270.456743726767,8672.248098147054,8347.422956352219,9748.52349509212,9185.117411916151,9211.906118982377,8169.651124854656,9675.82077066528,12321.33286456527,10203.855259257982,10173.10652613951,8378.935788708417,6781.216772799271,5933.729837556251,6012.91516568038,5953.554423621344,7012.513856414916,6636.287566612454,7466.820821561515,10168.84053230388,12561.056281704694,12350.72223290092,12554.90907808935,11485.598014525285,10797.632550232633,12311.906105627799,11954.899794558998,13220.925605447681,14226.878073255037,12474.709112810477,13048.306149973458,13668.462604186603,13000.65995672779,14316.701698389317,14354.270042253516,14956.380206008278,14327.952185211274,13866.803670404937,14439.600161620396,13737.075183718882,11925.35831732582,10383.852995230483,13251.412154125857,11507.64001031655,14033.189113799135,16281.218287653892,16338.81414473348,16669.38991022222,14511.49289156232,14550.37571754547,14906.617162447155,15981.888864234626,16838.495533918405,17123.57943876182,14485.343663696442,15227.4315444174,19798.867498334537,20736.593317744766,21986.032338542333,19832.735147914656,20082.59790635081,18275.234575170663,18376.590695244675,17489.22597931242,15884.462579821573,14081.939452158536,13939.723436041751,14461.160581916321,17173.688653181267,16171.890689182419,11445.392550664126,10482.12096785745,10797.01696699622,12240.588107712958,13230.745471049773,13276.624963566472,12557.583004239988,15953.45367220683,16404.54543515755,17717.831573004492,20118.653406327256,16268.15696912736,18200.18872177134,18303.460531863013,15860.11983810811,15986.75639166452,16791.876036566962,15726.368101975657,15295.839072111647,13536.181433220512,12988.719745723633,14231.172338284696,16699.966682164108,15190.659738493516,14415.713004187552,11716.398873746402,10749.442523938871,11717.319989426716,11660.807013154317,13699.097887640684,12476.994540639149,14431.523357958255,13981.767358214227,14835.749173675227,16209.450030280002,14376.094854156381,16351.484241129829,15287.05415203694,14244.334940540653,16479.539238884794,17222.776752630194,18179.529420090672,17437.952179768876,15873.672444963104,16883.192340382142,17553.641891396248,19365.89495352529,19570.486350087547,17272.93230702877,14173.755032104698,13474.40712694691,13706.966854687213,14793.73637504581,14823.796026776732,13390.47409732288,13138.527572499692,12906.989429388297,14864.842841651503,17167.879856856507,16839.26310099385,17737.77652215046,19707.520432166453],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"name\":\"forecast\",\"x\":[162,163,164,165,166],\"y\":[19090.442020114133,19269.639095145823,19607.127950110316,19532.47786532308,19806.713410552038],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"name\":\"true\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161],\"y\":[5344.023014670782,6587.880504885346,8120.639030879285,8136.0788981978385,7484.203626112821,6977.373975791941,6672.008616749272,9187.330042623724,9646.153158994746,9146.588644643289,10154.640749746275,10588.902123593418,10868.673660038754,10105.664101051212,11451.324099622661,10812.858030937557,11284.634633536574,9199.9277488072,8117.882609649378,7370.215865325086,5526.761985815975,4271.662067102907,2948.373500944957,1947.3471004736564,2878.9380651156116,3890.3160750070665,5670.811408206657,5275.64937199031,6728.9258316438845,6160.718634341012,7270.456743726767,8672.248098147054,8347.422956352219,9748.52349509212,9185.117411916151,9211.906118982377,8169.651124854656,9675.82077066528,12321.33286456527,10203.855259257982,10173.10652613951,8378.935788708417,6781.216772799271,5933.729837556251,6012.91516568038,5953.554423621344,7012.513856414916,6636.287566612454,7466.820821561515,10168.84053230388,12561.056281704694,12350.72223290092,12554.90907808935,11485.598014525285,10797.632550232633,12311.906105627799,11954.899794558998,13220.925605447681,14226.878073255037,12474.709112810477,13048.306149973458,13668.462604186603,13000.65995672779,14316.701698389317,14354.270042253516,14956.380206008278,14327.952185211274,13866.803670404937,14439.600161620396,13737.075183718882,11925.35831732582,10383.852995230483,13251.412154125857,11507.64001031655,14033.189113799135,16281.218287653892,16338.81414473348,16669.38991022222,14511.49289156232,14550.37571754547,14906.617162447155,15981.888864234626,16838.495533918405,17123.57943876182,14485.343663696442,15227.4315444174,19798.867498334537,20736.593317744766,21986.032338542333,19832.735147914656,20082.59790635081,18275.234575170663,18376.590695244675,17489.22597931242,15884.462579821573,14081.939452158536,13939.723436041751,14461.160581916321,17173.688653181267,16171.890689182419,11445.392550664126,10482.12096785745,10797.01696699622,12240.588107712958,13230.745471049773,13276.624963566472,12557.583004239988,15953.45367220683,16404.54543515755,17717.831573004492,20118.653406327256,16268.15696912736,18200.18872177134,18303.460531863013,15860.11983810811,15986.75639166452,16791.876036566962,15726.368101975657,15295.839072111647,13536.181433220512,12988.719745723633,14231.172338284696,16699.966682164108,15190.659738493516,14415.713004187552,11716.398873746402,10749.442523938871,11717.319989426716,11660.807013154317,13699.097887640684,12476.994540639149,14431.523357958255,13981.767358214227,14835.749173675227,16209.450030280002,14376.094854156381,16351.484241129829,15287.05415203694,14244.334940540653,16479.539238884794,17222.776752630194,18179.529420090672,17437.952179768876,15873.672444963104,16883.192340382142,17553.641891396248,19365.89495352529,19570.486350087547,17272.93230702877,14173.755032104698,13474.40712694691,13706.966854687213,14793.73637504581,14823.796026776732,13390.47409732288,13138.527572499692,12906.989429388297,14864.842841651503,17167.879856856507,16839.26310099385,17737.77652215046,19707.520432166453],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"name\":\"forecast\",\"x\":[162,163,164,165,166],\"y\":[20018.66773932326,20295.397673285843,20229.6456382972,20311.06328387439,20558.01805060208],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"name\":\"true\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161],\"y\":[5344.023014670782,6587.880504885346,8120.639030879285,8136.0788981978385,7484.203626112821,6977.373975791941,6672.008616749272,9187.330042623724,9646.153158994746,9146.588644643289,10154.640749746275,10588.902123593418,10868.673660038754,10105.664101051212,11451.324099622661,10812.858030937557,11284.634633536574,9199.9277488072,8117.882609649378,7370.215865325086,5526.761985815975,4271.662067102907,2948.373500944957,1947.3471004736564,2878.9380651156116,3890.3160750070665,5670.811408206657,5275.64937199031,6728.9258316438845,6160.718634341012,7270.456743726767,8672.248098147054,8347.422956352219,9748.52349509212,9185.117411916151,9211.906118982377,8169.651124854656,9675.82077066528,12321.33286456527,10203.855259257982,10173.10652613951,8378.935788708417,6781.216772799271,5933.729837556251,6012.91516568038,5953.554423621344,7012.513856414916,6636.287566612454,7466.820821561515,10168.84053230388,12561.056281704694,12350.72223290092,12554.90907808935,11485.598014525285,10797.632550232633,12311.906105627799,11954.899794558998,13220.925605447681,14226.878073255037,12474.709112810477,13048.306149973458,13668.462604186603,13000.65995672779,14316.701698389317,14354.270042253516,14956.380206008278,14327.952185211274,13866.803670404937,14439.600161620396,13737.075183718882,11925.35831732582,10383.852995230483,13251.412154125857,11507.64001031655,14033.189113799135,16281.218287653892,16338.81414473348,16669.38991022222,14511.49289156232,14550.37571754547,14906.617162447155,15981.888864234626,16838.495533918405,17123.57943876182,14485.343663696442,15227.4315444174,19798.867498334537,20736.593317744766,21986.032338542333,19832.735147914656,20082.59790635081,18275.234575170663,18376.590695244675,17489.22597931242,15884.462579821573,14081.939452158536,13939.723436041751,14461.160581916321,17173.688653181267,16171.890689182419,11445.392550664126,10482.12096785745,10797.01696699622,12240.588107712958,13230.745471049773,13276.624963566472,12557.583004239988,15953.45367220683,16404.54543515755,17717.831573004492,20118.653406327256,16268.15696912736,18200.18872177134,18303.460531863013,15860.11983810811,15986.75639166452,16791.876036566962,15726.368101975657,15295.839072111647,13536.181433220512,12988.719745723633,14231.172338284696,16699.966682164108,15190.659738493516,14415.713004187552,11716.398873746402,10749.442523938871,11717.319989426716,11660.807013154317,13699.097887640684,12476.994540639149,14431.523357958255,13981.767358214227,14835.749173675227,16209.450030280002,14376.094854156381,16351.484241129829,15287.05415203694,14244.334940540653,16479.539238884794,17222.776752630194,18179.529420090672,17437.952179768876,15873.672444963104,16883.192340382142,17553.641891396248,19365.89495352529,19570.486350087547,17272.93230702877,14173.755032104698,13474.40712694691,13706.966854687213,14793.73637504581,14823.796026776732,13390.47409732288,13138.527572499692,12906.989429388297,14864.842841651503,17167.879856856507,16839.26310099385,17737.77652215046,19707.520432166453],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"name\":\"forecast\",\"x\":[162,163,164,165,166],\"y\":[17153.863011872832,16487.68177360166,15377.535205254353,14029.717385831254,13777.502580514461],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"name\":\"true\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161],\"y\":[5344.023014670782,6587.880504885346,8120.639030879285,8136.0788981978385,7484.203626112821,6977.373975791941,6672.008616749272,9187.330042623724,9646.153158994746,9146.588644643289,10154.640749746275,10588.902123593418,10868.673660038754,10105.664101051212,11451.324099622661,10812.858030937557,11284.634633536574,9199.9277488072,8117.882609649378,7370.215865325086,5526.761985815975,4271.662067102907,2948.373500944957,1947.3471004736564,2878.9380651156116,3890.3160750070665,5670.811408206657,5275.64937199031,6728.9258316438845,6160.718634341012,7270.456743726767,8672.248098147054,8347.422956352219,9748.52349509212,9185.117411916151,9211.906118982377,8169.651124854656,9675.82077066528,12321.33286456527,10203.855259257982,10173.10652613951,8378.935788708417,6781.216772799271,5933.729837556251,6012.91516568038,5953.554423621344,7012.513856414916,6636.287566612454,7466.820821561515,10168.84053230388,12561.056281704694,12350.72223290092,12554.90907808935,11485.598014525285,10797.632550232633,12311.906105627799,11954.899794558998,13220.925605447681,14226.878073255037,12474.709112810477,13048.306149973458,13668.462604186603,13000.65995672779,14316.701698389317,14354.270042253516,14956.380206008278,14327.952185211274,13866.803670404937,14439.600161620396,13737.075183718882,11925.35831732582,10383.852995230483,13251.412154125857,11507.64001031655,14033.189113799135,16281.218287653892,16338.81414473348,16669.38991022222,14511.49289156232,14550.37571754547,14906.617162447155,15981.888864234626,16838.495533918405,17123.57943876182,14485.343663696442,15227.4315444174,19798.867498334537,20736.593317744766,21986.032338542333,19832.735147914656,20082.59790635081,18275.234575170663,18376.590695244675,17489.22597931242,15884.462579821573,14081.939452158536,13939.723436041751,14461.160581916321,17173.688653181267,16171.890689182419,11445.392550664126,10482.12096785745,10797.01696699622,12240.588107712958,13230.745471049773,13276.624963566472,12557.583004239988,15953.45367220683,16404.54543515755,17717.831573004492,20118.653406327256,16268.15696912736,18200.18872177134,18303.460531863013,15860.11983810811,15986.75639166452,16791.876036566962,15726.368101975657,15295.839072111647,13536.181433220512,12988.719745723633,14231.172338284696,16699.966682164108,15190.659738493516,14415.713004187552,11716.398873746402,10749.442523938871,11717.319989426716,11660.807013154317,13699.097887640684,12476.994540639149,14431.523357958255,13981.767358214227,14835.749173675227,16209.450030280002,14376.094854156381,16351.484241129829,15287.05415203694,14244.334940540653,16479.539238884794,17222.776752630194,18179.529420090672,17437.952179768876,15873.672444963104,16883.192340382142,17553.641891396248,19365.89495352529,19570.486350087547,17272.93230702877,14173.755032104698,13474.40712694691,13706.966854687213,14793.73637504581,14823.796026776732,13390.47409732288,13138.527572499692,12906.989429388297,14864.842841651503,17167.879856856507,16839.26310099385,17737.77652215046,19707.520432166453],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"name\":\"forecast\",\"x\":[162,163,164,165,166],\"y\":[17870.862994083047,17643.534020243766,17194.05082751608,16735.95680252302,16355.577915334701],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.2125]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.2625,0.475]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0]},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.525,0.7375]},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,1.0]},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.7875,1.0]},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,1.0]},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"SVR\",\"x\":0.10625,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"MLP\",\"x\":0.36875,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"LGBM\",\"x\":0.6312500000000001,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"LSTM\",\"x\":0.89375,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Models\"},\"height\":800,\"width\":1500},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d4be9790-2533-4d25-b8b1-0ca885575a05');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyP8iSjvm2MqDl8ljXRBdRiA",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}